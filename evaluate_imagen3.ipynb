{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n",
    "    \n",
    "#import os\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "\n",
    "datasetPathGeneratedFaces =  configParser.get('evaluate_imagen', 'test_datasetPathGeneratedFaces')\n",
    "generated_face_table_name =  configParser.get('evaluate_imagen', 'generated_face_table_name')\n",
    "\n",
    "\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'test_datasetPathDatabase') + '/dataset.db'\n",
    "\n",
    "\n",
    "\n",
    "cuda =  int(configParser.get('COMMON', 'cuda'))\n",
    "cpus =  int(configParser.get('COMMON', 'cpus'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO document jupyter\n",
    "import pickle\n",
    "import sqlite3 as sl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from textwrap import wrap\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =  int(configParser.get('COMMON', 'resizeImageTo'))\n",
    "audio_length_used =  configParser.get('evaluate_imagen', 'audio_length_used') \n",
    "model_filename =  configParser.get('evaluate_imagen', 'model_filename') + '_'  + audio_length_used +  's.pt'\n",
    "openl3_mode =  configParser.get('evaluate_imagen', 'openl3_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "uri = datasetPathDatabase\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "table = db.open_table(\"video_stage1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  db.drop_table(generated_face_table_name)\n",
    "except:\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "uri = datasetPathDatabase\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "\n",
    "files_to_insert = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(datasetPathGeneratedFaces):\n",
    "    for file in files:\n",
    "        files_to_insert.append(root +'/'+ file)\n",
    "        #print(root + file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = output_folder = r'imagen_testing_folder' \n",
    "if not os.path.exists(audio_folder):\n",
    "    os.makedirs(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from testing_imagen_vision_transformer import extract_vision_transformer\n",
    "from testing_imagen_face import extract_face_rep\n",
    "import pathlib\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i = 0\n",
    "for face_file in files_to_insert:\n",
    "    \n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    try:\n",
    "        proc = multiprocessing.Process(target=extract_face_rep, args=(q,face_file,\n",
    "                                                                image_size,output_folder,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    with open(output_folder + '/' + 'vgg_generated_face.pickle', 'rb') as handle:\n",
    "        vgg = pickle.load(handle)\n",
    "        #print(\"++++++\" + str(vgg))\n",
    "\n",
    "\n",
    "    \n",
    "    tbl = db.open_table(\"video_stage1\")\n",
    "    result = tbl.search(vgg).limit(5).to_df()\n",
    "\n",
    "    match_1 = result.iloc[0]['user']\n",
    "    match_2 = result.iloc[1]['user']\n",
    "    match_3 = result.iloc[2]['user']\n",
    "    match_4 = result.iloc[3]['user']\n",
    "    match_5 = result.iloc[4]['user']\n",
    "\n",
    "    p_small = pathlib.Path(os.path.dirname(face_file))\n",
    "    p_big = p_small.parent.absolute()\n",
    "    \n",
    "    df_table = pd.DataFrame()\n",
    "    df_table = df_table.append({'id': i , \n",
    "                    'generated_face_path': face_file,'user':p_big.name,\n",
    "                    'match_1':match_1,'match_2':match_2,'match_3':match_3,'match_4':match_4,'match_5':match_5,\n",
    "        'vector' : vgg,'stage': 1}, ignore_index=True)\n",
    "    \n",
    "\n",
    "    if(i == 0):\n",
    "        db.create_table(generated_face_table_name, df_table)\n",
    "    else:\n",
    "        tbl = db.open_table(generated_face_table_name)\n",
    "        tbl.add(df_table)\n",
    "\n",
    "\n",
    "    print(i)\n",
    "    i = i + 1\n",
    "\n",
    "shutil.rmtree(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = db.open_table(generated_face_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78dccc615e96ab04385280185a87a524fe0822daf5dbad2f4bf2e7d7b28366a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
