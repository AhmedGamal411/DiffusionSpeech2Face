{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n",
    "    \n",
    "#import os\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "\n",
    "datasetPathGeneratedFaces =  configParser.get('evaluate_imagen', 'test_datasetPathGeneratedFaces')\n",
    "generated_face_table_name =  configParser.get('evaluate_imagen', 'generated_face_table_name')\n",
    "evaluation_result_file = configParser.get('evaluate_imagen', 'evaluation_result_file')\n",
    "\n",
    "\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'test_datasetPathDatabase') + '/dataset.db'\n",
    "\n",
    "\n",
    "\n",
    "cuda =  int(configParser.get('COMMON', 'cuda'))\n",
    "cpus =  int(configParser.get('COMMON', 'cpus'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO document jupyter\n",
    "import pickle\n",
    "import sqlite3 as sl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from textwrap import wrap\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =  int(configParser.get('COMMON', 'resizeImageTo'))\n",
    "audio_length_used =  configParser.get('evaluate_imagen', 'audio_length_used') \n",
    "model_filename =  configParser.get('evaluate_imagen', 'model_filename') + '_'  + audio_length_used +  's.pt'\n",
    "openl3_mode =  configParser.get('evaluate_imagen', 'openl3_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "uri = datasetPathDatabase\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "table = db.open_table(\"video_stage1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  db.drop_table(generated_face_table_name)\n",
    "except:\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "try:\n",
    "    multiprocessing.set_start_method('spawn')\n",
    "except:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "uri = datasetPathDatabase\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "\n",
    "files_to_insert = []\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(datasetPathGeneratedFaces):\n",
    "    for file in files:\n",
    "        files_to_insert.append(root +'/'+ file)\n",
    "        #print(root + file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = output_folder = r'imagen_testing_folder' \n",
    "if not os.path.exists(audio_folder):\n",
    "    os.makedirs(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 21:40:24.758390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from testing_imagen_vision_transformer import extract_vision_transformer\n",
    "from testing_imagen_face import extract_face_rep,extract_face_attributes\n",
    "import pathlib\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0----------------\n",
      "---------------1----------------\n",
      "---------------2----------------\n",
      "---------------3----------------\n",
      "---------------4----------------\n",
      "---------------5----------------\n",
      "---------------6----------------\n",
      "---------------7----------------\n",
      "---------------8----------------\n",
      "---------------9----------------\n",
      "---------------10----------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "i = 0\n",
    "for face_file in files_to_insert:\n",
    "    \n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    try:\n",
    "        proc = multiprocessing.Process(target=extract_face_rep, args=(q,face_file,\n",
    "                                                                image_size,output_folder,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    with open(output_folder + '/' + 'vgg_generated_face.pickle', 'rb') as handle:\n",
    "        vgg = pickle.load(handle)\n",
    "        #print(\"++++++\" + str(vgg))\n",
    "\n",
    "    try:\n",
    "        proc = multiprocessing.Process(target=extract_face_attributes, args=(q,face_file,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "        gender = q.get()\n",
    "        if(gender == 'Error'):\n",
    "            continue\n",
    "        ethnicity = q.get()\n",
    "        if(ethnicity == 'Error'):\n",
    "            continue\n",
    "        age = q.get()\n",
    "        if(age == 'Error'):\n",
    "            continue\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n",
    "    tbl = db.open_table(\"video_stage1\")\n",
    "    result = tbl.search(vgg).limit(10).to_df()\n",
    "\n",
    "    match_1 = result.iloc[0]['user']\n",
    "    match_2 = result.iloc[1]['user']\n",
    "    match_3 = result.iloc[2]['user']\n",
    "    match_4 = result.iloc[3]['user']\n",
    "    match_5 = result.iloc[4]['user']\n",
    "    match_6 = result.iloc[5]['user']\n",
    "    match_7 = result.iloc[6]['user']\n",
    "    match_8 = result.iloc[7]['user']\n",
    "    match_9 = result.iloc[8]['user']\n",
    "    match_10= result.iloc[9]['user']\n",
    "    \n",
    "\n",
    "    p_small = pathlib.Path(os.path.dirname(face_file))\n",
    "    p_big = p_small.parent.absolute()\n",
    "    \n",
    "    df_table = pd.DataFrame()\n",
    "    df_table = df_table.append({'id': i , \n",
    "                    'generated_face_path': face_file,'user':p_big.name,'age':age,'gender':gender,'ethnicity':ethnicity,\n",
    "                    'match_1':match_1,'match_2':match_2,'match_3':match_3,'match_4':match_4,'match_5':match_5,\n",
    "                    'match_6':match_6,'match_7':match_7,'match_8':match_8,'match_9':match_9,'match_10':match_10,\n",
    "        'vector' : vgg,'stage': 1}, ignore_index=True)\n",
    "    \n",
    "\n",
    "    if(i == 0):\n",
    "        try:\n",
    "            db.create_table(generated_face_table_name, df_table)\n",
    "        except:\n",
    "            db.drop_table(generated_face_table_name)\n",
    "            db.create_table(generated_face_table_name, df_table)\n",
    "    else:\n",
    "        tbl = db.open_table(generated_face_table_name)\n",
    "        tbl.add(df_table)\n",
    "\n",
    "\n",
    "    print(\"---------------\" + str(i) + \"----------------\")\n",
    "    i = i + 1\n",
    "\n",
    "shutil.rmtree(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = db.open_table(generated_face_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated_face_path</th>\n",
       "      <th>user</th>\n",
       "      <th>match_1</th>\n",
       "      <th>match_2</th>\n",
       "      <th>match_3</th>\n",
       "      <th>match_4</th>\n",
       "      <th>match_5</th>\n",
       "      <th>match_6</th>\n",
       "      <th>match_7</th>\n",
       "      <th>match_8</th>\n",
       "      <th>match_9</th>\n",
       "      <th>match_10</th>\n",
       "      <th>vector</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00005</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00012</td>\n",
       "      <td>id00007</td>\n",
       "      <td>[0.016634291, 0.00096485106, 0.014822065, 0.03...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00012</td>\n",
       "      <td>[0.014305992, 0.00968499, 0.015560359, 0.02682...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00012</td>\n",
       "      <td>[0.013197578, 0.004402566, 0.014329791, 0.0255...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00012</td>\n",
       "      <td>[0.012554283, 0.004316603, 0.011428701, 0.0281...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00005</td>\n",
       "      <td>id00004</td>\n",
       "      <td>[0.014646208, 0.0038225134, 0.01508191, 0.0265...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00012</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00005</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00012</td>\n",
       "      <td>[0.019030118, 0.007888322, 0.01813038, 0.03026...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00012</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00005</td>\n",
       "      <td>[0.013786207, 0.0091431085, 0.011618518, 0.035...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00005</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00005</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00004</td>\n",
       "      <td>[0.015202785, 0.008085675, 0.0192317, 0.027221...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00008</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00005</td>\n",
       "      <td>[0.016861234, 0.008097973, 0.012873291, 0.0244...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00012</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00008</td>\n",
       "      <td>[0.008715284, 0.008745547, 0.019739512, 0.0285...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GeneratedFac...</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00003</td>\n",
       "      <td>id00001</td>\n",
       "      <td>id00010</td>\n",
       "      <td>id00007</td>\n",
       "      <td>id00002</td>\n",
       "      <td>id00009</td>\n",
       "      <td>id00006</td>\n",
       "      <td>id00005</td>\n",
       "      <td>id00004</td>\n",
       "      <td>id00008</td>\n",
       "      <td>[0.0143902125, 0.007967351, 0.021307115, 0.028...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                generated_face_path     user  match_1  \\\n",
       "0    0  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00002  id00003   \n",
       "1    1  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00001  id00003   \n",
       "2    2  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00006  id00003   \n",
       "3    3  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00008  id00003   \n",
       "4    4  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00010  id00003   \n",
       "5    5  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00012  id00003   \n",
       "6    6  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00009  id00003   \n",
       "7    7  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00005  id00003   \n",
       "8    8  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00004  id00003   \n",
       "9    9  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00007  id00003   \n",
       "10  10  /home/gamal/Datasets/Dataset1Test/GeneratedFac...  id00003  id00003   \n",
       "\n",
       "    match_2  match_3  match_4  match_5  match_6  match_7  match_8  match_9  \\\n",
       "0   id00001  id00006  id00002  id00010  id00008  id00005  id00009  id00012   \n",
       "1   id00001  id00009  id00007  id00010  id00004  id00008  id00002  id00006   \n",
       "2   id00001  id00009  id00007  id00002  id00010  id00004  id00006  id00008   \n",
       "3   id00001  id00009  id00010  id00007  id00008  id00006  id00002  id00004   \n",
       "4   id00001  id00002  id00010  id00009  id00007  id00006  id00008  id00005   \n",
       "5   id00001  id00010  id00006  id00002  id00005  id00007  id00009  id00008   \n",
       "6   id00006  id00010  id00012  id00001  id00009  id00008  id00007  id00002   \n",
       "7   id00001  id00002  id00007  id00010  id00009  id00005  id00006  id00008   \n",
       "8   id00001  id00010  id00006  id00009  id00002  id00007  id00008  id00004   \n",
       "9   id00001  id00009  id00010  id00007  id00006  id00012  id00002  id00004   \n",
       "10  id00001  id00010  id00007  id00002  id00009  id00006  id00005  id00004   \n",
       "\n",
       "   match_10                                             vector  stage  \n",
       "0   id00007  [0.016634291, 0.00096485106, 0.014822065, 0.03...      1  \n",
       "1   id00012  [0.014305992, 0.00968499, 0.015560359, 0.02682...      1  \n",
       "2   id00012  [0.013197578, 0.004402566, 0.014329791, 0.0255...      1  \n",
       "3   id00012  [0.012554283, 0.004316603, 0.011428701, 0.0281...      1  \n",
       "4   id00004  [0.014646208, 0.0038225134, 0.01508191, 0.0265...      1  \n",
       "5   id00012  [0.019030118, 0.007888322, 0.01813038, 0.03026...      1  \n",
       "6   id00005  [0.013786207, 0.0091431085, 0.011618518, 0.035...      1  \n",
       "7   id00004  [0.015202785, 0.008085675, 0.0192317, 0.027221...      1  \n",
       "8   id00005  [0.016861234, 0.008097973, 0.012873291, 0.0244...      1  \n",
       "9   id00008  [0.008715284, 0.008745547, 0.019739512, 0.0285...      1  \n",
       "10  id00008  [0.0143902125, 0.007967351, 0.021307115, 0.028...      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptable = tbl.to_pandas()\n",
    "ptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptable_unique_users = ptable.drop_duplicates(subset=['user'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= open(evaluation_result_file,\"w+\")\n",
    "f.write(\"No. of generated faces: \" + str(len(ptable)) + \"\\n\")\n",
    "f.write(\"No. of unique users: \" + str(len(ptable_unique_users)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_10 = int((len(tbl.search() \\\n",
    "   .where(\"\"\" user = match_1 or user = match_2 or user = match_3 \n",
    "          or user = match_4 or user = match_5 or user = match_6 or user = match_7\n",
    "          or user = match_8 or user = match_9 or user = match_10\n",
    "    \"\"\").to_df()) / float(len(ptable))) * 100)\n",
    "f.write(\"Face Recognition Accuracy within first 10 matches: \" + str(acc_10) + \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5 = int((len(tbl.search() \\\n",
    "   .where(\"\"\" user = match_1 or user = match_2 or user = match_3\n",
    "          or user = match_4 or user = match_5 \n",
    "    \"\"\").to_df()) / float(len(ptable))) * 100)\n",
    "f.write(\"Face Recognition Accuracy within first  5 matches: \" + str(acc_5) + \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_3 = int((len(tbl.search() \\\n",
    "   .where(\"\"\" user = match_1 or user = match_2 or user = match_3\n",
    "    \"\"\").to_df()) / float(len(ptable))) * 100)\n",
    "f.write(\"Face Recognition Accuracy within first  3 matches: \" + str(acc_3) + \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_1 = int((len(tbl.search() \\\n",
    "   .where(\"\"\" user = match_1\n",
    "    \"\"\").to_df()) / float(len(ptable))) * 100)\n",
    "f.write(\"Face Recognition Accuracy within first  1 matches: \" + str(acc_1) + \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78dccc615e96ab04385280185a87a524fe0822daf5dbad2f4bf2e7d7b28366a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
