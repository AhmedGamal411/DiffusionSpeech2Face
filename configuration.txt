[COMMON]
datasetPathVideo = /home/gamal/Datasets/Dataset1/Video
datasetPathDatabase = /home/gamal/Datasets/Dataset1/Database
test_datasetPathVideo = /home/gamal/Datasets/Dataset1Test/VideoTest
test_datasetPathDatabase = /home/gamal/Datasets/Dataset1Test/DatabaseTest
cuda=1
cpus=8
resizeImageTo = 32
begin_with_image_size = 8
audio_embs_options = wav2vec or openl3
audio_embs = pyannoteTitaNet
unet_dim = 64
unet1_image_size = 16
insert_amd_env_vars = 1
HSA_OVERRIDE_GFX_VERSION = 10.3.0
ROCM_PATH = /opt/rocm
timesteps = 256

[dbCreateAndPopulate]
recreateDb=1

[extractAudio]
datasetPathAudio = /home/gamal/Datasets/Dataset1/Audio
dbChunk = 240
time_to_wait_before_deleting_files = 60


[extractFaces]
expandFaceVerticalRatio = 0.4
expandFaceHorizontalRatio=0.5
faceDetectionDeepFaceBackend=4
parallelism = 5
parallelismFrames = 1
datasetPathFrames = /home/gamal/Datasets/Dataset1/Frames
datasetPathFaces = /home/gamal/Datasets/Dataset1/Faces

[fineTuneStableDiffusionTraining]
db_chunk = 50000
dev_mode = 0
continue_from_epoch = 1
continue_from_offset = 0
continue_from_epoch_and_offset = 0
unconditional_guidance_scale = 40

[extractOpenL3]
datasetPathAudio = /home/gamal/Datasets/Dataset1/Audio
dbChunk = 240
time_to_wait_before_deleting_files = 60
openl3_mode_options = stable or imagen
openl3_mode = imagen

[extractWavToVec]
datasetPathAudio = /home/gamal/Datasets/Dataset1/Audio
dbChunk = 240
time_to_wait_before_deleting_files = 60
audio_length_wav2vec = 6

[extractPyannoteTitaNet]
datasetPathAudio = /home/gamal/Datasets/Dataset1/Audio
dbChunk = 240
time_to_wait_before_deleting_files = 60
use_auth_token = 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

[extractAudioFeatures]
datasetPathAudio = /home/gamal/Datasets/Dataset1/Audio
dbChunk = 240
time_to_wait_before_deleting_files = 60

[fineTuneStableDiffusionTesting]
use_video_in_configuration = 1
video_path = /home/gamal/Datasets/Dataset1/Video/blhA_I4zjvE_15.600000_22.333333.mp4
time_to_wait_before_deleting_files = 180
dev_mode = 0

[train_imagen]
model_filename = imagen_features_low_res_asis
audio_length_used = 24
epochs = 1
sample_every_offset = 1
save_every_offset = 1
sub_epochs = 250
sample_every = 4000
save_model_every = 4000
batch_size = 4
continue_from_epoch = 1
continue_from_offset = 0
continue_from_epoch_and_offset_flag = 0
db_chunk = 12
c_unte2 = 54500
c_unite1 = 77000
ignore_speaker_embedding = 0
ignore_speech_brain = 0
ignore_pyannote_titanet_speakernet = 0
ignore_audio_features = 0
ignore_pyAudioAnalysis = 0
ignore_librosa = 0
ignore_image_guide = 0
ignore_additional_attributes = 0
ignore_age = 0
ignore_gender = 0
ignore_ethnicity = 0
ignore_language_spoken = 0

[test_imagen]
video_path = /home/gamal/vsc/DiffusionSpeech2Face/old/v.mp4
time_to_wait_before_deleting_files = 180
audio_length_used = 24
model_filename = imagen_features_low_res_asis
openl3_mode_options = stable or imagen
openl3_mode = imagen
folder = imagen-test-folder
number_of_images = 2
age = 25
ethnicity = black 
gender = man
language = English
image_guide_path = /home/gamal/vsc/DiffusionSpeech2Face/old/a12.png
blur_or_pixelate = 1
boxBlurMin = 4
boxBlurMax = 14
gaussianBlurMin=2
gaussianBlurMax=6
pix_to_min = 8
pix_to_max = 16
low_res_image = /home/gamal/vsc/DiffusionSpeech2Face/old/a12.png
skip_speaker_embedding = 0
skip_speech_brain = 0
skip_pyannote_titanet_speakernet = 0
skip_audio_features = 0
skip_pyAudioAnalysis = 0
skip_librosa = 0
skip_image_guide = 0
skip_additional_attributes = 0
skip_age = 0
skip_gender = 0
skip_ethnicity = 0
skip_language_spoken = 0

[evaluate_imagen]
test_datasetpathfaces = /home/gamal/Datasets/Dataset1Test/FacesTest
test_datasetpathgeneratedfaces = /home/gamal/Datasets/Dataset1Test/GeneratedFacesTest
test_datasetpathfeatures = /home/gamal/Datasets/Dataset1Test/FeaturesTest
test_datasetpathguides = /home/gamal/Datasets/Dataset1Test/GuidesTest
time_to_wait_before_deleting_files = 180
audio_length_used = 24
model_filename = imagen_features_low_res_asis
openl3_mode_options = stable or imagen
openl3_mode = imagen
folder = imagen-test-folder
number_of_images = 2
boxBlurMin = 4
boxBlurMax = 14
gaussianBlurMin=2
gaussianBlurMax=6
pix_to_min = 8
pix_to_max = 16
ignore_age = 1
expandFaceVerticalRatio = 0.4
expandFaceHorizontalRatio=0.5
faceDetectionDeepFaceBackend=4
generated_face_table_name = audio_image_guide_only
skip_speaker_embedding = 0
skip_speech_brain = 0
skip_pyannote_titanet_speakernet = 0
skip_audio_features = 0
skip_pyAudioAnalysis = 0
skip_librosa = 0
skip_image_guide = 0
skip_additional_attributes = 0
skip_age = 0
skip_gender = 0
skip_ethnicity = 0
skip_language_spoken = 0
evaluation_results_folder = /home/gamal/Datasets/Dataset1Test

[extractVggBlurred]
dbChunk = 20
boxBlurMin = 4
boxBlurMax = 14
gaussianBlurMin=2
gaussianBlurMax=6
pix_to_min = 8
pix_to_max = 16

[extractAudioSpectogramTransformer]
datasetPathAudio = /home/gamal/Datasets/Dataset1/Audio
dbChunk = 240
time_to_wait_before_deleting_files = 60