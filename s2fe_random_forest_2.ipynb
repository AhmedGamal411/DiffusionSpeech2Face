{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLEASE EDIT configuration.txt BEFORE EXECUTION\n",
      ".wav files might be generated in path. The program will automatically delete them. If execuetion stops unexpectedly, please delete them yourself\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import pathlib\n",
    "import configparser\n",
    "import sqlite3 as sl\n",
    "import cv2\n",
    "from pydub import AudioSegment\n",
    "import math\n",
    "import pickle\n",
    "import shutil\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Process,Queue\n",
    "import itertools\n",
    "from threading import Thread\n",
    "\n",
    "start_time = time.time()    # To measure execution time in seconds\n",
    "\n",
    "\n",
    "print(\"PLEASE EDIT configuration.txt BEFORE EXECUTION\")\n",
    "print(\".wav files might be generated in path. The program will automatically delete them. If execuetion stops unexpectedly, please delete them yourself\")\n",
    "\n",
    "\n",
    "\n",
    "datasetPathVideo =  configParser.get('COMMON', 'datasetPathVideo')\n",
    "datasetPathAudio =  configParser.get('extractAudio', 'datasetPathAudio')\n",
    "p =  configParser.get('extractAudio', 'dbChunk')\n",
    "ttwbdf =  int(configParser.get('extractAudio', 'time_to_wait_before_deleting_files'))\n",
    "cuda =  int(configParser.get('COMMON', 'cuda'))\n",
    "cpus =  int(configParser.get('COMMON', 'cpus'))\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'datasetPathDatabase') + '/dataset.db'\n",
    "csv_folder =  configParser.get('train_s2fe_random_forest', 'csv_folder')\n",
    "model_path =  configParser.get('train_s2fe_random_forest', 'model_path')\n",
    "cpus_reg =  int(configParser.get('train_s2fe_random_forest', 'cpus_reg'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file no:1\n",
      "Loaded file no:2\n",
      "Loaded file no:3\n",
      "Loaded file no:4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "stacked_data_x = None\n",
    "stacked_data_y = None\n",
    "count_f = 0\n",
    "\n",
    "while(True):\n",
    "    count_f = count_f + 1\n",
    "    if(os.path.exists(csv_folder + \"/tree_reg_x\" + str(count_f) + \"_.csv\")):\n",
    "\n",
    "        \n",
    "        loaded_data_x = np.loadtxt(csv_folder + \"/tree_reg_x\" + str(count_f) + \"_.csv\", delimiter=\",\")\n",
    "        loaded_data_y = np.loadtxt(csv_folder + \"/tree_reg_y\" + str(count_f) + \"_.csv\", delimiter=\",\")\n",
    "\n",
    "        if(count_f <= 1):\n",
    "            stacked_data_x = np.copy(loaded_data_x)\n",
    "            stacked_data_y = np.copy(loaded_data_y)\n",
    "        else:\n",
    "            stacked_data_x = np.vstack([stacked_data_x,loaded_data_x])\n",
    "            stacked_data_y = np.vstack([stacked_data_y,loaded_data_y])\n",
    "\n",
    "\n",
    "        print('Loaded file no:' + str(count_f))\n",
    "    else:\n",
    "        break; \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(stacked_data_x, \n",
    "                                                    stacked_data_y, \n",
    "                                                    test_size=0.01, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    4.9s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.2s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.5s finished\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.5s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.8s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.8s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.8s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.7s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.8s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.7s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    5.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.3s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize and train the random forest regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=12, \n",
    "                                     n_jobs=cpus_reg, verbose =1, max_depth=4)\n",
    "#odel = MultiOutputRegressor(rf_regressor)\n",
    "#rf_regressor = RandomForestRegressor(verbose =1, max_depth=2)\n",
    "rf_regressor = MultiOutputRegressor(rf_regressor,n_jobs = cpus_reg)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "    \n",
    "        #tf.reset_default_graph()\n",
    "#for index,model in enumerate(cloned_models):\n",
    "#history_model = model.fit(train_dataset\n",
    "#                          , epochs=no_of_epochs,\n",
    "#                          callbacks=[model_checkpoint_callback],\n",
    "#                          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Serialize the object\n",
    "with open(model_path, 'wb') as outp:  # 'wb' for writing in binary mode\n",
    "    pickle.dump(rf_regressor, outp, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2622)\n",
      "(1, 2622)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2737355240.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    40 --> max=depth = 6 --> 5 GB -- > 10000 line --> 15 min\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "40 --> 1 tree -->max=depth = 6 --> 5 GB -- > 10000 line --> 15 min\n",
    "40 --> 2 tree -->max=depth = 6 --> 6 GB -- > 10000 line --> 3 min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
