{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 15:38:02.282446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-14 15:38:02.328710: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 training samples found at /media/gamal/Passport/Datasets/VoxCeleb2Test/Voxceleb2TestFaces\n",
      "training with dataset of 19 samples and validating with randomly splitted 1 samples\n",
      "0: vae loss: 0.7431672438979149 - discr loss: 326.45938301086426\n",
      "0: saving to /media/gamal/Passport/parti/vae\n",
      "0: saving model to /media/gamal/Passport/parti/vae\n",
      "1: vae loss: 0.3594689518213272 - discr loss: 325.36595916748047\n",
      "2: vae loss: 0.36097996681928635 - discr loss: 346.1001396179199\n",
      "3: vae loss: 0.2980678677558899 - discr loss: 286.59543800354004\n",
      "4: vae loss: 0.23920389637351036 - discr loss: 296.4740867614746\n",
      "5: vae loss: 0.20208706706762314 - discr loss: 286.3272705078125\n",
      "6: vae loss: 0.18509099073708057 - discr loss: 332.95605087280273\n",
      "7: vae loss: 0.1692269630730152 - discr loss: 319.2588348388672\n",
      "8: vae loss: 0.1595591902732849 - discr loss: 10.397484302520752\n",
      "9: vae loss: 0.15615341067314148 - discr loss: 8.281454503536224\n",
      "10: vae loss: 0.1521444097161293 - discr loss: 5.078916549682617\n",
      "10: saving to /media/gamal/Passport/parti/vae\n",
      "11: vae loss: 0.15080393850803375 - discr loss: 5.878942608833313\n",
      "12: vae loss: 0.1431125793606043 - discr loss: 3.901386171579361\n",
      "13: vae loss: 0.13910017255693674 - discr loss: 4.357588917016983\n",
      "14: vae loss: 0.13662532065063715 - discr loss: 2.9414561688899994\n",
      "15: vae loss: 0.13447427470237017 - discr loss: 2.6577956080436707\n",
      "16: vae loss: 0.12509786244481802 - discr loss: 3.6298272013664246\n",
      "17: vae loss: 0.12262397352606058 - discr loss: 2.2724785208702087\n",
      "18: vae loss: 0.1204857723787427 - discr loss: 2.9035086929798126\n",
      "19: vae loss: 0.11656784825026989 - discr loss: 2.565750479698181\n",
      "20: vae loss: 0.11669539846479893 - discr loss: 2.396539270877838\n",
      "20: saving to /media/gamal/Passport/parti/vae\n",
      "21: vae loss: 0.11129727866500616 - discr loss: 2.6454688906669617\n",
      "22: vae loss: 0.11373840924352407 - discr loss: 2.647933840751648\n",
      "23: vae loss: 0.1098293624818325 - discr loss: 2.4372575134038925\n",
      "24: vae loss: 0.10935323312878609 - discr loss: 2.6101120710372925\n",
      "25: vae loss: 0.101672881282866 - discr loss: 2.190504416823387\n",
      "26: vae loss: 0.10433838702738285 - discr loss: 2.405183330178261\n",
      "27: vae loss: 0.09897756576538086 - discr loss: 2.6170718669891357\n",
      "28: vae loss: 0.09376468323171139 - discr loss: 2.3026425540447235\n",
      "29: vae loss: 0.09550635237246752 - discr loss: 2.2803532630205154\n",
      "30: vae loss: 0.09501411207020283 - discr loss: 2.318414717912674\n",
      "30: saving to /media/gamal/Passport/parti/vae\n",
      "31: vae loss: 0.08551261015236378 - discr loss: 2.405729591846466\n",
      "32: vae loss: 0.0895089190453291 - discr loss: 2.7275690883398056\n",
      "33: vae loss: 0.08659481629729271 - discr loss: 3.0107680559158325\n",
      "34: vae loss: 0.08157318457961082 - discr loss: 2.8185553550720215\n",
      "35: vae loss: 0.08317933138459921 - discr loss: 2.344689905643463\n",
      "36: vae loss: 0.08082290645688772 - discr loss: 2.682093620300293\n",
      "37: vae loss: 0.07909663207828999 - discr loss: 2.415706515312195\n",
      "38: vae loss: 0.07910212222486734 - discr loss: 2.435356318950653\n",
      "39: vae loss: 0.07253433018922806 - discr loss: 2.4213986992836\n",
      "40: vae loss: 0.07103349547833204 - discr loss: 2.4883820712566376\n",
      "40: saving to /media/gamal/Passport/parti/vae\n",
      "41: vae loss: 0.07571159675717354 - discr loss: 2.169025808572769\n",
      "42: vae loss: 0.07140070851892233 - discr loss: 3.9728893041610718\n",
      "43: vae loss: 0.07124519255012274 - discr loss: 4.81898894906044\n",
      "44: vae loss: 0.06732452195137739 - discr loss: 3.5763661563396454\n",
      "45: vae loss: 0.07308505848050117 - discr loss: 6.865116655826569\n",
      "46: vae loss: 0.061936660669744015 - discr loss: 5.768442690372467\n",
      "47: vae loss: 0.07632939144968987 - discr loss: 6.475362122058868\n",
      "48: vae loss: 0.06612802855670452 - discr loss: 3.632714092731476\n",
      "49: vae loss: 0.06318295281380415 - discr loss: 6.618801772594452\n",
      "50: vae loss: 0.06237793620675802 - discr loss: 2.909864515066147\n",
      "50: saving to /media/gamal/Passport/parti/vae\n",
      "50: saving model to /media/gamal/Passport/parti/vae\n",
      "51: vae loss: 0.06395762972533703 - discr loss: 4.3465434312820435\n",
      "52: vae loss: 0.06409652251750231 - discr loss: 4.023047864437103\n",
      "53: vae loss: 0.055271316319704056 - discr loss: 3.2748162746429443\n",
      "54: vae loss: 0.06260993890464306 - discr loss: 3.638273686170578\n",
      "55: vae loss: 0.050282228738069534 - discr loss: 3.695304423570633\n",
      "56: vae loss: 0.05185614340007305 - discr loss: 3.27409628033638\n",
      "57: vae loss: 0.05204999912530184 - discr loss: 2.7317472100257874\n",
      "58: vae loss: 0.056110153906047344 - discr loss: 2.9614870250225067\n",
      "59: vae loss: 0.05182952154427767 - discr loss: 2.824810177087784\n",
      "60: vae loss: 0.048294439911842346 - discr loss: 3.037638545036316\n",
      "60: saving to /media/gamal/Passport/parti/vae\n",
      "61: vae loss: 0.046715266071259975 - discr loss: 2.48453426361084\n",
      "62: vae loss: 0.05024345498532057 - discr loss: 3.0253540873527527\n",
      "63: vae loss: 0.04863952472805977 - discr loss: 2.744075119495392\n",
      "64: vae loss: 0.04135502316057682 - discr loss: 2.4337244033813477\n",
      "65: vae loss: 0.03857589326798916 - discr loss: 2.487588733434677\n",
      "66: vae loss: 0.04961469303816557 - discr loss: 2.535010516643524\n",
      "67: vae loss: 0.04335006978362799 - discr loss: 2.5232175290584564\n",
      "68: vae loss: 0.039147939532995224 - discr loss: 2.5185563266277313\n",
      "69: vae loss: 0.043127574026584625 - discr loss: 2.2401610910892487\n",
      "70: vae loss: 0.03979628626257181 - discr loss: 2.358963668346405\n",
      "70: saving to /media/gamal/Passport/parti/vae\n",
      "71: vae loss: 0.035922431387007236 - discr loss: 2.2520068883895874\n",
      "72: vae loss: 0.03918931353837252 - discr loss: 2.372024655342102\n",
      "73: vae loss: 0.03878369741141796 - discr loss: 2.2752286195755005\n",
      "74: vae loss: 0.032004005275666714 - discr loss: 2.3608171939849854\n",
      "75: vae loss: 0.03141751419752836 - discr loss: 2.2998115718364716\n",
      "76: vae loss: 0.028479318134486675 - discr loss: 2.2252413630485535\n",
      "77: vae loss: 0.026943362317979336 - discr loss: 2.2500343918800354\n",
      "78: vae loss: 0.030012675561010838 - discr loss: 2.2068779170513153\n",
      "79: vae loss: 0.030012385919690132 - discr loss: 2.2295462489128113\n",
      "80: vae loss: 0.03704275004565716 - discr loss: 2.4508115649223328\n",
      "80: saving to /media/gamal/Passport/parti/vae\n",
      "81: vae loss: 0.043626775965094566 - discr loss: 2.3159144520759583\n",
      "82: vae loss: 0.0384151479229331 - discr loss: 2.1473058313131332\n",
      "83: vae loss: 0.026593349874019623 - discr loss: 2.2678072303533554\n",
      "84: vae loss: 0.023727109655737877 - discr loss: 2.6904584169387817\n",
      "85: vae loss: 0.030708542093634605 - discr loss: 2.7789779007434845\n",
      "86: vae loss: 0.026408839970827103 - discr loss: 2.308411866426468\n",
      "87: vae loss: 0.02218400314450264 - discr loss: 2.487254649400711\n",
      "88: vae loss: 0.026208198629319668 - discr loss: 2.880373030900955\n",
      "89: vae loss: 0.03875025175511837 - discr loss: 2.473637104034424\n",
      "90: vae loss: 0.02764235343784094 - discr loss: 2.14762219786644\n",
      "90: saving to /media/gamal/Passport/parti/vae\n",
      "91: vae loss: 0.018242652527987957 - discr loss: 2.2835017442703247\n",
      "92: vae loss: 0.019055054523050785 - discr loss: 2.07193261384964\n",
      "93: vae loss: 0.023206637240946293 - discr loss: 2.136322647333145\n",
      "94: vae loss: 0.027000758796930313 - discr loss: 2.1648639738559723\n",
      "95: vae loss: 0.018199553713202477 - discr loss: 2.1139840185642242\n",
      "96: vae loss: 0.022482928819954395 - discr loss: 2.0552951842546463\n",
      "97: vae loss: 0.025416399352252483 - discr loss: 2.072652503848076\n",
      "98: vae loss: 0.015991627238690853 - discr loss: 2.077718496322632\n",
      "99: vae loss: 0.0174335865303874 - discr loss: 2.07885979115963\n",
      "100: vae loss: 0.02221537008881569 - discr loss: 2.0925439596176147\n",
      "100: saving to /media/gamal/Passport/parti/vae\n",
      "100: saving model to /media/gamal/Passport/parti/vae\n",
      "101: vae loss: 0.015963527373969555 - discr loss: 2.223903611302376\n",
      "102: vae loss: 0.018747791647911072 - discr loss: 2.7495362162590027\n",
      "103: vae loss: 0.020249726250767708 - discr loss: 2.1248307526111603\n",
      "104: vae loss: 0.015283290296792984 - discr loss: 2.2365362346172333\n",
      "105: vae loss: 0.015765270218253136 - discr loss: 2.7012484073638916\n",
      "106: vae loss: 0.01935072150081396 - discr loss: 2.228418469429016\n",
      "107: vae loss: 0.015858364291489124 - discr loss: 2.1126475781202316\n",
      "108: vae loss: 0.012052127160131931 - discr loss: 2.221849709749222\n",
      "109: vae loss: 0.01503911055624485 - discr loss: 2.1213295310735703\n",
      "110: vae loss: 0.018446083180606365 - discr loss: 2.150937795639038\n",
      "110: saving to /media/gamal/Passport/parti/vae\n",
      "111: vae loss: 0.011132371611893177 - discr loss: 2.073619782924652\n",
      "112: vae loss: 0.010682708583772182 - discr loss: 2.0179901719093323\n",
      "113: vae loss: 0.01270996779203415 - discr loss: 2.129688322544098\n",
      "114: vae loss: 0.017207391560077667 - discr loss: 2.1365318596363068\n",
      "115: vae loss: 0.006712339818477631 - discr loss: 2.0352803617715836\n",
      "116: vae loss: 0.00787760503590107 - discr loss: 2.16977521777153\n",
      "117: vae loss: 0.011931540444493294 - discr loss: 2.1775603890419006\n",
      "118: vae loss: 0.0068683503195643425 - discr loss: 2.086540475487709\n",
      "119: vae loss: 0.009197563864290714 - discr loss: 2.201064348220825\n",
      "120: vae loss: 0.010732201859354973 - discr loss: 2.0277897715568542\n",
      "120: saving to /media/gamal/Passport/parti/vae\n",
      "121: vae loss: 0.007724253460764885 - discr loss: 2.0564313530921936\n",
      "122: vae loss: 0.005613972432911396 - discr loss: 2.0133571475744247\n",
      "123: vae loss: 0.007016421295702457 - discr loss: 2.0635453164577484\n",
      "124: vae loss: 0.009350260719656944 - discr loss: 2.008170783519745\n",
      "125: vae loss: 0.008559980429708958 - discr loss: 2.0746079683303833\n",
      "126: vae loss: 0.006081056781113148 - discr loss: 2.0373128801584244\n",
      "127: vae loss: 0.004828786477446556 - discr loss: 2.0547134578227997\n",
      "128: vae loss: 0.005937147885560989 - discr loss: 2.017814576625824\n",
      "129: vae loss: 0.003924659453332424 - discr loss: 2.0622381567955017\n",
      "130: vae loss: 0.005168902687728405 - discr loss: 2.035861998796463\n",
      "130: saving to /media/gamal/Passport/parti/vae\n",
      "131: vae loss: 0.003342956304550171 - discr loss: 2.0272610634565353\n",
      "132: vae loss: 0.0030176639556884766 - discr loss: 2.0363239347934723\n",
      "133: vae loss: 0.002502918243408203 - discr loss: 2.033526360988617\n",
      "134: vae loss: 0.004909135401248932 - discr loss: 2.0335609912872314\n",
      "135: vae loss: 0.0051431963220238686 - discr loss: 1.9973773807287216\n",
      "136: vae loss: 0.00824855174869299 - discr loss: 2.022503435611725\n",
      "137: vae loss: 0.009516208432614803 - discr loss: 2.0010074079036713\n",
      "138: vae loss: 0.007167579606175423 - discr loss: 2.008460193872452\n",
      "139: vae loss: 0.0020691677927970886 - discr loss: 2.004935771226883\n",
      "140: vae loss: 0.0009741261601448059 - discr loss: 1.9711219370365143\n",
      "140: saving to /media/gamal/Passport/parti/vae\n",
      "141: vae loss: 0.005993009544909 - discr loss: 2.003379136323929\n",
      "142: vae loss: 0.009394265711307526 - discr loss: 1.9757421761751175\n",
      "143: vae loss: 0.003936869092285633 - discr loss: 1.9944111108779907\n",
      "144: vae loss: 0.0014490196481347084 - discr loss: 2.0174993574619293\n",
      "145: vae loss: 0.001702621579170227 - discr loss: 2.0091429501771927\n",
      "146: vae loss: 0.002104641869664192 - discr loss: 2.007045239210129\n",
      "147: vae loss: 0.003502846695482731 - discr loss: 2.013665124773979\n",
      "148: vae loss: -0.0018337331712245941 - discr loss: 1.9958183467388153\n",
      "149: vae loss: -0.003723052330315113 - discr loss: 2.002409905195236\n",
      "150: vae loss: -0.0006903675384819508 - discr loss: 1.9943019449710846\n",
      "150: saving to /media/gamal/Passport/parti/vae\n",
      "150: saving model to /media/gamal/Passport/parti/vae\n",
      "151: vae loss: -0.0016183080151677132 - discr loss: 1.9961206763982773\n",
      "152: vae loss: -0.0037535205483436584 - discr loss: 1.985931545495987\n",
      "153: vae loss: -0.0021890075877308846 - discr loss: 1.998056560754776\n",
      "154: vae loss: -0.001868443563580513 - discr loss: 1.9843096882104874\n",
      "155: vae loss: -0.0009061843156814575 - discr loss: 1.9789758324623108\n",
      "156: vae loss: -0.001616201363503933 - discr loss: 1.9912171810865402\n",
      "157: vae loss: -0.0022756168618798256 - discr loss: 1.9817547351121902\n",
      "158: vae loss: -0.003007791005074978 - discr loss: 1.9847461581230164\n",
      "159: vae loss: -0.0007358528673648834 - discr loss: 2.0088951140642166\n",
      "160: vae loss: 0.007895484566688538 - discr loss: 1.986821711063385\n",
      "160: saving to /media/gamal/Passport/parti/vae\n",
      "161: vae loss: 0.011306710541248322 - discr loss: 2.0065330415964127\n",
      "162: vae loss: 0.007181787863373756 - discr loss: 1.9906388521194458\n",
      "163: vae loss: -0.0008702371269464493 - discr loss: 2.0065703094005585\n",
      "164: vae loss: -0.0024364935234189034 - discr loss: 1.9992950409650803\n",
      "165: vae loss: -0.004110528156161308 - discr loss: 1.9751681685447693\n",
      "166: vae loss: 0.004155835136771202 - discr loss: 2.0054596662521362\n",
      "167: vae loss: 0.004910497926175594 - discr loss: 1.995186060667038\n",
      "168: vae loss: -0.005401323549449444 - discr loss: 1.9899137765169144\n",
      "169: vae loss: -6.0492195188999176e-05 - discr loss: 1.9934535324573517\n",
      "170: vae loss: 0.004367740824818611 - discr loss: 2.0108784437179565\n",
      "170: saving to /media/gamal/Passport/parti/vae\n",
      "171: vae loss: 0.0006681391969323158 - discr loss: 1.9968251734972\n",
      "172: vae loss: -0.003725099377334118 - discr loss: 1.996606007218361\n",
      "173: vae loss: 0.001476670615375042 - discr loss: 1.9876661151647568\n",
      "174: vae loss: -0.0016872351989150047 - discr loss: 1.981666848063469\n",
      "175: vae loss: -0.0045884111896157265 - discr loss: 1.9890927374362946\n",
      "176: vae loss: -0.0033011557534337044 - discr loss: 1.9845740348100662\n",
      "177: vae loss: -0.006361331790685654 - discr loss: 1.9988660216331482\n",
      "178: vae loss: -0.004406298045068979 - discr loss: 1.9882184118032455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>save_model_every = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">50</span>,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span>)                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>34 trainer.train()                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/parti_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">vit_vqgan_trainer.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">275</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>device = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.vae.parameters()).device                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">274 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.steps &lt; <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_train_steps:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>275 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>logs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_step()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>log_fn(logs)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'training complete'</span>)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/parti_pytorch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">vit_vqgan_trainer.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">216</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_step</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> autocast(enabled = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.amp):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.vae(img, return_discr_loss = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>216 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.discr_scaler.scale(loss / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.grad_accum_every).backward()       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">217 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>accum_log(logs, {<span style=\"color: #808000; text-decoration-color: #808000\">'discr_loss'</span>: loss.item() / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.grad_accum_every})       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m34\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   \u001b[0msave_model_every = \u001b[94m50\u001b[0m,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m)                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m34 trainer.train()                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/parti_pytorch/\u001b[0m\u001b[1;33mvit_vqgan_trainer.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m275\u001b[0m in \u001b[92mtrain\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m│   │   \u001b[0mdevice = \u001b[96mnext\u001b[0m(\u001b[96mself\u001b[0m.vae.parameters()).device                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m274 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[96mself\u001b[0m.steps < \u001b[96mself\u001b[0m.num_train_steps:                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m275 \u001b[2m│   │   │   \u001b[0mlogs = \u001b[96mself\u001b[0m.train_step()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   │   \u001b[0mlog_fn(logs)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mtraining complete\u001b[0m\u001b[33m'\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/parti_pytorch/\u001b[0m\u001b[1;33mvit_vqgan_trainer.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m216\u001b[0m in \u001b[92mtrain_step\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m autocast(enabled = \u001b[96mself\u001b[0m.amp):                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.vae(img, return_discr_loss = \u001b[94mTrue\u001b[0m)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m216 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.discr_scaler.scale(loss / \u001b[96mself\u001b[0m.grad_accum_every).backward()       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m217 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   │   │   \u001b[0maccum_log(logs, {\u001b[33m'\u001b[0m\u001b[33mdiscr_loss\u001b[0m\u001b[33m'\u001b[0m: loss.item() / \u001b[96mself\u001b[0m.grad_accum_every})       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m219 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mbackward\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from parti_pytorch import VitVQGanVAE, VQGanVAETrainer\n",
    "\n",
    "\n",
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "datasetPathVideo =  configParser.get('COMMON', 'datasetPathVideo')\n",
    "\n",
    "vit_vae = VitVQGanVAE(\n",
    "    dim = 256,               # dimensions\n",
    "    image_size = 128,        # target image size\n",
    "    patch_size = 256,         # size of the patches in the image attending to each other\n",
    "    num_layers = 3           # number of layers\n",
    ").cuda()\n",
    "\n",
    "\n",
    "trainer = VQGanVAETrainer(\n",
    "    vit_vae,\n",
    "    folder = '/media/gamal/Passport/Datasets/VoxCeleb2Test/Voxceleb2TestFaces',\n",
    "    num_train_steps = 100000,\n",
    "    lr = 3e-4,\n",
    "    batch_size = 4,\n",
    "    grad_accum_every = 8,\n",
    "    amp = True,\n",
    "    results_folder = '/media/gamal/Passport/parti/vae',\n",
    "    save_results_every = 10,\n",
    "    save_model_every = 50,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
