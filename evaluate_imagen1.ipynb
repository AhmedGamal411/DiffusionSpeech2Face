{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n",
    "    \n",
    "#import os\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "\n",
    "datasetPathVideo =  configParser.get('COMMON', 'test_datasetPathVideo')\n",
    "datasetPathFaces =  configParser.get('evaluate_imagen', 'test_datasetPathFaces')\n",
    "datasetPathFeatures =  configParser.get('evaluate_imagen', 'test_datasetPathFeatures')\n",
    "datasetPathGuides =  configParser.get('evaluate_imagen', 'test_datasetPathGuides')\n",
    "\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'test_datasetPathDatabase') + '/dataset.db'\n",
    "\n",
    "ttwbdf =  int(configParser.get('evaluate_imagen', 'time_to_wait_before_deleting_files'))\n",
    "\n",
    "\n",
    "cuda =  int(configParser.get('COMMON', 'cuda'))\n",
    "cpus =  int(configParser.get('COMMON', 'cpus'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO document jupyter\n",
    "import pickle\n",
    "import sqlite3 as sl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from textwrap import wrap\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = output_folder = r'imagen_testing_folder' \n",
    "if not os.path.exists(audio_folder):\n",
    "    os.makedirs(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =  int(configParser.get('COMMON', 'resizeImageTo'))\n",
    "audio_length_used =  configParser.get('evaluate_imagen', 'audio_length_used') \n",
    "model_filename =  configParser.get('evaluate_imagen', 'model_filename') + '_'  + audio_length_used +  's.pt'\n",
    "openl3_mode =  configParser.get('evaluate_imagen', 'openl3_mode')\n",
    "folder =  configParser.get('evaluate_imagen', 'folder')\n",
    "number_of_images =  configParser.get('evaluate_imagen', 'number_of_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boxBlurMin =  int(configParser.get('evaluate_imagen', 'boxBlurMin'))\n",
    "boxBlurMax =  int(configParser.get('evaluate_imagen', 'boxBlurMax'))\n",
    "\n",
    "gaussianBlurMin =  int(configParser.get('evaluate_imagen', 'gaussianBlurMin'))\n",
    "gaussianBlurMax =  int(configParser.get('evaluate_imagen', 'gaussianBlurMax'))\n",
    "\n",
    "pix_to_min =  int(configParser.get('evaluate_imagen', 'pix_to_min'))\n",
    "pix_to_max =  int(configParser.get('evaluate_imagen', 'pix_to_max'))\n",
    "\n",
    "fddfb =  int(configParser.get('evaluate_imagen', 'faceDetectionDeepFaceBackend'))\n",
    "efvr =  float(configParser.get('evaluate_imagen', 'expandFaceVerticalRatio'))\n",
    "efhr =  float(configParser.get('evaluate_imagen', 'expandFaceHorizontalRatio'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "uri = datasetPathDatabase\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "table = db.open_table(\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing_imagen_speechbrain import extract_speechbrain_embeddings\n",
    "from testing_imagen_pyannote_titanet import extract_pyannote_titanet_embeddings\n",
    "from testing_imagen_audio_features import extract_audio_features\n",
    "from testing_imagen_vision_transformer import extract_vision_transformer\n",
    "from testing_imagen_face import extract_face\n",
    "import pathlib\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i = 0\n",
    "for index, row in table.to_pandas().iterrows():\n",
    "    video_path = absPathVideo = row['video_path']\n",
    "\n",
    "\n",
    "    # EXTRACT FACE, AGE, GENDER, ETHNICITY, FACE EMBEDDING\n",
    "    absPathFace = absPathVideo.replace(datasetPathVideo,datasetPathFaces)\n",
    "    absPathFace = os.path.splitext(absPathFace)[0]\n",
    "    absPathFace = absPathFace + \"_face_\" + str(1) + \".png\"\n",
    "    #print(absPathFace)\n",
    "    #Create Directory\n",
    "    pathlib.Path(os.path.dirname(absPathFace)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "    \n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    proc = multiprocessing.Process(target=extract_face, args=(q,absPathVideo,\n",
    "                                                             image_size,\n",
    "                                                             fddfb,\n",
    "                                                             output_folder,\n",
    "                                                             efvr,efhr,))\n",
    "    proc.start()\n",
    "    proc.join()\n",
    "\n",
    "    shutil.copy2(output_folder + \"/\" + \"face.png\", \n",
    "                 absPathFace) # complete target filename given\n",
    "    \n",
    "    image_guide_path = output_folder + \"/\" + \"face.png\"\n",
    "\n",
    "    gender = q.get()\n",
    "    if(gender == 'Error'):\n",
    "        continue\n",
    "    ethnicity = q.get()\n",
    "    if(ethnicity == 'Error'):\n",
    "        continue\n",
    "    age = q.get()\n",
    "    if(age == 'Error'):\n",
    "        continue\n",
    "\n",
    "\n",
    "    with open(output_folder + '/' + 'vgg.pickle', 'rb') as handle:\n",
    "        vgg = pickle.load(handle)\n",
    "        #print(\"++++++\" + str(vgg))\n",
    "\n",
    "\n",
    "\n",
    "    dataGotten = [['1','1',video_path,'age','ethnicity','gender',[],[],[],'language',[]]]\n",
    "    df = pd.DataFrame(dataGotten,columns = ['ID','FACE_ID','VIDEO_PATH','caption_a','caption_e','caption_g','SPEAKER_EMB','AUDIO_EMB','AUDIO_FEATURES','caption_l','image_path'])\n",
    "    df[\"image_guide\"] = np.nan\n",
    "\n",
    "    df[\"caption_e\"] = ethnicity\n",
    "    df[\"caption_g\"] = gender\n",
    "    df[\"caption_a\"] = age\n",
    "\n",
    "    print(\"age :--------------\"  + str(age))\n",
    "    print(\"gender :--------------\"  + str(gender))\n",
    "    print(\"ethnicity :--------------\"  + str(ethnicity))\n",
    "\n",
    "    q.empty()\n",
    "\n",
    "    #gpus\n",
    "    import pickle\n",
    "\n",
    "\n",
    "\n",
    "    # EXTRACT SPEAKER EMBEDDINGS, AUDIO FEATURES AND LANGUAGE\n",
    "\n",
    "    audio_embs =  configParser.get('COMMON', 'audio_embs') \n",
    "    from pydub import AudioSegment\n",
    "    import math\n",
    "    # Get original duration of video\n",
    "    audio = AudioSegment.from_file(video_path)\n",
    "    audio_length_og = math.floor(audio.duration_seconds)\n",
    "\n",
    "\n",
    "    video_filename = os.path.basename(video_path)\n",
    "\n",
    "    absPathAudio_w = os.path.abspath(audio_folder) + \"/\" + video_filename\n",
    "    absPathAudio = os.path.splitext(absPathAudio_w)[0]+'_audio.wav'\n",
    "    absPathAudio_w = os.path.splitext(absPathAudio_w)[0]\n",
    "\n",
    "\n",
    "    import subprocess\n",
    "    # Extract audio monochannel and with 16khz and put it in absPathAudio\n",
    "\n",
    "    command = \"ffmpeg -nostats -loglevel 0 -y -i '\" + video_path + \"' -acodec pcm_s16le -ab 160k -ac 1 -ar 16000 -vn '\" + absPathAudio  + \"'\"\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    from threading import Thread\n",
    "    import time\n",
    "\n",
    "    # Function to delete audio temp files\n",
    "    def delFiles(filesToDelete):\n",
    "        time.sleep(ttwbdf)  # wait a bit\n",
    "        for file in filesToDelete:  \n",
    "            try:\n",
    "                os.remove(file)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "\n",
    "    # Will either truncate or loop the original video to reach audio_length (6,12 or 24)\n",
    "    audio_length_list = [24]\n",
    "    for audio_length in audio_length_list:\n",
    "        path_var_len_audio =  absPathAudio_w + \"audio\" + str(audio_length) + \"s.wav\"    # path to the variable length audio\n",
    "        path_var_len_audio_temp =  absPathAudio_w + \"audio_temp\" + str(audio_length) + \"s.wav\"  # path to a temp version of the variable length audio\n",
    "\n",
    "        if(audio_length_og > audio_length):\n",
    "            # Truncate    \n",
    "\n",
    "            command = \"ffmpeg -nostats -loglevel 0 -y -ss 0 -t \"+str(audio_length)+\" -i \\\"\" + absPathAudio + \"\\\" \\\"\" + path_var_len_audio + \"\\\"\"\n",
    "            subprocess.call(command, shell=True)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Loop then truncaate\n",
    "            #print(\"lesa\")\n",
    "            twoDigitLenStr = f\"{audio_length:02}\"\n",
    "            #print(twoDigitLenStr)\n",
    "            command = \"ffmpeg -nostats -loglevel 0 -y -stream_loop -1 -i '\" + absPathAudio + \"' -t \\\"00:00:\"+twoDigitLenStr+\".000\\\" -codec:a \\\"aac\\\" -f \\\"wav\\\" -c copy '\"+ path_var_len_audio_temp + \"'\"\n",
    "            subprocess.call(command, shell=True)\n",
    "            command = \"ffmpeg -nostats -loglevel 0 -y -ss 0 -t \"+str(audio_length)+\" -i \\\"\" + path_var_len_audio_temp + \"\\\" \\\"\" + path_var_len_audio + \"\\\"\"\n",
    "            subprocess.call(command, shell=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        proc = multiprocessing.Process(target=extract_speechbrain_embeddings, args=(q,path_var_len_audio,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        df['SPEAKER_EMB'] = q.get()\n",
    "        df['caption_l'] = q.get()\n",
    "        print(df['caption_l'])\n",
    "\n",
    "\n",
    "        proc = multiprocessing.Process(target=extract_pyannote_titanet_embeddings, args=(q,path_var_len_audio,audio_embs,audio_length,openl3_mode,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "        df['AUDIO_EMB'] = q.get()\n",
    "\n",
    "        proc = multiprocessing.Process(target=extract_audio_features, args=(q,path_var_len_audio,output_folder,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "\n",
    "\n",
    "        with open(output_folder + '/' + 'audio_features.pickle', 'rb') as handle:\n",
    "            df['AUDIO_FEATURES'] = pickle.load(handle)\n",
    "\n",
    "        ftd = [absPathAudio,path_var_len_audio,os.path.basename(path_var_len_audio),path_var_len_audio_temp]\n",
    "        tDelete = Thread(target=delFiles, args=(ftd,))   # spawn a process\n",
    "        tDelete.start()\n",
    "\n",
    "    proc = multiprocessing.Process(target=extract_vision_transformer, args=(q,output_folder,\n",
    "                                                                            image_guide_path,1,\n",
    "                                                                            image_size,\n",
    "        boxBlurMin,boxBlurMax,gaussianBlurMin,gaussianBlurMax,pix_to_min,pix_to_max,))\n",
    "    proc.start()\n",
    "    proc.join()\n",
    "\n",
    "\n",
    "\n",
    "    with open(output_folder + '/' + 'image_features.pickle', 'rb') as handle:\n",
    "        df[\"image_guide\"] = pickle.load(handle)\n",
    "\n",
    "\n",
    "    absPathGuide = absPathVideo.replace(datasetPathVideo,datasetPathGuides)\n",
    "    absPathGuide = os.path.splitext(absPathGuide)[0]\n",
    "    absPathGuide = absPathGuide + \"_guide_\"+ \".png\"\n",
    "    #print(absPathFace)\n",
    "    #Create Directory\n",
    "    pathlib.Path(os.path.dirname(absPathGuide)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "    shutil.copy2(output_folder + \"/\" + \"guide.png\", absPathGuide) # complete target filename given\n",
    "\n",
    "\n",
    "    df3 = df[[\"image_path\",\"caption_a\",\"caption_e\",\"caption_g\",\"caption_l\"]]\n",
    "    data_frame = df3\n",
    "    data_frame['SPEAKER_EMB'] = df['SPEAKER_EMB']\n",
    "    data_frame['AUDIO_EMB'] = df['AUDIO_EMB']\n",
    "    data_frame['AUDIO_FEATURES'] = df['AUDIO_FEATURES']\n",
    "    data_frame['image_guide'] = df['image_guide']\n",
    "\n",
    "    import pickle\n",
    "\n",
    "\n",
    "    with open(output_folder + '/' + 'filename.pickle', 'wb') as handle:\n",
    "        pickle.dump(data_frame, handle)\n",
    "\n",
    "\n",
    "    absPathFeatures = absPathVideo.replace(datasetPathVideo,datasetPathFeatures)\n",
    "    absPathFeatures = os.path.splitext(absPathFeatures)[0]\n",
    "    absPathFeatures = absPathFeatures + \"_features_\"+ \".pickle\"\n",
    "    #print(absPathFace)\n",
    "    #Create Directory\n",
    "    pathlib.Path(os.path.dirname(absPathFeatures)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "    shutil.copy2(output_folder + \"/\" + \"filename.pickle\", absPathFeatures) # complete target filename given\n",
    "\n",
    "    #data_frame.loc[index,\"features_path\"] = output_folder + '/' + 'filename.pickle'\n",
    "\n",
    "    \n",
    "    df_table = df_table.append({'id': int(row['id']), 'video_path': row['video_path'], \n",
    "                    'face_path': absPathFace, \n",
    "        'blurred_face_path': absPathGuide, 'features_path': absPathFeatures, \n",
    "        'vector' : vgg,'stage': 1}, ignore_index=True)\n",
    "\n",
    "    i = i + 1\n",
    "    if(i == 2):\n",
    "        break\n",
    "\n",
    "shutil.rmtree(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table('video')\n",
    "db.create_table(\"video\", df_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = db.open_table(\"video\")\n",
    "tbl.search(np.random.rand(2622)).limit(2).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78dccc615e96ab04385280185a87a524fe0822daf5dbad2f4bf2e7d7b28366a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
