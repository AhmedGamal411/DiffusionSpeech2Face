{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n",
    "    \n",
    "#import os\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "#os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "\n",
    "datasetPathVideo =  configParser.get('COMMON', 'test_datasetPathVideo')\n",
    "datasetPathFaces =  configParser.get('evaluate_imagen', 'test_datasetPathFaces')\n",
    "datasetPathFeatures =  configParser.get('evaluate_imagen', 'test_datasetPathFeatures')\n",
    "datasetPathGuides =  configParser.get('evaluate_imagen', 'test_datasetPathGuides')\n",
    "\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'test_datasetPathDatabase') + '/dataset.db'\n",
    "\n",
    "ttwbdf =  int(configParser.get('evaluate_imagen', 'time_to_wait_before_deleting_files'))\n",
    "\n",
    "\n",
    "cuda =  int(configParser.get('COMMON', 'cuda'))\n",
    "cpus =  int(configParser.get('COMMON', 'cpus'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO document jupyter\n",
    "import pickle\n",
    "import sqlite3 as sl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from textwrap import wrap\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = output_folder = r'imagen_testing_folder' \n",
    "if not os.path.exists(audio_folder):\n",
    "    os.makedirs(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size =  int(configParser.get('COMMON', 'resizeImageTo'))\n",
    "begin_with_image_size = int(configParser.get('COMMON', 'begin_with_image_size'))\n",
    "timesteps= int(configParser.get('COMMON', 'timesteps') )\n",
    "audio_length_used =  configParser.get('evaluate_imagen', 'audio_length_used') \n",
    "model_filename =  configParser.get('evaluate_imagen', 'model_filename') + '_'  + audio_length_used +  's.pt'\n",
    "openl3_mode =  configParser.get('evaluate_imagen', 'openl3_mode')\n",
    "folder =  configParser.get('evaluate_imagen', 'folder')\n",
    "number_of_images =  configParser.get('evaluate_imagen', 'number_of_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "boxBlurMin =  int(configParser.get('evaluate_imagen', 'boxBlurMin'))\n",
    "boxBlurMax =  int(configParser.get('evaluate_imagen', 'boxBlurMax'))\n",
    "\n",
    "gaussianBlurMin =  int(configParser.get('evaluate_imagen', 'gaussianBlurMin'))\n",
    "gaussianBlurMax =  int(configParser.get('evaluate_imagen', 'gaussianBlurMax'))\n",
    "\n",
    "pix_to_min =  int(configParser.get('evaluate_imagen', 'pix_to_min'))\n",
    "pix_to_max =  int(configParser.get('evaluate_imagen', 'pix_to_max'))\n",
    "\n",
    "fddfb =  int(configParser.get('evaluate_imagen', 'faceDetectionDeepFaceBackend'))\n",
    "efvr =  float(configParser.get('evaluate_imagen', 'expandFaceVerticalRatio'))\n",
    "efhr =  float(configParser.get('evaluate_imagen', 'expandFaceHorizontalRatio'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "uri = datasetPathDatabase\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "table = db.open_table(\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>face_path</th>\n",
       "      <th>user</th>\n",
       "      <th>blurred_face_path</th>\n",
       "      <th>features_path</th>\n",
       "      <th>vector</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.065377645]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00001</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.25357106]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00006</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.3160929]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00008</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.68535125]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00010</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.28327712]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00012</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.6307946]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.32150412]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.17822036]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00004</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.9230645]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00007</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.70353085]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>None</td>\n",
       "      <td>id00003</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.91743106]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                         video_path face_path     user  \\\n",
       "0    0  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00002   \n",
       "1    1  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00001   \n",
       "2    2  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00006   \n",
       "3    3  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00008   \n",
       "4    4  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00010   \n",
       "5    5  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00012   \n",
       "6    6  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00009   \n",
       "7    7  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00005   \n",
       "8    8  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00004   \n",
       "10  10  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00007   \n",
       "11  11  /home/gamal/Datasets/Dataset1Test/VideoTest/id...      None  id00003   \n",
       "\n",
       "   blurred_face_path features_path         vector stage  \n",
       "0               None          None  [0.065377645]  None  \n",
       "1               None          None   [0.25357106]  None  \n",
       "2               None          None    [0.3160929]  None  \n",
       "3               None          None   [0.68535125]  None  \n",
       "4               None          None   [0.28327712]  None  \n",
       "5               None          None    [0.6307946]  None  \n",
       "6               None          None   [0.32150412]  None  \n",
       "7               None          None   [0.17822036]  None  \n",
       "8               None          None    [0.9230645]  None  \n",
       "10              None          None   [0.70353085]  None  \n",
       "11              None          None   [0.91743106]  None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_unique_users = videos.drop_duplicates('user', keep='first')\n",
    "videos_unique_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  db.drop_table(\"video_stage1\")\n",
    "except:\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 22:56:01.389164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[NeMo W 2023-10-06 22:56:05 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 22:56:05 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "from testing_imagen_speechbrain import extract_speechbrain_embeddings\n",
    "from testing_imagen_pyannote_titanet import extract_pyannote_titanet_embeddings\n",
    "from testing_imagen_audio_features import extract_audio_features\n",
    "from testing_imagen_vision_transformer import extract_vision_transformer\n",
    "from testing_imagen_face import extract_face\n",
    "import pathlib\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------36\n",
      "gender :--------------Man\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    English\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:56:34 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 22:56:34 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:56:36 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 22:56:36 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:56:36 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 22:56:37 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 22:56:37 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 22:56:37 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 22:56:37 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 22:56:37 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:56:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 22:56:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:56:37 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------1--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------43\n",
      "gender :--------------Man\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    English\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:57:17 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 22:57:17 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:57:20 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 22:57:20 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:57:20 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 22:57:20 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 22:57:20 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 22:57:20 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 22:57:20 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 22:57:20 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:57:20 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 22:57:20 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:57:20 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------2--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------27\n",
      "gender :--------------Woman\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    English\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:58:03 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 22:58:03 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:58:05 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 22:58:05 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:58:05 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 22:58:05 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 22:58:05 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 22:58:05 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 22:58:05 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 22:58:05 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:58:05 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 22:58:05 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:58:05 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------3--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------32\n",
      "gender :--------------Man\n",
      "ethnicity :--------------middle eastern\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    English\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:58:44 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 22:58:44 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:58:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 22:58:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:58:46 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 22:58:46 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 22:58:46 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 22:58:46 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 22:58:46 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 22:58:46 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:58:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 22:58:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:58:46 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------4--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------26\n",
      "gender :--------------Man\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Chinese_China\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:59:27 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 22:59:27 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:59:58 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 22:59:58 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:59:58 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 22:59:59 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 22:59:59 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 22:59:59 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 22:59:59 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 22:59:59 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 22:59:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 22:59:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 22:59:59 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------5--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------30\n",
      "gender :--------------Woman\n",
      "ethnicity :--------------asian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Swedish\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:00:58 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 23:00:58 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:01:28 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 23:01:28 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:01:28 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 23:01:28 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 23:01:28 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 23:01:28 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 23:01:28 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 23:01:28 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:01:28 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 23:01:28 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:01:29 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------6--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.59it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------30\n",
      "gender :--------------Man\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    English\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:02:06 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 23:02:06 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:02:08 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 23:02:08 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:02:08 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 23:02:09 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 23:02:09 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 23:02:09 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 23:02:09 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 23:02:09 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:02:09 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 23:02:09 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:02:09 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------7--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.52it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------33\n",
      "gender :--------------Man\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Portuguese\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:02:45 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 23:02:45 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:02:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 23:02:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:02:46 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 23:02:47 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 23:02:47 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 23:02:47 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 23:02:47 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 23:02:47 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:02:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 23:02:47 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:02:47 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------8--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------25\n",
      "gender :--------------Man\n",
      "ethnicity :--------------latino hispanic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Japanese\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:03:22 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 23:03:23 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:03:25 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 23:03:25 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:03:25 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 23:03:25 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 23:03:25 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 23:03:25 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 23:03:25 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 23:03:25 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:03:25 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 23:03:25 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:03:25 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------9--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------26\n",
      "gender :--------------Woman\n",
      "ethnicity :--------------asian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Chinese_Taiwan\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:04:02 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 23:04:02 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:04:04 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 23:04:04 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:04:04 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 23:04:04 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 23:04:04 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 23:04:04 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 23:04:04 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 23:04:04 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:04:04 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 23:04:04 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:04:04 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------10--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age :--------------39\n",
      "gender :--------------Man\n",
      "ethnicity :--------------white\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_pre/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    English\n",
      "Name: caption_l, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:04:39 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-10-06 23:04:40 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v1.9.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/17917d9c9cdff5c3c53e618a00299df26fd977aa/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.0.1+rocm5. Bad things might happen unless you revert torch to 1.x.\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:04:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-10-06 23:04:42 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:04:42 features:287] PADDING: 16\n",
      "[NeMo I 2023-10-06 23:04:42 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/huggingface/hub/models--nvidia--speakerverification_en_titanet_large/snapshots/4e0b2d387a805da7c208b13d5898ee09de8ec1e9/speakerverification_en_titanet_large.nemo.\n",
      "[NeMo I 2023-10-06 23:04:42 cloud:58] Found existing object /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "[NeMo I 2023-10-06 23:04:42 cloud:64] Re-using file from: /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo\n",
      "[NeMo I 2023-10-06 23:04:42 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-10-06 23:04:42 features:287] PADDING: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-10-06 23:04:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /ws/manifests/raid/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /ws/manifests/raid/musan/musan_music_noise_manifest_dur8.json\n",
      "        prob: 0.2\n",
      "        min_snr_db: 5\n",
      "        max_snr_db: 15\n",
      "    num_workers: 4\n",
      "    \n",
      "[NeMo W 2023-10-06 23:04:42 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /ws/manifests/raid/voxceleb/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    num_workers: 1\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-10-06 23:04:42 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /home/gamal/.cache/torch/NeMo/NeMo_1.18.1/speakerverification_speakernet/a8330fa516557b963a89ccbf0fcbe2f2/speakerverification_speakernet.nemo.\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "--------------------------------11--------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "i = 0\n",
    "for index, row in videos_unique_users.iterrows():\n",
    "    video_path = absPathVideo = row['video_path']\n",
    "\n",
    "\n",
    "    # EXTRACT FACE, AGE, GENDER, ETHNICITY, FACE EMBEDDING\n",
    "    absPathFace = absPathVideo.replace(datasetPathVideo,datasetPathFaces)\n",
    "    absPathFace = os.path.splitext(absPathFace)[0]\n",
    "    absPathFace = absPathFace + \"_face_\" + str(1) + \".png\"\n",
    "    #print(absPathFace)\n",
    "    #Create Directory\n",
    "    pathlib.Path(os.path.dirname(absPathFace)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "    \n",
    "    q = multiprocessing.Queue()\n",
    "\n",
    "    try:\n",
    "        proc = multiprocessing.Process(target=extract_face, args=(q,absPathVideo,\n",
    "                                                                image_size,\n",
    "                                                                fddfb,\n",
    "                                                                output_folder,\n",
    "                                                                efvr,efhr,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    shutil.copy2(output_folder + \"/\" + \"face.png\", \n",
    "                 absPathFace) # complete target filename given\n",
    "    \n",
    "    image_guide_path = output_folder + \"/\" + \"face.png\"\n",
    "    low_res_image_path = output_folder + \"/\" + \"face.png\"\n",
    "\n",
    "    gender = q.get()\n",
    "    if(gender == 'Error'):\n",
    "        continue\n",
    "    ethnicity = q.get()\n",
    "    if(ethnicity == 'Error'):\n",
    "        continue\n",
    "    age = q.get()\n",
    "    if(age == 'Error'):\n",
    "        continue\n",
    "\n",
    "\n",
    "    with open(output_folder + '/' + 'vgg.pickle', 'rb') as handle:\n",
    "        vgg = pickle.load(handle)\n",
    "        #print(\"++++++\" + str(vgg))\n",
    "\n",
    "\n",
    "\n",
    "    dataGotten = [['1','1',video_path,'age','ethnicity','gender',[],[],[],'language',[]]]\n",
    "    df = pd.DataFrame(dataGotten,columns = ['ID','FACE_ID','VIDEO_PATH','caption_a','caption_e','caption_g','SPEAKER_EMB','AUDIO_EMB','AUDIO_FEATURES','caption_l','image_path'])\n",
    "    df[\"image_guide\"] = np.nan\n",
    "    df['low_res_image'] = df['image_path']\n",
    "\n",
    "    df[\"caption_e\"] = ethnicity\n",
    "    df[\"caption_g\"] = gender\n",
    "    df[\"caption_a\"] = age\n",
    "\n",
    "    print(\"age :--------------\"  + str(age))\n",
    "    print(\"gender :--------------\"  + str(gender))\n",
    "    print(\"ethnicity :--------------\"  + str(ethnicity))\n",
    "\n",
    "    q.empty()\n",
    "\n",
    "    #gpus\n",
    "    import pickle\n",
    "\n",
    "\n",
    "\n",
    "    # EXTRACT SPEAKER EMBEDDINGS, AUDIO FEATURES AND LANGUAGE\n",
    "\n",
    "    audio_embs =  configParser.get('COMMON', 'audio_embs') \n",
    "    from pydub import AudioSegment\n",
    "    import math\n",
    "    # Get original duration of video\n",
    "    audio = AudioSegment.from_file(video_path)\n",
    "    audio_length_og = math.floor(audio.duration_seconds)\n",
    "\n",
    "\n",
    "    video_filename = os.path.basename(video_path)\n",
    "\n",
    "    absPathAudio_w = os.path.abspath(audio_folder) + \"/\" + video_filename\n",
    "    absPathAudio = os.path.splitext(absPathAudio_w)[0]+'_audio.wav'\n",
    "    absPathAudio_w = os.path.splitext(absPathAudio_w)[0]\n",
    "\n",
    "\n",
    "    import subprocess\n",
    "    # Extract audio monochannel and with 16khz and put it in absPathAudio\n",
    "\n",
    "    command = \"ffmpeg -nostats -loglevel 0 -y -i '\" + video_path + \"' -acodec pcm_s16le -ab 160k -ac 1 -ar 16000 -vn '\" + absPathAudio  + \"'\"\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "    from threading import Thread\n",
    "    import time\n",
    "\n",
    "    # Function to delete audio temp files\n",
    "    def delFiles(filesToDelete):\n",
    "        time.sleep(ttwbdf)  # wait a bit\n",
    "        for file in filesToDelete:  \n",
    "            try:\n",
    "                os.remove(file)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "\n",
    "    # Will either truncate or loop the original video to reach audio_length (6,12 or 24)\n",
    "    audio_length_list = [24]\n",
    "    for audio_length in audio_length_list:\n",
    "        path_var_len_audio =  absPathAudio_w + \"audio\" + str(audio_length) + \"s.wav\"    # path to the variable length audio\n",
    "        path_var_len_audio_temp =  absPathAudio_w + \"audio_temp\" + str(audio_length) + \"s.wav\"  # path to a temp version of the variable length audio\n",
    "\n",
    "        if(audio_length_og > audio_length):\n",
    "            # Truncate    \n",
    "\n",
    "            command = \"ffmpeg -nostats -loglevel 0 -y -ss 0 -t \"+str(audio_length)+\" -i \\\"\" + absPathAudio + \"\\\" \\\"\" + path_var_len_audio + \"\\\"\"\n",
    "            subprocess.call(command, shell=True)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Loop then truncaate\n",
    "            #print(\"lesa\")\n",
    "            twoDigitLenStr = f\"{audio_length:02}\"\n",
    "            #print(twoDigitLenStr)\n",
    "            command = \"ffmpeg -nostats -loglevel 0 -y -stream_loop -1 -i '\" + absPathAudio + \"' -t \\\"00:00:\"+twoDigitLenStr+\".000\\\" -codec:a \\\"aac\\\" -f \\\"wav\\\" -c copy '\"+ path_var_len_audio_temp + \"'\"\n",
    "            subprocess.call(command, shell=True)\n",
    "            command = \"ffmpeg -nostats -loglevel 0 -y -ss 0 -t \"+str(audio_length)+\" -i \\\"\" + path_var_len_audio_temp + \"\\\" \\\"\" + path_var_len_audio + \"\\\"\"\n",
    "            subprocess.call(command, shell=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        proc = multiprocessing.Process(target=extract_speechbrain_embeddings, args=(q,path_var_len_audio,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        df['SPEAKER_EMB'] = q.get()\n",
    "        df['caption_l'] = q.get()\n",
    "        print(df['caption_l'])\n",
    "\n",
    "\n",
    "        proc = multiprocessing.Process(target=extract_pyannote_titanet_embeddings, args=(q,path_var_len_audio,audio_embs,audio_length,openl3_mode,output_folder,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "        with open(output_folder + '/' + 'audio_emb_pyannote_titanet.pickle', 'rb') as handle:\n",
    "            df['AUDIO_EMB'] = pickle.load(handle)\n",
    "\n",
    "        proc = multiprocessing.Process(target=extract_audio_features, args=(q,path_var_len_audio,output_folder,))\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "\n",
    "\n",
    "\n",
    "        with open(output_folder + '/' + 'audio_features.pickle', 'rb') as handle:\n",
    "            df['AUDIO_FEATURES'] = pickle.load(handle)\n",
    "\n",
    "        ftd = [absPathAudio,path_var_len_audio,os.path.basename(path_var_len_audio),path_var_len_audio_temp]\n",
    "        tDelete = Thread(target=delFiles, args=(ftd,))   # spawn a process\n",
    "        tDelete.start()\n",
    "\n",
    "    #proc = multiprocessing.Process(target=extract_vision_transformer, args=(q,output_folder,\n",
    "    #                                                                        image_guide_path,1,\n",
    "    #                                                                        image_size,\n",
    "    #    boxBlurMin,boxBlurMax,gaussianBlurMin,gaussianBlurMax,pix_to_min,pix_to_max,))\n",
    "    #proc.start()\n",
    "    #proc.join()\n",
    "\n",
    "\n",
    "\n",
    "    #with open(output_folder + '/' + 'image_features.pickle', 'rb') as handle:\n",
    "    #    df[\"image_guide\"] = pickle.load(handle)\n",
    "\n",
    "    image = Image.open(image_guide_path).convert('RGB')\n",
    "\n",
    "    w_s = image_size / (1+2 * 0.4)\n",
    "    h_s = image_size / (1+2 * 0.4)\n",
    "\n",
    "    image = image.crop((0.2*w_s, 0.0*h_s, 1.6*w_s, 1.4*h_s))\n",
    "\n",
    "    image = image.resize((image_size,image_size))\n",
    "\n",
    "    image = image.resize((begin_with_image_size,begin_with_image_size))\n",
    "    im = image\n",
    "    \n",
    "\n",
    "    #print('saving')\n",
    "    image.save(output_folder + \"/\" + \"guide.png\")\n",
    "\n",
    "    #print(np.array(image,np.float32).shape)\n",
    "\n",
    "    #pix = np.array(image, np.float32)\n",
    "    #pix = np.moveaxis(pix, -1, 0)\n",
    "\n",
    "    #pix = pix / 255\n",
    "    image.close()\n",
    "    im.close()\n",
    "    #return pix.tolist()\n",
    "\n",
    "    absPathGuide = absPathVideo.replace(datasetPathVideo,datasetPathGuides)\n",
    "    absPathGuide = os.path.splitext(absPathGuide)[0]\n",
    "    absPathGuide = absPathGuide + \"_guide_\"+ \".png\"\n",
    "    #print(absPathFace)\n",
    "    #Create Directory\n",
    "    pathlib.Path(os.path.dirname(absPathGuide)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "    shutil.copy2(output_folder + \"/\" + \"guide.png\", absPathGuide) # complete target filename given\n",
    "\n",
    "\n",
    "    df3 = df[[\"image_path\",\"caption_a\",\"caption_e\",\"caption_g\",\"caption_l\"]]\n",
    "    data_frame = df3\n",
    "    data_frame['SPEAKER_EMB'] = df['SPEAKER_EMB']\n",
    "    data_frame['AUDIO_EMB'] = df['AUDIO_EMB']\n",
    "    data_frame['AUDIO_FEATURES'] = df['AUDIO_FEATURES']\n",
    "    data_frame['image_guide'] = df['image_guide']\n",
    "    data_frame['low_res_image'] = df['low_res_image']\n",
    "\n",
    "    import pickle\n",
    "\n",
    "\n",
    "    with open(output_folder + '/' + 'filename.pickle', 'wb') as handle:\n",
    "        pickle.dump(data_frame, handle)\n",
    "\n",
    "\n",
    "    absPathFeatures = absPathVideo.replace(datasetPathVideo,datasetPathFeatures)\n",
    "    absPathFeatures = os.path.splitext(absPathFeatures)[0]\n",
    "    absPathFeatures = absPathFeatures + \"_features_\"+ \".pickle\"\n",
    "    #print(absPathFace)\n",
    "    #Create Directory\n",
    "    pathlib.Path(os.path.dirname(absPathFeatures)).mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "    shutil.copy2(output_folder + \"/\" + \"filename.pickle\", absPathFeatures) # complete target filename given\n",
    "\n",
    "    #data_frame.loc[index,\"features_path\"] = output_folder + '/' + 'filename.pickle'\n",
    "\n",
    "    p_small = pathlib.Path(os.path.dirname(absPathVideo))\n",
    "    p_big = p_small.parent.absolute()\n",
    "    \n",
    "    df_table = pd.DataFrame()\n",
    "    df_table = df_table.append({'id': int(row['id']), 'video_path': row['video_path'], \n",
    "                    'face_path': absPathFace,'user':p_big.name,\n",
    "        'blurred_face_path': absPathGuide, 'features_path': absPathFeatures, \n",
    "        'age': age,'gender':gender,'ethnicity':ethnicity,\n",
    "        'vector' : vgg,'stage': 1}, ignore_index=True)\n",
    "    \n",
    "\n",
    "    if(i == 0):\n",
    "        db.create_table(\"video_stage1\", df_table)\n",
    "    else:\n",
    "        tbl = db.open_table(\"video_stage1\")\n",
    "        tbl.add(df_table)\n",
    "        \n",
    "\n",
    "    i = i + 1\n",
    "    if(i == 20):\n",
    "        break\n",
    "\n",
    "    print('--------------------------------' + str(i) + '--------------------------------')\n",
    "\n",
    "shutil.rmtree(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>face_path</th>\n",
       "      <th>user</th>\n",
       "      <th>blurred_face_path</th>\n",
       "      <th>features_path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>vector</th>\n",
       "      <th>stage</th>\n",
       "      <th>_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00009</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.0135836145, 0.0042493055, 0.005943807, 0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>868.875854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00010</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>26</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.021446062, 0.010711044, 0.02926736, 0.02391...</td>\n",
       "      <td>1</td>\n",
       "      <td>868.960632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         video_path  \\\n",
       "0   6  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "1   4  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "\n",
       "                                           face_path     user  \\\n",
       "0  /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00009   \n",
       "1  /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00010   \n",
       "\n",
       "                                   blurred_face_path  \\\n",
       "0  /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "1  /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "\n",
       "                                       features_path  age gender ethnicity  \\\n",
       "0  /home/gamal/Datasets/Dataset1Test/FeaturesTest...   30    Man     white   \n",
       "1  /home/gamal/Datasets/Dataset1Test/FeaturesTest...   26    Man     white   \n",
       "\n",
       "                                              vector  stage   _distance  \n",
       "0  [0.0135836145, 0.0042493055, 0.005943807, 0.01...      1  868.875854  \n",
       "1  [0.021446062, 0.010711044, 0.02926736, 0.02391...      1  868.960632  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = db.open_table(\"video_stage1\")\n",
    "tbl.search(np.random.rand(2622)).limit(2).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_path</th>\n",
       "      <th>face_path</th>\n",
       "      <th>user</th>\n",
       "      <th>blurred_face_path</th>\n",
       "      <th>features_path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>vector</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00002</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>36</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.009602746, -0.004742456, 0.004785673, 0.032...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00001</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>43</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.0071346397, 0.0012256216, 0.008316233, 0.01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00006</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>27</td>\n",
       "      <td>Woman</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.009253787, 0.01768741, 0.006679517, 0.03707...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00008</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>32</td>\n",
       "      <td>Man</td>\n",
       "      <td>middle eastern</td>\n",
       "      <td>[0.015824728, 0.015256352, 0.0022940119, 0.022...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00010</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>26</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.021446062, 0.010711044, 0.02926736, 0.02391...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00012</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>30</td>\n",
       "      <td>Woman</td>\n",
       "      <td>asian</td>\n",
       "      <td>[0.011320298, 0.000799592, 0.0058022174, 0.019...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00009</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.0135836145, 0.0042493055, 0.005943807, 0.01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00005</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>33</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.017614838, 0.009371514, 0.0011152884, 0.028...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00004</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>25</td>\n",
       "      <td>Man</td>\n",
       "      <td>latino hispanic</td>\n",
       "      <td>[0.019905446, 0.009860523, 0.006439571, 0.0109...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00007</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>26</td>\n",
       "      <td>Woman</td>\n",
       "      <td>asian</td>\n",
       "      <td>[0.0077050775, 0.0055537038, 0.011315688, 0.01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/VideoTest/id...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FacesTest/id...</td>\n",
       "      <td>id00003</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/GuidesTest/i...</td>\n",
       "      <td>/home/gamal/Datasets/Dataset1Test/FeaturesTest...</td>\n",
       "      <td>39</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>[0.022298168, 0.0112246405, 0.008998627, 0.028...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                         video_path  \\\n",
       "0    0  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "1    1  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "2    2  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "3    3  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "4    4  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "5    5  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "6    6  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "7    7  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "8    8  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "9   10  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "10  11  /home/gamal/Datasets/Dataset1Test/VideoTest/id...   \n",
       "\n",
       "                                            face_path     user  \\\n",
       "0   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00002   \n",
       "1   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00001   \n",
       "2   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00006   \n",
       "3   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00008   \n",
       "4   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00010   \n",
       "5   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00012   \n",
       "6   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00009   \n",
       "7   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00005   \n",
       "8   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00004   \n",
       "9   /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00007   \n",
       "10  /home/gamal/Datasets/Dataset1Test/FacesTest/id...  id00003   \n",
       "\n",
       "                                    blurred_face_path  \\\n",
       "0   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "1   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "2   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "3   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "4   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "5   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "6   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "7   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "8   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "9   /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "10  /home/gamal/Datasets/Dataset1Test/GuidesTest/i...   \n",
       "\n",
       "                                        features_path  age gender  \\\n",
       "0   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   36    Man   \n",
       "1   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   43    Man   \n",
       "2   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   27  Woman   \n",
       "3   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   32    Man   \n",
       "4   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   26    Man   \n",
       "5   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   30  Woman   \n",
       "6   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   30    Man   \n",
       "7   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   33    Man   \n",
       "8   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   25    Man   \n",
       "9   /home/gamal/Datasets/Dataset1Test/FeaturesTest...   26  Woman   \n",
       "10  /home/gamal/Datasets/Dataset1Test/FeaturesTest...   39    Man   \n",
       "\n",
       "          ethnicity                                             vector  stage  \n",
       "0             white  [0.009602746, -0.004742456, 0.004785673, 0.032...      1  \n",
       "1             white  [0.0071346397, 0.0012256216, 0.008316233, 0.01...      1  \n",
       "2             white  [0.009253787, 0.01768741, 0.006679517, 0.03707...      1  \n",
       "3    middle eastern  [0.015824728, 0.015256352, 0.0022940119, 0.022...      1  \n",
       "4             white  [0.021446062, 0.010711044, 0.02926736, 0.02391...      1  \n",
       "5             asian  [0.011320298, 0.000799592, 0.0058022174, 0.019...      1  \n",
       "6             white  [0.0135836145, 0.0042493055, 0.005943807, 0.01...      1  \n",
       "7             white  [0.017614838, 0.009371514, 0.0011152884, 0.028...      1  \n",
       "8   latino hispanic  [0.019905446, 0.009860523, 0.006439571, 0.0109...      1  \n",
       "9             asian  [0.0077050775, 0.0055537038, 0.011315688, 0.01...      1  \n",
       "10            white  [0.022298168, 0.0112246405, 0.008998627, 0.028...      1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78dccc615e96ab04385280185a87a524fe0822daf5dbad2f4bf2e7d7b28366a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
