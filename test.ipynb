{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import sqlite3 as sl\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'datasetPathDatabase') + '/dataset.db'\n",
    "con = sl.connect(datasetPathDatabase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04599404335021973\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for _ in range(20):\n",
    "    sql = (\"SELECT V.ID,F.ID,V.VIDEO_PATH, V.AGE CAPTION_A, \" + \n",
    "                        \"V.ETHNICITY CAPTION_E, \" +\n",
    "                        \"lower(V.GENDER) CAPTION_G, \" +\n",
    "                            \"A.SPEAKER_EMB, A.PYANNOTE_TITANET, \" +\n",
    "                        \"A.AUDIO_FEATURES, \" +\n",
    "                        \"A.LANG CAPTION_L, \"+\n",
    "                        \"F.FACE_PATH \"+\n",
    "                        \"FROM VIDEO V \"+\n",
    "                        \"INNER JOIN AUDIO A ON V.ID = A.VIDEO_ID \" +\n",
    "                        \"INNER JOIN FACE F ON F.ID = (select ID from FACE f2 where f2.video_id = v.ID ORDER By ID limit 1 ) \" + \n",
    "                        \"WHERE AUDIO_LENGTH = \" + str(24) + ' ' +\n",
    "                        \"AND V.ID in (select V2.ID from VIDEO v2 WHERE V2.TRAINED IS NULL AND AUDIO_PRE IN (3,4) AND FACES_PRE = 2 ORDER BY ABS(RANDOM()) LIMIT \"+ str(50) + \")\")\n",
    "    data = con.execute(sql)\n",
    "    dataGotten = data.fetchall()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0037674903869628906\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for _ in range(1):\n",
    "    sql = (\"SELECT * FROM GENERATOR\")\n",
    "    data = con.execute(sql)\n",
    "    dataGotten = data.fetchall()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 1 times : ~0.07 seconds\n",
    "500 2 times : ~0.06 seconds\n",
    "100 10 times: ~0.065 seconds\n",
    "20 50 TIMES: ~ 0.002 seconds\n",
    "1 1000 times: ~ 0.002 seconds\n",
    "VIEW\n",
    "1000 1 times: ~0.07 seconds\n",
    "1000 1 times: ~ 0.002 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array, nan\n",
    "import numpy as np\n",
    "arr = np.array([nan, nan,nan])\n",
    "n = len(arr)\n",
    "temp = n*[None]\n",
    "arr[np.isnan(arr)] = None\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12\n",
       "1       14\n",
       "2    aaaaa\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series([12,14,\"aaaaa\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['gender','ethnicity','age','VGG'] = df_data.apply(extract_face_fn,args=(\n",
    "    start_at_frame,output_folder,resizeImageTo,fddfb,efvr,efhr,auto_zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "\n",
    "datasetPathVideo =  configParser.get('COMMON', 'test_datasetPathVideo')\n",
    "\n",
    "datasetPathFeatures =  configParser.get('evaluate_imagen', 'test_datasetPathFeatures')\n",
    "datasetPathGeneratedFaces =  configParser.get('evaluate_imagen', 'test_datasetPathGeneratedFaces')\n",
    "generated_face_table_name =  configParser.get('evaluate_imagen', 'generated_face_table_name')\n",
    "\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'test_datasetPathDatabase') + '/dataset.db'\n",
    "\n",
    "ttwbdf =  int(configParser.get('evaluate_imagen', 'time_to_wait_before_deleting_files'))\n",
    "\n",
    "\n",
    "cuda =  int(configParser.get('COMMON', 'cuda'))\n",
    "cpus =  int(configParser.get('COMMON', 'cpus'))\n",
    "\n",
    "image_size =  int(configParser.get('COMMON', 'resizeImageTo'))\n",
    "begin_with_image_size = int(configParser.get('COMMON', 'begin_with_image_size'))\n",
    "timesteps= int(configParser.get('COMMON', 'timesteps') )\n",
    "unet1_image_size =  int(configParser.get('COMMON', 'unet1_image_size'))\n",
    "audio_length_used =  configParser.get('evaluate_imagen', 'audio_length_used') \n",
    "model_filename =  configParser.get('evaluate_imagen', 'model_filename') + '_'  + audio_length_used +  's.pt'\n",
    "openl3_mode =  configParser.get('evaluate_imagen', 'openl3_mode')\n",
    "folder =  configParser.get('evaluate_imagen', 'folder')\n",
    "audio_embs =  configParser.get('COMMON', 'audio_embs') \n",
    "unet1_dim =  int(configParser.get('COMMON', 'unet1_dim'))\n",
    "unet2_dim =  int(configParser.get('COMMON', 'unet2_dim'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamal/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-26 23:19:18.037566: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer,NullUnet\n",
    "from imagen_pytorch.data import Dataset\n",
    "\n",
    "unet0 = NullUnet()  # add a placeholder \"null\" unet for the base unet\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = unet1_dim,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = unet2_dim,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "#unet = Unet(\n",
    "#    dim = 32,\n",
    "#    dim_mults = (1, 2, 4, 8),\n",
    "#    num_resnet_blocks = 1,\n",
    "#    layer_attns = (False, False, False, True),\n",
    "#    layer_cross_attns = False\n",
    "#)\n",
    "\n",
    "# imagen, which contains the unet above\n",
    "\n",
    "#imagen = Imagen(\n",
    "#    unets = unet,\n",
    "#    image_sizes = 32,\n",
    "#    timesteps = 1000\n",
    "#)\n",
    "\n",
    "imagen = Imagen(\n",
    "    unets = (unet0,unet1, unet2),\n",
    "    image_sizes = (begin_with_image_size,unet1_image_size, image_size),\n",
    "    timesteps = timesteps,\n",
    "    cond_drop_prob = 0.1\n",
    ").cuda()\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    "    split_valid_from_train = True # whether to split the validation dataset from the training\n",
    ").cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 768])\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input = torch.from_numpy(np.ones((1,256,768)) * 0.5)\n",
    "input = input.to(torch.float)\n",
    "input2 = torch.from_numpy(np.ones((1,3,32,32)) * 0.5)\n",
    "input2 = input2.to(torch.float)\n",
    "print(input.shape)\n",
    "print(input2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "         [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    images = trainer.sample(text_embeds=input,start_image_or_video = input2,\n",
    "                        stop_at_unet_number=3,start_at_unet_number = 2\n",
    "                        ,batch_size = 1, return_pil_images = True) # returns List[Image]\n",
    "except:\n",
    "    print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              col1             col2\n",
      "0     [5, 6, 7, 8]  [9, 10, 11, 12]\n",
      "1  [9, 10, 11, 12]     [5, 6, 7, 8]\n",
      "              col1             col2\n",
      "0     [5, 6, 7, 8]  [9, 10, 11, 12]\n",
      "1  [9, 10, 11, 12]     [5, 6, 7, 8]\n",
      "                  col1                 col2\n",
      "0     [[5, 6], [7, 8]]  [[9, 10], [11, 12]]\n",
      "1  [[9, 10], [11, 12]]     [[5, 6], [7, 8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10218/2638581980.py:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(x == 'foo'):\n",
      "/tmp/ipykernel_10218/2638581980.py:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if(x == 'foo'):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "\n",
    "a = np.array([[5, 6], [7, 8]]).flatten()\n",
    "b = np.array([[9, 10], [11, 12]]).flatten()\n",
    "df = pd.DataFrame({\"col1\": [a],\"col2\":[b]})\n",
    "df.loc[1] = (b,a)\n",
    "\n",
    "df = dd.from_pandas(df, npartitions=2)\n",
    "\n",
    "print(df.compute())\n",
    "\n",
    "name_function = lambda x: f\"data-{x}.parquet\"\n",
    "df[['col1','col2']].to_parquet('train/',name_function=name_function,engine='pyarrow',schema={\"col1\": pa.list_(pa.int32()),\"col2\": pa.list_(pa.int32())})\n",
    "\n",
    "\n",
    "df2 = dd.read_parquet(['train/data-0.parquet','train/data-1.parquet'])  \n",
    "print(df2.compute())\n",
    "\n",
    "def reshape(x):\n",
    "    if(x == 'foo'):\n",
    "        return x\n",
    "    return x.reshape(2,2) \n",
    "\n",
    "df2 = df2.applymap(lambda x:reshape(x)) \n",
    "print(df2.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>image_guide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  image_guide\n",
       "0     0     1     2          NaN\n",
       "1     5     6     7          NaN\n",
       "2    10    11    12          NaN\n",
       "3    15    16    -1          NaN"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"image_guide\"] = np.nan\n",
    "df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>image_guide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  image_guide\n",
       "0     0     1     2          NaN\n",
       "1     5     6     7          NaN\n",
       "2    10    11    12          NaN\n",
       "3    15    16    -1          NaN"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"col3\")\n",
    "df.repartition(npartitions=2)\n",
    "df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>image_guide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  image_guide\n",
       "0     1     3          NaN\n",
       "0     2     4          NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     3\n",
       "0     2     4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = df[[\"col1\",\"col2\"]]\n",
    "data_frame.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [x, y, z]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.DataFrame(columns=[\"x\", \"y\",\"z\"], dtype=int)\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 8 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                col1   col2    col3\n",
       "npartitions=2                      \n",
       "               int64  int64  object\n",
       "                 ...    ...     ...\n",
       "                 ...    ...     ...\n",
       "Dask Name: assign, 8 graph layers"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def speaker_emb_preprocess(x):\n",
    "    return x*x*x\n",
    "\n",
    "data_frame['col3'] = data_frame['col1'].apply(lambda x: speaker_emb_preprocess(x),meta=('1', 'object'))\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.DataFrame([[1,2,4],[1,4,5]], dtype=int)\n",
    "type(\"meta_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.zeros((1,768)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: drop_by_shallow_copy, 9 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                col2    col3\n",
       "npartitions=2               \n",
       "               int64  object\n",
       "                 ...     ...\n",
       "                 ...     ...\n",
       "Dask Name: drop_by_shallow_copy, 9 graph layers"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop(['col1'], axis=1)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: getitem, 10 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                col2    col3\n",
       "npartitions=2               \n",
       "               int64  object\n",
       "                 ...     ...\n",
       "                 ...     ...\n",
       "Dask Name: getitem, 10 graph layers"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame[['col2','col3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_frame[\"col2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for index, row in data_frame.iterrows():\n",
    "    print(row['col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_LocIndexer' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_frame\u001b[39m.\u001b[39;49mloc[\u001b[39m1\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mcol2\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_LocIndexer' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "data_frame.loc[1,\"col2\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "x = []\n",
    "x.append(0)\n",
    "x.append(1)\n",
    "x.append(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(10))\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Training Sample (x500)\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "fig.savefig(\"save_file_name.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# For a single Element\n",
    "random.choices([True, False], weights=[100, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_size = 128\n",
    "\n",
    "def make_square(im, min_size=128, fill_color=(0, 0, 0, 0)):\n",
    "    x, y = im.size\n",
    "    size = max(min_size, x, y)\n",
    "    new_im = Image.new('RGB', (size, size), fill_color)\n",
    "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
    "    im.close()\n",
    "    return new_im\n",
    "\n",
    "def image_guide_preprocess_low_res_dummy(path):\n",
    "    #print(face_id)\n",
    "\n",
    "    image_guide = np.zeros((1, 768))\n",
    "    return image_guide\n",
    "\n",
    "def image_guide_preprocess_low_res(path):\n",
    "    #print(face_id)\n",
    "\n",
    "\n",
    "    if(False): #never\n",
    "        image_guide = np.zeros((49, 768))\n",
    "        #print(image_guide.shape)\n",
    "    else:\n",
    "\n",
    "        image = Image.open(path).convert('RGB')\n",
    "\n",
    "        #print(image.size)\n",
    "\n",
    "        w_s = image_size / (1+2 * 0.4)\n",
    "        h_s = image_size / (1+2 * 0.4)\n",
    "\n",
    "        image = image.crop((0.2*w_s, 0.0*h_s, 1.6*w_s, 1.4*h_s))\n",
    "        image = image.resize((128,128))\n",
    "        print(image.size)\n",
    "        #image = im\n",
    "\n",
    "        #image = image.resize((16,16))\n",
    "        im = image\n",
    "        \n",
    "\n",
    "        print('saving')\n",
    "        image.save('opop.png')\n",
    "\n",
    "        #print(np.array(image,np.float32).shape)\n",
    "\n",
    "        pix = np.array(image, np.float32)\n",
    "        pix = np.moveaxis(pix, -1, 0)\n",
    "\n",
    "        pix = pix / 255\n",
    "        image.close()\n",
    "        im.close()\n",
    "        return pix.tolist()\n",
    "    return image_guide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = '/media/gamal/Passport/Datasets/VoxCeleb2Test/Voxceleb2TestFaces/mp4/id01106/45TAeIEqhcU/00001_face_1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_guide_preprocess_low_res(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "class CsvDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_folder):\n",
    "\n",
    "        self.csv_folder = csv_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        _, _, files = next(os.walk(self.csv_folder))\n",
    "        file_count = len(files)\n",
    "        print('found ' + str(file_count) + ' files.')\n",
    "        return file_count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = sorted(glob.glob(self.csv_folder + '*.csv'))[index]\n",
    "        df = pd.read_csv(file)\n",
    "        print(df.head(1))\n",
    "        df['INPUT'] = np.fromstring(s[1:-1], dtype=np.int, sep=' ')\n",
    "        #df['INPUT'] = df['INPUT'].astype('numpy.ndarray')\n",
    "        print(df['INPUT'][0])\n",
    "        torch_tensor = torch.tensor(df.head(1).values)\n",
    "        return torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = CsvDataset(csv_folder='train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(face_dataset,\n",
    "        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1 files.\n",
      "   Unnamed: 0                                              INPUT  \\\n",
      "0           0  [[0. 0. 0. ... 0. 0. 1.]\\n [0. 0. 0. ... 0. 0....   \n",
      "\n",
      "                                          image_path  \\\n",
      "0  [[[0.23921569 0.23921569 0.23921569 ... 0.3019...   \n",
      "\n",
      "                                       low_res_image  \n",
      "0  [[[0.24313726 0.6313726  0.6784314  0.7529412 ...  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "data type 'numpy.ndarray' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mhead(\u001b[39m1\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mINPUT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mINPUT\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mnumpy.ndarray\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#df['INPUT'] = df['INPUT'].astype('numpy.ndarray')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/test.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mINPUT\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdtypes))\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/pandas/core/dtypes/astype.py:279\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    273\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    274\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected an instance of \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got the class instead. Try instantiating \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m dtype \u001b[39m=\u001b[39m pandas_dtype(dtype)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, PandasDtype):\n\u001b[1;32m    281\u001b[0m     \u001b[39m# Ensure we don't end up with a PandasArray\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1781\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[39m# try a numpy dtype\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[39m# raise a consistent TypeError if failed\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1781\u001b[0m     npdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdtype(dtype)\n\u001b[1;32m   1782\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mSyntaxError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1783\u001b[0m     \u001b[39m# np.dtype uses `eval` which can raise SyntaxError\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not understood\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type 'numpy.ndarray' not understood"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(i0, i1, i2, i3, i4, i5, i6, i7, i8, i9)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [(i0, i1, i2, i3, i4, i5, i6, i7, i8, i9)]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = np.arange(10)\n",
    "charar = np.chararray((1, 10))\n",
    "charar[:] = 'i'\n",
    "names = charar.astype('str') + names.astype('str')\n",
    "meta_df = pd.DataFrame(columns=names.astype(str), dtype=int)\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 1: [-0.68918758 -0.20665118 -0.972757   ...  0.97566972  0.51995366\n",
      " -0.75467984]\n",
      "Vector 2: [ 0.5         0.5         0.5        ...  0.97566972  0.51995366\n",
      " -0.75467984]\n",
      "Mean Squared Error: 0.006568963128269801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set seed for reproducibility\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Generate two vectors of length 2622 with values ranging from -1 to 1\n",
    "vector1 = np.random.uniform(-1, 1, 2622)\n",
    "vector2 = np.array(vector1)\n",
    "vector2[0:25] = 0.5\n",
    "\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(vector1, vector2)\n",
    "\n",
    "print(f\"Vector 1: {vector1}\")\n",
    "print(f\"Vector 2: {vector2}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_pre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
