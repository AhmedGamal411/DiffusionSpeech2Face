{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "\n",
    "# Loading configurations\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "\n",
    "insert_amd_env_vars =  int(configParser.get('COMMON', 'insert_amd_env_vars'))\n",
    "HSA_OVERRIDE_GFX_VERSION =  configParser.get('COMMON', 'HSA_OVERRIDE_GFX_VERSION')\n",
    "ROCM_PATH =  configParser.get('COMMON', 'ROCM_PATH')\n",
    "\n",
    "if(insert_amd_env_vars != 0):\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = HSA_OVERRIDE_GFX_VERSION\n",
    "    os.environ[\"ROCM_PATH\"] = ROCM_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#TODO document jupyter\n",
    "import pickle\n",
    "import configparser\n",
    "import sqlite3 as sl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "configParser = configparser.RawConfigParser()   \n",
    "configFilePath = r'configuration.txt'\n",
    "configParser.read(configFilePath)\n",
    "datasetPathDatabase =  configParser.get('COMMON', 'datasetPathDatabase') + '/dataset.db'\n",
    "datasetPathDatabaseAdditional =  configParser.get('COMMON', 'datasetPathDatabase') + '/datasetAdditional.db'\n",
    "datasetPathDatabaseVgg =  configParser.get('COMMON', 'datasetPathDatabase') + '/datasetFacesBlurred.db'\n",
    "image_size =  int(configParser.get('COMMON', 'resizeImageTo'))\n",
    "begin_with_image_size = int(configParser.get('COMMON', 'begin_with_image_size'))\n",
    "unet1_dim =  int(configParser.get('COMMON', 'unet1_dim'))\n",
    "unet2_dim =  int(configParser.get('COMMON', 'unet2_dim'))\n",
    "unet1_image_size =  int(configParser.get('COMMON', 'unet1_image_size'))\n",
    "audio_embs =  str(configParser.get('COMMON', 'audio_embs'))\n",
    "audio_length_used =  configParser.get('train_imagen', 'audio_length_used') \n",
    "model_filename =  configParser.get('train_imagen', 'model_filename')\n",
    "sub_epochs=  int(configParser.get('train_imagen', 'sub_epochs') )\n",
    "inner_epochs=  int(configParser.get('train_imagen', 'inner_epochs') )\n",
    "batch_size=  int(configParser.get('train_imagen', 'batch_size') )\n",
    "timesteps= int(configParser.get('COMMON', 'timesteps') )\n",
    "sample_every=  int(configParser.get('train_imagen', 'sample_every') ) - 1\n",
    "sample_probability = int(configParser.get('train_imagen', 'sample_probability') )\n",
    "save_model_every=  int(configParser.get('train_imagen', 'save_model_every') )\n",
    "sample_every_offset=  int(configParser.get('train_imagen', 'sample_every_offset') ) - 1\n",
    "save_every_offset=  int(configParser.get('train_imagen', 'save_every_offset') ) - 1\n",
    "imagen_samples_folder = configParser.get('train_imagen', 'imagen_samples_folder') \n",
    "db_chunk = int(configParser.get('train_imagen', 'db_chunk'))\n",
    "dask_chunk = int(configParser.get('train_imagen', 'dask_chunk'))\n",
    "stop_at_no_of_samples = int(configParser.get('train_imagen', 'stop_at_no_of_samples'))\n",
    "epochs = int(configParser.get('train_imagen', 'epochs'))\n",
    "ignore_speaker_embedding = bool(int(configParser.get('train_imagen', 'ignore_speaker_embedding') ))\n",
    "ignore_speech_brain = bool(int(configParser.get('train_imagen', 'ignore_speech_brain') ))\n",
    "ignore_pyannote_titanet_speakernet = bool(int(configParser.get('train_imagen', 'ignore_pyannote_titanet_speakernet') ))\n",
    "ignore_audio_features = bool(int(configParser.get('train_imagen', 'ignore_audio_features') ))\n",
    "ignore_pyAudioAnalysis = bool(int(configParser.get('train_imagen', 'ignore_pyAudioAnalysis') ))\n",
    "ignore_librosa = bool(int(configParser.get('train_imagen', 'ignore_librosa') ))\n",
    "ignore_image_guide = bool(int(configParser.get('train_imagen', 'ignore_image_guide') ))\n",
    "ignore_additional_attributes = bool(int(configParser.get('train_imagen', 'ignore_additional_attributes') ))\n",
    "ignore_age = bool(int(configParser.get('train_imagen', 'ignore_age') ))\n",
    "ignore_gender = bool(int(configParser.get('train_imagen', 'ignore_gender') ))\n",
    "ignore_ethnicity = bool(int(configParser.get('train_imagen', 'ignore_ethnicity') ))\n",
    "ignore_language_spoken = bool(int(configParser.get('train_imagen', 'ignore_language_spoken') ))\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaker_emb_preprocess(speaker_emb2):\n",
    "\n",
    "    if(ignore_speaker_embedding or ignore_speech_brain):\n",
    "        #print('ignore speech brain')\n",
    "        return np.zeros((1,768))\n",
    "    else:\n",
    "        speaker_emb2 = pickle.loads(speaker_emb2)\n",
    "        #print(speaker_emb2.print)\n",
    "        speaker_emb2 = speaker_emb2.squeeze()\n",
    "        speaker_emb2 = np.pad(speaker_emb2, (288), 'constant', constant_values=(0))\n",
    "        speaker_emb2 = np.tile(speaker_emb2, (1, 1))\n",
    "        speaker_emb2 = speaker_emb2 / 200.0\n",
    "        #print(speaker_emb2.shape)\n",
    "        #speaker_emb2 = np.array(speaker_emb2).tolist()\n",
    "        #print(type(speaker_emb2))\n",
    "        return speaker_emb2\n",
    "\n",
    "\n",
    "def audio_emb_preprocess2(speaker_emb2):\n",
    "    \n",
    "    if(ignore_pyannote_titanet_speakernet or ignore_speaker_embedding):\n",
    "        #print('ignore speech brain')\n",
    "        return np.zeros((28,768))\n",
    "    else:\n",
    "        #print(speaker_emb2)\n",
    "        speaker_emb2 = pickle.loads(speaker_emb2)\n",
    "        a = speaker_emb2 #np.zeros(shape=(24, 512))\n",
    "        a = a[-28:,:] # Actually only last 39 are the relevant ones\n",
    "        #print('au')\n",
    "        #print(a.shape)\n",
    "        b = np.zeros(shape=(a.shape[0], 768-a.shape[1]))\n",
    "        #c = np.zeros(shape=(28-a.shape[0], 768))\n",
    "        arr = np.concatenate((a, b), axis=1)\n",
    "        #arr = np.concatenate((arr, c), axis=0)\n",
    "        arr = arr / (1 if(audio_embs == 'wav2vec') else 10 if(audio_embs == 'openl3')  else 1 if(audio_embs == 'pyannoteTitaNet') else 1)\n",
    "        #print(str(arr.max()))\n",
    "        #print(arr.shape)\n",
    "        speaker_emb2 = np.array(arr)\n",
    "        return speaker_emb2\n",
    "\n",
    "def audio_features_preprocess(video_id,cursor_passed):\n",
    "    #  79 belong to pyaudioanalysis\n",
    "    # 111 belogn to liborsa\n",
    "    if(ignore_audio_features):\n",
    "        #print('ignore speech brain')\n",
    "        return np.zeros((190,768))\n",
    "    else:\n",
    "        #print(video_id)\n",
    "        if(cursor_passed != None):\n",
    "            cur = cursor_passed\n",
    "        else:\n",
    "            conAdditional = sl.connect(datasetPathDatabaseAdditional)\n",
    "            cur = conAdditional.cursor()\n",
    "        sql = '''SELECT AUDIO_FEATURES FROM AUDIO WHERE VIDEO_ID = ?'''\n",
    "        cur.execute(sql, [video_id])\n",
    "        audio_features = cur.fetchall()\n",
    "        #print(audio_features[0])\n",
    "        audio_features = pickle.loads(audio_features[0][0])\n",
    "        #print(audio_features.shape) # 190 x 128\n",
    "        audio_features = audio_features[0:190]\n",
    "        \n",
    "        #import sys\n",
    "        #np.set_printoptions(threshold=sys.maxsize)\n",
    "        #print(np.argwhere(audio_features == 0))\n",
    "\n",
    "        if(ignore_pyAudioAnalysis and not ignore_librosa):\n",
    "            zpa = np.zeros((190-110,128))\n",
    "            audio_features = audio_features[80:190]\n",
    "            audio_features = np.vstack((audio_features,zpa))\n",
    "            #print('ignore pyAudioAnalysis')\n",
    "            #print(audio_features.shape)\n",
    "        elif(ignore_librosa and not ignore_pyAudioAnalysis):\n",
    "            zpa = np.zeros((190-80,128))\n",
    "            audio_features = audio_features[0:80]\n",
    "            audio_features = np.vstack((audio_features,zpa))\n",
    "            #print('ignore librosa')\n",
    "            #print(audio_features.shape)\n",
    "        else:\n",
    "            audio_features = np.zeros((190,128))\n",
    "            #print('ignore pyaudioanalysis and librosa')\n",
    "\n",
    "\n",
    "        z1 = np.zeros((190,768-128))\n",
    "        audio_features = np.hstack((audio_features,z1))\n",
    "        audio_features = audio_features / 100.0\n",
    "        #print(audio_features.shape)\n",
    "        if(cursor_passed != None):\n",
    "            pass\n",
    "        else:\n",
    "            cur.close()\n",
    "            conAdditional.close()\n",
    "    return audio_features\n",
    "\n",
    "def audio_transformer_features_preprocess(video_id):\n",
    "    #print(video_id)\n",
    "    conAdditional = sl.connect(datasetPathDatabaseAdditional)\n",
    "    cur = conAdditional.cursor()\n",
    "    sql = '''SELECT AUDIO_FEATURES FROM AUDIO_TRANSFORMER WHERE VIDEO_ID = ?'''\n",
    "    cur.execute(sql, [video_id])\n",
    "    audio_features = cur.fetchall()\n",
    "    #print(audio_features[0])\n",
    "    audio_features = pickle.loads(audio_features[0][0])\n",
    "    #print(audio_features.shape) # 514 x 768\n",
    "    audio_features = audio_features.squeeze()\n",
    "    audio_features = audio_features[0::3]#172*768\n",
    "    #z1 = np.zeros((161,768-128))\n",
    "    #audio_features = np.hstack((audio_features,z1))\n",
    "    #audio_features = audio_features / 100.0\n",
    "    return audio_features\n",
    "\n",
    "import random\n",
    "def image_guide_preprocess(face_id):\n",
    "    #print(face_id)\n",
    "\n",
    "    if(random.random() > 2):\n",
    "        image_guide = np.zeros((49,768))\n",
    "        #print(image_guide.shape)\n",
    "    else:\n",
    "        conAdditional = sl.connect(datasetPathDatabaseVgg)\n",
    "        cur = conAdditional.cursor()\n",
    "        sql = '''SELECT BLURRED_FACE_EMB FROM FACES_BLURRED WHERE FACE_ID = ?'''\n",
    "        cur.execute(sql, [face_id])\n",
    "        image_guide = cur.fetchall()\n",
    "        #print(image_guide)\n",
    "        image_guide = pickle.loads(image_guide[0][0])\n",
    "        image_guide = image_guide.squeeze() #197 x 768\n",
    "        image_guide = image_guide[1::4] #49 x 768\n",
    "    return image_guide\n",
    "\n",
    "\n",
    "#boxBlurMin =  int(configParser.get('extractVggBlurred', 'boxBlurMin'))\n",
    "#boxBlurMax =  int(configParser.get('extractVggBlurred', 'boxBlurMax'))\n",
    "\n",
    "#gaussianBlurMin =  int(configParser.get('extractVggBlurred', 'gaussianBlurMin'))\n",
    "#gaussianBlurMax =  int(configParser.get('extractVggBlurred', 'gaussianBlurMax'))\n",
    "\n",
    "\n",
    "from PIL import Image,ImageFilter\n",
    "import random\n",
    "#import cv2\n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt\n",
    "  \n",
    "\n",
    "\n",
    "def image_guide_preprocess_low_res_dummy(path):\n",
    "    #print(face_id)\n",
    "\n",
    "    image_guide = np.zeros((1, 768))\n",
    "    return image_guide\n",
    "\n",
    "def image_guide_preprocess_low_res(path):\n",
    "    #print(face_id)\n",
    "\n",
    "\n",
    "    if(ignore_image_guide):\n",
    "        return np.nan\n",
    "    else:\n",
    "\n",
    "        image = Image.open(path).convert('RGB')\n",
    "\n",
    "        #print(image.size)\n",
    "\n",
    "        w_s = image_size / (1+2 * 0.4)\n",
    "        h_s = image_size / (1+2 * 0.4)\n",
    "\n",
    "        image = image.crop((0.2*w_s, 0.0*h_s, 1.6*w_s, 1.4*h_s))\n",
    "\n",
    "        image = image.resize((image_size,image_size))\n",
    "\n",
    "        image = image.resize((begin_with_image_size,begin_with_image_size))\n",
    "        im = image\n",
    "        \n",
    "\n",
    "        #print('saving')\n",
    "        #image.save('opop.png')\n",
    "\n",
    "        #print(np.array(image,np.float32).shape)\n",
    "\n",
    "        pix = np.array(image, np.float32)\n",
    "        pix = np.moveaxis(pix, -1, 0)\n",
    "\n",
    "        pix = pix / 255\n",
    "        image.close()\n",
    "        im.close()\n",
    "        return pix\n",
    "    return image_guide\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def process_age(age):\n",
    "    if(random.random() < 0.2 or ignore_age or ignore_additional_attributes):\n",
    "        x = np.zeros(768)\n",
    "        x[767] = 1\n",
    "        return x\n",
    "    else:\n",
    "        try:\n",
    "            x = np.ones(768) * (age / 100.0)\n",
    "            x[767] = 0\n",
    "        except:\n",
    "            x = np.zeros(768)\n",
    "            x[767] = 1\n",
    "\n",
    "        return x\n",
    "\n",
    "def process_gender(gender):\n",
    "    if(random.random() < 0.2 or ignore_gender or ignore_additional_attributes):\n",
    "        return np.zeros(768)\n",
    "    elif(gender == 'man'):\n",
    "        return np.ones(768)\n",
    "    elif(gender == \"woman\"):\n",
    "        return np.ones(768) * -1\n",
    "    else:\n",
    "        return np.zeros(768)\n",
    "    \n",
    "# TODO\n",
    "def process_ethnicity(eth):\n",
    "    x = np.zeros(768)\n",
    "    if(random.random() < 0.2 or ignore_ethnicity or ignore_additional_attributes):\n",
    "        x = x\n",
    "    elif(eth == \"indian\"):\n",
    "        x[0] = 1\n",
    "    elif(eth == \"asian\"):\n",
    "        x[16]=1\n",
    "    elif(eth == \"latino hispanic\"):\n",
    "        x[2]=1\n",
    "    elif(eth == \"black\"):\n",
    "        x[3]=1\n",
    "    elif(eth == \"middle eastern\"):\n",
    "        x[4]=1\n",
    "    elif(eth == \"white\"):\n",
    "        x[5]=1 \n",
    "    else:\n",
    "        x = x\n",
    "    return x     \n",
    "\n",
    "def process_language(lan):\n",
    "    x = np.zeros(768)\n",
    "    if(random.random() < 0.2 or ignore_language_spoken or ignore_additional_attributes):\n",
    "        x = x\n",
    "    elif(lan == \"Arabic\"):\n",
    "        x[0] = 1\n",
    "    elif(lan == \"Portuguese\"):\n",
    "        x[16]=1\n",
    "    elif(lan == \"Romansh_Sursilvan\"):\n",
    "        x[2]=1\n",
    "    elif(lan == \"Japanese\"):\n",
    "        x[3]=1\n",
    "    elif(lan == \"Ukranian\"):\n",
    "        x[4]=1\n",
    "    elif(lan == \"German\"):\n",
    "        x[5]=1   \n",
    "    elif(lan == \"Chinese_China\"):\n",
    "        x[6]=1   \n",
    "    elif(lan == \"Welsh\"):\n",
    "        x[7]=1  \n",
    "    elif(lan == \"English\"):\n",
    "        x[8]=1\n",
    "    elif(lan == \"Kabyle\"):\n",
    "        x[9]=1 \n",
    "    elif(lan == \"Kyrgyz\"):\n",
    "        x[10]=1\n",
    "    elif(lan == \"Georgian\"):\n",
    "        x[11]=1\n",
    "    elif(lan == \"Persian\"):\n",
    "        x[12]=1 \n",
    "    elif(lan == \"French\"):\n",
    "        x[13]=1\n",
    "    elif(lan == \"Interlingua\"):\n",
    "        x[14]=1\n",
    "    elif(lan == \"Swedish\"):\n",
    "        x[15]=1\n",
    "    elif(lan == \"Spanish\"):\n",
    "        x[16]=1 \n",
    "    elif(lan == \"Dhivehi\"):\n",
    "        x[17]=1\n",
    "    elif(lan == \"Kinyarwanda\"):\n",
    "        x[18]=1 \n",
    "    elif(lan == \"Tatar\"):\n",
    "        x[19]=1\n",
    "    elif(lan == \"Hakha_Chin\"):\n",
    "        x[20]=1 \n",
    "    elif(lan == \"Tamil\"):\n",
    "        x[21]=1 \n",
    "    elif(lan == \"Greek\"):\n",
    "        x[22]=1\n",
    "    elif(lan == \"Latvian\"):\n",
    "        x[23]=1 \n",
    "    elif(lan == \"Russian\"):\n",
    "        x[24]=1\n",
    "    elif(lan == \"Breton\"):\n",
    "        x[25]=1\n",
    "    elif(lan == \"Catalan\"):\n",
    "        x[26]=1    \n",
    "    elif(lan == \"Maltese\"):\n",
    "        x[27]=1 \n",
    "    elif(lan == \"Slovenian\"):\n",
    "        x[28]=1    \n",
    "    elif(lan == \"Indonesian\"):\n",
    "        x[29]=1    \n",
    "    elif(lan == \"Dutch\"):\n",
    "        x[30]=1\n",
    "    elif(lan == \"Chinese_Taiwan\"):\n",
    "        x[31]=1 \n",
    "    elif(lan == \"Sakha\"):\n",
    "        x[32]=1 \n",
    "    elif(lan == \"Polish\"):\n",
    "        x[33]=1 \n",
    "    elif(lan == \"Czech\"):\n",
    "        x[34]=1 \n",
    "    elif(lan == \"Romanian\"):\n",
    "        x[35]=1 \n",
    "    elif(lan == \"Mangolian\"):\n",
    "        x[36]=1 \n",
    "    elif(lan == \"Italian\"):\n",
    "        x[37]=1 \n",
    "    elif(lan == \"Chinese_Hongkong\"):\n",
    "        x[38]=1 \n",
    "    elif(lan == \"Estonian\"):\n",
    "        x[39]=1 \n",
    "    elif(lan == \"Basque\"):\n",
    "        x[40]=1 \n",
    "    elif(lan == \"Esperanto\"):\n",
    "        x[41]=1 \n",
    "    elif(lan == \"Frisian\"):\n",
    "        x[42]=1 \n",
    "    elif(lan == \"Turkish\"):\n",
    "        x[43]=1 \n",
    "    elif(lan == \"Chuvash\"):\n",
    "        x[44]=1 \n",
    "    else:\n",
    "        x = x\n",
    "    return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_input(row):\n",
    "    #print(row)\n",
    "    age = row[\"caption_a\"]\n",
    "    ethnicity=row[\"caption_e\"]\n",
    "    gender=row[\"caption_g\"]\n",
    "    language=row[\"caption_l\"]\n",
    "    speaker_emb=row[\"SPEAKER_EMB\"]\n",
    "    audio_emb=row[\"AUDIO_EMB\"]\n",
    "    audio_features=row[\"AUDIO_FEATURES\"]\n",
    "    image_guide=row[\"image_guide\"]\n",
    "    #print(image_guide)\n",
    "    #print(speaker_emb)\n",
    "    speaker_emb = np.asarray(speaker_emb, dtype=np.float32)\n",
    "    speaker_emb = speaker_emb.squeeze()\n",
    "    audio_emb = np.asarray(audio_emb, dtype=np.float32)\n",
    "    audio_emb = audio_emb.squeeze()\n",
    "    #print(speaker_emb.shape)\n",
    "    h = np.vstack((age, ethnicity))\n",
    "    h = np.vstack((h, gender))\n",
    "    h = np.vstack((h, language))\n",
    "    h = np.vstack((h, speaker_emb))\n",
    "    h = np.vstack((h, audio_emb))\n",
    "    h = np.vstack((h,audio_features))\n",
    "    h = np.vstack((h,image_guide))\n",
    "    #print('aaaaaaaaaaa')\n",
    "    #print(h.shape)\n",
    "    j = np.zeros(768)\n",
    "    j = np.tile(j,(256-h.shape[0],1))\n",
    "    h = np.vstack((h, j))\n",
    "    #print(h.shape)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image_path(path):\n",
    "    \n",
    "    image = Image.open(path).convert('RGB')\n",
    "\n",
    "    w_s = image_size / (1+2 * 0.4)\n",
    "    h_s = image_size / (1+2 * 0.4)\n",
    "\n",
    "    #print(image.size)\n",
    "    image = image.crop((0.2*w_s,0.0*h_s,1.6*w_s,1.4*h_s))\n",
    "    image = image.resize((image_size,image_size))\n",
    "\n",
    "    #print('saving')\n",
    "    #image.save(str(random.random()) + '.png')\n",
    "\n",
    "    \n",
    "\n",
    "    #print(np.array(image,np.float32).shape)\n",
    "    pix = np.array(image,np.float32)\n",
    "    pix = np.moveaxis(pix, -1, 0)\n",
    "    \n",
    "    pix = pix / 255\n",
    "    image.close()\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor,Compose\n",
    "import dask.dataframe as dd\n",
    "from multiprocessing import Manager,RLock,Value,Queue\n",
    "import ctypes\n",
    "from random import randrange\n",
    "import random\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    total_rows = None\n",
    "    con = None\n",
    "    con_additional = None\n",
    "    lock = None\n",
    "    samples_seen =  Value('i', 0,lock=False)\n",
    "    c = None\n",
    "    c_additional = None\n",
    "    \n",
    "    def no_of_samples_seen(self):\n",
    "        return self.samples_seen.value\n",
    "\n",
    "    def samples_seen_multiple_times(self,no_of_samples_seen_value,multiple_times):\n",
    "        self.lock.acquire(block=True)\n",
    "        self.samples_seen.value = self.samples_seen.value + (no_of_samples_seen_value * (multiple_times - 1))\n",
    "        self.lock.release()\n",
    "\n",
    "    def __init__(self,datasetPathDatabase_a,lock,last_sample_no,datasetPathDatabaseAdditional_a):\n",
    "        self.lock = lock\n",
    "        self.samples_seen.value = last_sample_no\n",
    "        self.con = sl.connect(datasetPathDatabase_a)\n",
    "        self.con.isolation_level = None\n",
    "        self.c = self.con.cursor()\n",
    "        self.c.execute(\"PRAGMA journal_mode=OFF\")\n",
    "        self.c.execute(\"begin\")\n",
    "\n",
    "        print(datasetPathDatabase_a)\n",
    "        print(datasetPathDatabaseAdditional_a)\n",
    "\n",
    "        \n",
    "        self.con_additional = sl.connect(datasetPathDatabaseAdditional_a,check_same_thread=False)\n",
    "        self.con_additional.isolation_level = None\n",
    "        self.c_additional = self.con_additional.cursor()\n",
    "        self.c_additional.execute(\"PRAGMA journal_mode=OFF\")\n",
    "        self.c_additional.execute(\"begin\")\n",
    "        pass\n",
    "\n",
    "    def destroy(self):\n",
    "        self.lock.acquire(block=True)\n",
    "        self.c.execute(\"commit\")\n",
    "        self.c.close()\n",
    "        self.con.close()\n",
    "\n",
    "        self.c_additional.execute(\"commit\")\n",
    "        self.c_additional.close()\n",
    "        self.con_additional.close()\n",
    "\n",
    "        self.lock.release()\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        if(self.total_rows == None):\n",
    "            self.lock.acquire(block=True)\n",
    "            data = self.con.execute(\"select count(V2.ID) from VIDEO v2 WHERE  AUDIO_PRE IN (3,4) AND FACES_PRE = 2 \")\n",
    "            count = data.fetchall()\n",
    "            self.total_rows = count[0][0]\n",
    "            data.close()\n",
    "            print(\"Found \" + str(self.total_rows) + \" data points.\")\n",
    "\n",
    "            #data = self.con.execute(\"SELECT COUNT(*) FROM VIDEO v WHERE V.TRAINED = 1\")\n",
    "            #count = data.fetchall()\n",
    "            #data.close()\n",
    "            #self.samples_seen.value = count[0][0]\n",
    "            #print(\"Starting from \" + str(self.samples_seen.value) + \" data points.\")\n",
    "            self.lock.release()\n",
    "\n",
    "        return self.total_rows\n",
    "    def get_row_data(self,idx):\n",
    "\n",
    "        sql = (\"SELECT V.ID,F.ID,V.VIDEO_PATH, V.AGE CAPTION_A, \" + \n",
    "                            \"V.ETHNICITY CAPTION_E, \" +\n",
    "                            \"lower(V.GENDER) CAPTION_G, \" +\n",
    "                                \"A.SPEAKER_EMB, \"+ (\"A.WAV_TO_VEC, \" if(audio_embs == 'wav2vec') else \"A.AUDIO_EMB2, \" if(audio_embs == 'openl3')  else \"A.PYANNOTE_TITANET, \" if(audio_embs == 'pyannoteTitaNet') else ', ') +\n",
    "                            \"A.AUDIO_FEATURES, \" +\n",
    "                            \"A.LANG CAPTION_L, \"+\n",
    "                            \"F.FACE_PATH \"+\n",
    "                            \"FROM VIDEO V \"+\n",
    "                            \"INNER JOIN AUDIO A ON V.ID = A.VIDEO_ID \" +\n",
    "                            \"INNER JOIN FACE F ON F.ID = (select ID from FACE f2 where f2.video_id = v.ID ORDER By ID limit 1 ) \" + \n",
    "                            \"WHERE AUDIO_LENGTH = \" + audio_length_used + ' ' +\n",
    "                            \"AND V.ID in (select V2.ID from VIDEO v2 WHERE  AUDIO_PRE IN (3,4) AND FACES_PRE = 2 LIMIT  1 OFFSET \" +str(idx) + \" )\" )\n",
    "        data = self.con.execute(sql)\n",
    "        dataGotten = data.fetchall()\n",
    "        df = pd.DataFrame(dataGotten,columns = ['ID','FACE_ID','VIDEO_PATH','caption_a','caption_e','caption_g','SPEAKER_EMB','AUDIO_EMB','AUDIO_FEATURES','caption_l','image_path'])\n",
    "        data.close()\n",
    "        return df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.lock.acquire(block=True)\n",
    "        #print(str(idx) + \"/n\")\n",
    "        while True:\n",
    "            df = self.get_row_data(idx)\n",
    "            if(len(df) != 0):\n",
    "                break\n",
    "            print(\"retrying for data\")\n",
    "            idx = random.randint(1, self.total_rows)\n",
    "        #print(df)\n",
    "        \n",
    "        self.samples_seen.value +=  1\n",
    "        print (self.samples_seen.value,end='\\r')\n",
    "\n",
    "\n",
    "        self.lock.release()\n",
    "\n",
    "        \n",
    "        \n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "        df = dd.from_pandas(df, npartitions=1)\n",
    "        df[\"image_guide\"] = np.nan\n",
    "\n",
    "        #print(df.head(10))\n",
    "        data_frame = df[[\"ID\",\"FACE_ID\",\"image_path\",\"caption_a\",\"caption_e\",\"caption_g\",\"caption_l\"]]\n",
    "        data_frame['SPEAKER_EMB'] = df['SPEAKER_EMB']\n",
    "        data_frame['AUDIO_EMB'] = df['AUDIO_EMB']\n",
    "        data_frame['image_guide'] = df['image_guide']\n",
    "\n",
    "        \n",
    "        data_frame['SPEAKER_EMB'] = data_frame['SPEAKER_EMB'].apply(lambda x: speaker_emb_preprocess(x),meta=('1', 'object'))\n",
    "        data_frame['AUDIO_EMB'] = data_frame['AUDIO_EMB'].apply(lambda x: audio_emb_preprocess2(x),meta=('1', 'object'))\n",
    "        data_frame['AUDIO_FEATURES'] = data_frame['ID'].apply(lambda x: audio_features_preprocess(x,self.c_additional),meta=('1', 'object'))\n",
    "        data_frame = data_frame.drop(['ID'], axis=1)\n",
    "        data_frame['image_guide'] = data_frame['image_path'].apply(lambda x: image_guide_preprocess_low_res_dummy(x),meta=('1', 'str'))\n",
    "        data_frame = data_frame.drop(['FACE_ID'], axis=1)\n",
    "        data_frame['caption_a'] = data_frame['caption_a'].apply(lambda x: process_age(x),meta=('1', 'object'))\n",
    "        data_frame['caption_g'] = data_frame['caption_g'].apply(lambda x: process_gender(x),meta=('1', 'object'))\n",
    "        data_frame['caption_l'] = data_frame['caption_l'].apply(lambda x: process_language(x),meta=('1', 'object'))\n",
    "        data_frame['caption_e'] = data_frame['caption_e'].apply(lambda x: process_ethnicity(x),meta=('1', 'object'))\n",
    "        data_frame['low_res_image'] = data_frame['image_path'].apply(lambda x: image_guide_preprocess_low_res(x),meta=('1', 'object'))\n",
    "\n",
    "        data_frame['INPUT'] = data_frame['SPEAKER_EMB']\n",
    "        #print(data_frame)\n",
    "\n",
    "        data_frame['INPUT'] = data_frame.apply(process_input,args=(),axis=1,meta=('1', 'object'))\n",
    "\n",
    "        #for index, row in data_frame.iterrows():\n",
    "        #    x =946922              data_frame.loc[index,\"caption_l\"],data_frame.loc[index,\"SPEAKER_EMB\"],\n",
    "        #                    data_frame.loc[index,\"AUDIO_EMB\"],data_frame.loc[index,\"AUDIO_FEATURES\"],\n",
    "        #                    data_frame.loc[index,\"image_guide\"])\n",
    "        #    x = [x]\n",
    "        #    #AADFS = AADFS\n",
    "        #    data_frame.loc[index,\"INPUT\"] = x\n",
    "\n",
    "        data_frame = data_frame.drop(['caption_e', 'caption_g','caption_l','SPEAKER_EMB','AUDIO_EMB'], axis=1)\n",
    "\n",
    "\n",
    "        data_frame['image_path'] = data_frame['image_path'].apply(lambda x: process_image_path(x),meta=('1', 'str'))\n",
    "        data_frame.compute()\n",
    "\n",
    "        part = data_frame[['INPUT','image_path','low_res_image']].partitions[0]\n",
    "\n",
    "                \n",
    "\n",
    "        input0 = np.array(part['INPUT'])\n",
    "        input0 = np.array([np.array(xi) for xi in input0])\n",
    "        input0[np.isnan(input0)] = 0\n",
    "        input0[input0 > 10] = 10\n",
    "        input0[input0 < -10] = -10\n",
    "        #print(sys.getsizeof(input))\n",
    "        \n",
    "        output = np.array(part['image_path'])\n",
    "        output = np.array([np.array(xi) for xi in output])\n",
    "        output.squeeze().shape\n",
    "        #print(sys.getsizeof(output))\n",
    "\n",
    "        input2 = np.array(part['low_res_image'])\n",
    "        input2 = np.array([np.array(xi) for xi in input2])\n",
    "        input2.squeeze()\n",
    "        #print(sys.getsizeof(input2))\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        #print(len(procs))\n",
    "        #if(len(procs) > 0):\n",
    "        #    procs[0].join() # Wait for previous process to finish\n",
    "        #    print(\"Model trained using a batch of data...\")\n",
    "        #    prProcess,\n",
    "        input0 = torch.from_numpy(input0)\n",
    "        input0 = input0.to(torch.float)\n",
    "\n",
    "\n",
    "        input2 = torch.from_numpy(input2)\n",
    "        input2 = input2.to(torch.float)\n",
    "\n",
    "        output = torch.from_numpy(output)\n",
    "        output = output.to(torch.float)\n",
    "\n",
    "        input0 = input0.squeeze()\n",
    "        input2 = input2.squeeze()\n",
    "        output = output.squeeze()\n",
    "\n",
    "        return output,input0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(sample_no,loss_value):\n",
    "\n",
    "    if(UNET == 1):\n",
    "        my_file = Path(model_filename + '/loss_total_1.picke')\n",
    "        if my_file.is_file():\n",
    "            with open(model_filename + '/loss_total_1.picke', 'rb') as handle:\n",
    "                loss_total = pickle.load(handle)\n",
    "        else:\n",
    "            loss_total = []\n",
    "    else:\n",
    "        my_file = Path(model_filename + '/loss_total_2.picke')\n",
    "        if my_file.is_file():\n",
    "            with open(model_filename + '/loss_total_2.picke', 'rb') as handle:\n",
    "                loss_total = pickle.load(handle)\n",
    "        else:\n",
    "            loss_total = []\n",
    "    \n",
    "    #print(loss_list)\n",
    "    #print(loss_total)\n",
    "    loss_total.append([sample_no,loss_value])\n",
    "\n",
    "    if(UNET == 1):\n",
    "        with open(model_filename +'/loss_total_1.picke', 'wb') as handle:\n",
    "            pickle.dump(loss_total, handle)\n",
    "    else:\n",
    "        with open(model_filename +'/loss_total_2.picke', 'wb') as handle:\n",
    "            pickle.dump(loss_total, handle)\n",
    "    #print(loss_total)\n",
    "    fig = plt.figure()\n",
    "    x_val = [x[0] for x in loss_total]\n",
    "    y_val = [x[1] for x in loss_total]\n",
    "    plt.plot(x_val,y_val)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Training Sample\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    if(UNET == 1):\n",
    "        if(os.path.isfile(model_filename + '/loss_1_plot.png')):\n",
    "            os.remove(model_filename + '/loss_1_plot.png')\n",
    "        fig.savefig(model_filename + '/loss_1_plot.png')\n",
    "    else:\n",
    "        if(os.path.isfile(model_filename + '/loss_2_plot.png')):\n",
    "            os.remove(model_filename + '/loss_2_plot.png')\n",
    "        fig.savefig(model_filename + '/loss_2_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    try:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(x_val[1000::],y_val[1000::]\n",
    "                ,'.',zorder=-100)\n",
    "\n",
    "        #plt.axvline(x=1000,linestyle='--',color='green',label='1000 inner epochs')\n",
    "        #plt.axvline(x=17000,linestyle='--',color='purple',label='100 inner epochs - 100000 unique samples seen' )\n",
    "        #plt.axvline(x=23100,linestyle='-.',color='black',label='1 inner epoch - end of 1st epoch ')\n",
    "        #plt.legend(bbox_to_anchor = (1.0, 1), loc = 'upper right')\n",
    "        plt.grid()\n",
    "        yhat = savgol_filter(y_val, 1000, 3)\n",
    "        plt.plot(x_val[1000::],yhat[1000::],'r')\n",
    "        plt.title(\"Training Loss\")\n",
    "        plt.xlabel(\"Training Sample\")\n",
    "        plt.ylabel(\"MSE Loss\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if(UNET == 1):\n",
    "            if(os.path.isfile(model_filename + '/loss_zoomed_1_plot.png')):\n",
    "                os.remove(model_filename + '/loss_zoomed_1_plot.png')\n",
    "            fig.savefig(model_filename + '/loss_zoomed_1_plot.png')\n",
    "        else:\n",
    "            if(os.path.isfile(model_filename + '/loss_zoomed_2_plot.png')):\n",
    "                os.remove(model_filename + '/loss_zoomed_2_plot.png')\n",
    "            fig.savefig(model_filename + '/loss_zoomed_2_plot.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            plt.close()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sample_no = 0\n",
    "if(UNET == 1):\n",
    "    my_file = Path(model_filename + '/last_sample_no1.picke')\n",
    "    if my_file.is_file():\n",
    "        with open(model_filename + '/last_sample_no1.picke', 'rb') as handle:\n",
    "            last_sample_no = pickle.load(handle)\n",
    "else:\n",
    "    my_file = Path(model_filename + '/last_sample_no2.picke')\n",
    "    if my_file.is_file():\n",
    "        with open(model_filename + '/last_sample_no2.picke', 'rb') as handle:\n",
    "            last_sample_no = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gamal/Passport/Datasets/VoxCeleb2/Voxceleb2Database/dataset.db\n",
      "/media/gamal/Passport/Datasets/VoxCeleb2/Voxceleb2Database/datasetAdditional.db\n",
      "Found 402440 data points.\n",
      "402440\n"
     ]
    }
   ],
   "source": [
    "my_dataset = CustomDataset(datasetPathDatabase,RLock(),last_sample_no,datasetPathDatabaseAdditional)\n",
    "print(len(my_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = DataLoader(my_dataset,batch_size = batch_size * 16,shuffle=True,num_workers=16) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349842\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m test_images, test_labels \u001b[39min\u001b[39;00m my_dataloader:  \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349926\r"
     ]
    }
   ],
   "source": [
    "#for test_images, test_labels in my_dataloader:  \n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint loaded from /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8002.pt\n",
      "loss: 0.02090453536948189\n",
      "epoch:1 from 100000\n",
      "loss: 0.020589689258486032\n",
      "epoch:2 from 100000\n",
      "loss: 0.019329565693624318\n",
      "epoch:3 from 100000\n",
      "loss: 0.0162459968123585\n",
      "epoch:4 from 100000\n",
      "loss: 0.02100005268584937\n",
      "epoch:5 from 100000\n",
      "loss: 0.018247329368023202\n",
      "epoch:6 from 100000\n",
      "loss: 0.01712001796113327\n",
      "epoch:7 from 100000\n",
      "loss: 0.017070956295356154\n",
      "epoch:8 from 100000\n",
      "loss: 0.020060712995473295\n",
      "epoch:9 from 100000\n",
      "loss: 0.01898198830895126\n",
      "epoch:10 from 100000\n",
      "loss: 0.021063693799078465\n",
      "epoch:11 from 100000\n",
      "loss: 0.020927699864841998\n",
      "epoch:12 from 100000\n",
      "loss: 0.020600256975740194\n",
      "epoch:13 from 100000\n",
      "loss: 0.01945403404533863\n",
      "epoch:14 from 100000\n",
      "loss: 0.020195597899146378\n",
      "epoch:15 from 100000\n",
      "loss: 0.020330890198238194\n",
      "epoch:16 from 100000\n",
      "loss: 0.01854440983152017\n",
      "epoch:17 from 100000\n",
      "loss: 0.01993389835115522\n",
      "epoch:18 from 100000\n",
      "loss: 0.02145336364628747\n",
      "epoch:19 from 100000\n",
      "loss: 0.01840634911786765\n",
      "epoch:20 from 100000\n",
      "loss: 0.022011070337612182\n",
      "epoch:21 from 100000\n",
      "loss: 0.019977598451077938\n",
      "epoch:22 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8025.pt\n",
      "loss: 0.018196582910604775\n",
      "epoch:23 from 100000\n",
      "loss: 0.020237410382833332\n",
      "epoch:24 from 100000\n",
      "loss: 0.020535829913569614\n",
      "epoch:25 from 100000\n",
      "loss: 0.021157665585633367\n",
      "epoch:26 from 100000\n",
      "loss: 0.018268207379151136\n",
      "epoch:27 from 100000\n",
      "loss: 0.01851017164881341\n",
      "epoch:28 from 100000\n",
      "loss: 0.017704813741147518\n",
      "epoch:29 from 100000\n",
      "loss: 0.017856465361546725\n",
      "epoch:30 from 100000\n",
      "loss: 0.023235529370140284\n",
      "epoch:31 from 100000\n",
      "loss: 0.01966813049511984\n",
      "epoch:32 from 100000\n",
      "loss: 0.020472999836783856\n",
      "epoch:33 from 100000\n",
      "993946loss: 0.01932108122855425\n",
      "epoch:34 from 100000\n",
      "loss: 0.02212467504432425\n",
      "epoch:35 from 100000\n",
      "loss: 0.019860692555084825\n",
      "epoch:36 from 100000\n",
      "loss: 0.017478392517659813\n",
      "epoch:37 from 100000\n",
      "loss: 0.017551730037666857\n",
      "epoch:38 from 100000\n",
      "loss: 0.01839518075576052\n",
      "epoch:39 from 100000\n",
      "loss: 0.02100247220369056\n",
      "epoch:40 from 100000\n",
      "loss: 0.01623414020286873\n",
      "epoch:41 from 100000\n",
      "loss: 0.01803187173209153\n",
      "epoch:42 from 100000\n",
      "loss: 0.018957184976898134\n",
      "epoch:43 from 100000\n",
      "loss: 0.020016405906062573\n",
      "epoch:44 from 100000\n",
      "loss: 0.021219100162852556\n",
      "epoch:45 from 100000\n",
      "loss: 0.018720632302574813\n",
      "epoch:46 from 100000\n",
      "loss: 0.01938737672753632\n",
      "epoch:47 from 100000\n",
      "loss: 0.018178355792770162\n",
      "epoch:48 from 100000\n",
      "loss: 0.018622116651386023\n",
      "epoch:49 from 100000\n",
      "loss: 0.020670945348683745\n",
      "epoch:50 from 100000\n",
      "loss: 0.02077369682956487\n",
      "epoch:51 from 100000\n",
      "loss: 0.01893709064461291\n",
      "epoch:52 from 100000\n",
      "loss: 0.020602759846951813\n",
      "epoch:53 from 100000\n",
      "loss: 0.019497562432661653\n",
      "epoch:54 from 100000\n",
      "loss: 0.020272284920793027\n",
      "epoch:55 from 100000\n",
      "loss: 0.02072303427848965\n",
      "epoch:56 from 100000\n",
      "loss: 0.01977216440718621\n",
      "epoch:57 from 100000\n",
      "loss: 0.020095791900530457\n",
      "epoch:58 from 100000\n",
      "loss: 0.017856251739431173\n",
      "epoch:59 from 100000\n",
      "loss: 0.020671838079579175\n",
      "epoch:60 from 100000\n",
      "loss: 0.020571709028445184\n",
      "epoch:61 from 100000\n",
      "loss: 0.01976205490063876\n",
      "epoch:62 from 100000\n",
      "loss: 0.0187708722660318\n",
      "epoch:63 from 100000\n",
      "loss: 0.01803545927396044\n",
      "epoch:64 from 100000\n",
      "loss: 0.019794726744294167\n",
      "epoch:65 from 100000\n",
      "loss: 0.019113577844109386\n",
      "epoch:66 from 100000\n",
      "loss: 0.018708639894612134\n",
      "epoch:67 from 100000\n",
      "loss: 0.01777995185693726\n",
      "epoch:68 from 100000\n",
      "loss: 0.020016973838210106\n",
      "epoch:69 from 100000\n",
      "loss: 0.02076122208382003\n",
      "epoch:70 from 100000\n",
      "999217loss: 0.02007340342970565\n",
      "epoch:71 from 100000\n",
      "loss: 0.021112387359607965\n",
      "epoch:72 from 100000\n",
      "loss: 0.01889814785681665\n",
      "epoch:73 from 100000\n",
      "loss: 0.019392135902307928\n",
      "epoch:74 from 100000\n",
      "loss: 0.01664539595367387\n",
      "epoch:75 from 100000\n",
      "loss: 0.015417381131555885\n",
      "epoch:76 from 100000\n",
      "loss: 0.020621800795197487\n",
      "epoch:77 from 100000\n",
      "loss: 0.023417522897943854\n",
      "epoch:78 from 100000\n",
      "loss: 0.02033123857108876\n",
      "epoch:79 from 100000\n",
      "loss: 0.019182485179044306\n",
      "epoch:80 from 100000\n",
      "loss: 0.020008405961561948\n",
      "epoch:81 from 100000\n",
      "loss: 0.017563575587701052\n",
      "epoch:82 from 100000\n",
      "loss: 0.01952158159110695\n",
      "epoch:83 from 100000\n",
      "loss: 0.020354688225779682\n",
      "epoch:84 from 100000\n",
      "loss: 0.02053291810443625\n",
      "epoch:85 from 100000\n",
      "loss: 0.019272620556876063\n",
      "epoch:86 from 100000\n",
      "loss: 0.01838613790459931\n",
      "epoch:87 from 100000\n",
      "loss: 0.022030015825293958\n",
      "epoch:88 from 100000\n",
      "loss: 0.019886543886968866\n",
      "epoch:89 from 100000\n",
      "loss: 0.018486541463062167\n",
      "epoch:90 from 100000\n",
      "loss: 0.01891155174234882\n",
      "epoch:91 from 100000\n",
      "loss: 0.01979475759435445\n",
      "epoch:92 from 100000\n",
      "1001901loss: 0.020072630810318515\n",
      "epoch:93 from 100000\n",
      "loss: 0.01987293566344306\n",
      "epoch:94 from 100000\n",
      "loss: 0.01873446913668886\n",
      "epoch:95 from 100000\n",
      "loss: 0.019402784120757133\n",
      "epoch:96 from 100000\n",
      "loss: 0.01871707392274402\n",
      "epoch:97 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8100.pt\n",
      "loss: 0.019486660254187882\n",
      "epoch:98 from 100000\n",
      "loss: 0.02097077516373247\n",
      "epoch:99 from 100000\n",
      "loss: 0.020889689272735268\n",
      "epoch:100 from 100000\n",
      "loss: 0.020051417814102024\n",
      "epoch:101 from 100000\n",
      "loss: 0.017236466228496283\n",
      "epoch:102 from 100000\n",
      "loss: 0.018596952024381608\n",
      "epoch:103 from 100000\n",
      "loss: 0.02063147258013487\n",
      "epoch:104 from 100000\n",
      "loss: 0.020133945101406425\n",
      "epoch:105 from 100000\n",
      "loss: 0.01843737665330991\n",
      "epoch:106 from 100000\n",
      "loss: 0.020705555158201605\n",
      "epoch:107 from 100000\n",
      "loss: 0.020271515822969377\n",
      "epoch:108 from 100000\n",
      "loss: 0.020248092361725867\n",
      "epoch:109 from 100000\n",
      "loss: 0.019771134306211025\n",
      "epoch:110 from 100000\n",
      "loss: 0.019224519666749984\n",
      "epoch:111 from 100000\n",
      "loss: 0.02018218132434413\n",
      "epoch:112 from 100000\n",
      "loss: 0.018957385211251676\n",
      "epoch:113 from 100000\n",
      "loss: 0.02245241589844227\n",
      "epoch:114 from 100000\n",
      "loss: 0.01904524871497415\n",
      "epoch:115 from 100000\n",
      "loss: 0.02030045207357034\n",
      "epoch:116 from 100000\n",
      "loss: 0.020064863085281104\n",
      "epoch:117 from 100000\n",
      "loss: 0.017942752107046545\n",
      "epoch:118 from 100000\n",
      "loss: 0.019686605723109096\n",
      "epoch:119 from 100000\n",
      "loss: 0.01860282849520445\n",
      "epoch:120 from 100000\n",
      "loss: 0.017499184235930443\n",
      "epoch:121 from 100000\n",
      "loss: 0.017778459645342082\n",
      "epoch:122 from 100000\n",
      "loss: 0.01985304558183998\n",
      "epoch:123 from 100000\n",
      "loss: 0.019875691272318363\n",
      "epoch:124 from 100000\n",
      "loss: 0.019625568063929677\n",
      "epoch:125 from 100000\n",
      "loss: 0.020105430914554745\n",
      "epoch:126 from 100000\n",
      "loss: 0.021807768614962697\n",
      "epoch:127 from 100000\n",
      "loss: 0.018119373882655054\n",
      "epoch:128 from 100000\n",
      "loss: 0.020083899260498583\n",
      "epoch:129 from 100000\n",
      "loss: 0.01688299363013357\n",
      "epoch:130 from 100000\n",
      "loss: 0.019993929308839142\n",
      "epoch:131 from 100000\n",
      "loss: 0.019948510453104973\n",
      "epoch:132 from 100000\n",
      "loss: 0.019243821618147194\n",
      "epoch:133 from 100000\n",
      "loss: 0.020065633347257972\n",
      "epoch:134 from 100000\n",
      "loss: 0.01953391684219241\n",
      "epoch:135 from 100000\n",
      "loss: 0.019413796544540673\n",
      "epoch:136 from 100000\n",
      "loss: 0.020920510054565966\n",
      "epoch:137 from 100000\n",
      "loss: 0.020010429376270622\n",
      "epoch:138 from 100000\n",
      "loss: 0.017226473602931947\n",
      "epoch:139 from 100000\n",
      "loss: 0.019440789852524176\n",
      "epoch:140 from 100000\n",
      "loss: 0.022106832824647427\n",
      "epoch:141 from 100000\n",
      "loss: 0.017806426039896905\n",
      "epoch:142 from 100000\n",
      "loss: 0.019897593010682613\n",
      "epoch:143 from 100000\n",
      "loss: 0.020612336578778923\n",
      "epoch:144 from 100000\n",
      "loss: 0.019998656876850873\n",
      "epoch:145 from 100000\n",
      "loss: 0.019723613280802965\n",
      "epoch:146 from 100000\n",
      "loss: 0.018718342296779156\n",
      "epoch:147 from 100000\n",
      "loss: 0.018203901941888034\n",
      "epoch:148 from 100000\n",
      "loss: 0.01906292061903514\n",
      "epoch:149 from 100000\n",
      "loss: 0.020661271351855248\n",
      "epoch:150 from 100000\n",
      "loss: 0.01801089441869408\n",
      "epoch:151 from 100000\n",
      "loss: 0.01914000982651487\n",
      "epoch:152 from 100000\n",
      "loss: 0.018669732788112015\n",
      "epoch:153 from 100000\n",
      "loss: 0.01999702292960137\n",
      "epoch:154 from 100000\n",
      "loss: 0.021617200574837625\n",
      "epoch:155 from 100000\n",
      "loss: 0.018531116016674787\n",
      "epoch:156 from 100000\n",
      "loss: 0.019372896756976843\n",
      "epoch:157 from 100000\n",
      "1012135loss: 0.01895184285240248\n",
      "epoch:158 from 100000\n",
      "loss: 0.02031164092477411\n",
      "epoch:159 from 100000\n",
      "loss: 0.020429428608622402\n",
      "epoch:160 from 100000\n",
      "loss: 0.017878228798508644\n",
      "epoch:161 from 100000\n",
      "loss: 0.01980400749016553\n",
      "epoch:162 from 100000\n",
      "loss: 0.02012392968754284\n",
      "epoch:163 from 100000\n",
      "loss: 0.017784905736334622\n",
      "epoch:164 from 100000\n",
      "loss: 0.016982341650873423\n",
      "epoch:165 from 100000\n",
      "loss: 0.019212153390981257\n",
      "epoch:166 from 100000\n",
      "loss: 0.01894619921222329\n",
      "epoch:167 from 100000\n",
      "loss: 0.018088248558342457\n",
      "epoch:168 from 100000\n",
      "loss: 0.01966141231241636\n",
      "epoch:169 from 100000\n",
      "loss: 0.018062151793856174\n",
      "epoch:170 from 100000\n",
      "loss: 0.02097219630377367\n",
      "epoch:171 from 100000\n",
      "loss: 0.016378895641537383\n",
      "epoch:172 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8175.pt\n",
      "loss: 0.018599613045807928\n",
      "epoch:173 from 100000\n",
      "1014766loss: 0.022348053171299398\n",
      "epoch:174 from 100000\n",
      "loss: 0.022073695668950677\n",
      "epoch:175 from 100000\n",
      "loss: 0.022569131455384195\n",
      "epoch:176 from 100000\n",
      "loss: 0.01929381105583161\n",
      "epoch:177 from 100000\n",
      "loss: 0.01944076834479347\n",
      "epoch:178 from 100000\n",
      "loss: 0.02249057311564684\n",
      "epoch:179 from 100000\n",
      "loss: 0.019043717125896364\n",
      "epoch:180 from 100000\n",
      "loss: 0.02003526350017637\n",
      "epoch:181 from 100000\n",
      "loss: 0.019445471349172294\n",
      "epoch:182 from 100000\n",
      "loss: 0.02006593206897378\n",
      "epoch:183 from 100000\n",
      "loss: 0.020407715579494834\n",
      "epoch:184 from 100000\n",
      "loss: 0.019461762625724077\n",
      "epoch:185 from 100000\n",
      "loss: 0.02098990010563284\n",
      "epoch:186 from 100000\n",
      "loss: 0.017293494078330696\n",
      "epoch:187 from 100000\n",
      "loss: 0.01874438696540892\n",
      "epoch:188 from 100000\n",
      "loss: 0.020434904959984124\n",
      "epoch:189 from 100000\n",
      "loss: 0.01824062690138817\n",
      "epoch:190 from 100000\n",
      "loss: 0.01829705771524459\n",
      "epoch:191 from 100000\n",
      "loss: 0.021663559426087886\n",
      "epoch:192 from 100000\n",
      "loss: 0.019944444415159523\n",
      "epoch:193 from 100000\n",
      "loss: 0.01938741991762072\n",
      "epoch:194 from 100000\n",
      "loss: 0.017605226137675345\n",
      "epoch:195 from 100000\n",
      "loss: 0.019047899753786623\n",
      "epoch:196 from 100000\n",
      "loss: 0.019280505483038723\n",
      "epoch:197 from 100000\n",
      "loss: 0.021809327066875994\n",
      "epoch:198 from 100000\n",
      "loss: 0.020959190267603844\n",
      "epoch:199 from 100000\n",
      "loss: 0.01998630748130381\n",
      "epoch:200 from 100000\n",
      "loss: 0.01947622641455382\n",
      "epoch:201 from 100000\n",
      "loss: 0.018532400048570707\n",
      "epoch:202 from 100000\n",
      "loss: 0.01934126840205863\n",
      "epoch:203 from 100000\n",
      "loss: 0.01975027285516262\n",
      "epoch:204 from 100000\n",
      "loss: 0.02090882364427671\n",
      "epoch:205 from 100000\n",
      "loss: 0.018441546359099448\n",
      "epoch:206 from 100000\n",
      "loss: 0.020274734706617892\n",
      "epoch:207 from 100000\n",
      "retrying for data\n",
      "loss: 0.021824908501002938\n",
      "epoch:208 from 100000\n",
      "loss: 0.02021166664781049\n",
      "epoch:209 from 100000\n",
      "loss: 0.018281402648426592\n",
      "epoch:210 from 100000\n",
      "loss: 0.020999459724407643\n",
      "epoch:211 from 100000\n",
      "loss: 0.020384998992085457\n",
      "epoch:212 from 100000\n",
      "loss: 0.02029594936175272\n",
      "epoch:213 from 100000\n",
      "loss: 0.018849530431907624\n",
      "epoch:214 from 100000\n",
      "loss: 0.01940081996144727\n",
      "epoch:215 from 100000\n",
      "loss: 0.01792979141464457\n",
      "epoch:216 from 100000\n",
      "loss: 0.019252197700552642\n",
      "epoch:217 from 100000\n",
      "loss: 0.019584074994781986\n",
      "epoch:218 from 100000\n",
      "loss: 0.018317897483939305\n",
      "epoch:219 from 100000\n",
      "loss: 0.018104541522916406\n",
      "epoch:220 from 100000\n",
      "loss: 0.0200297495466657\n",
      "epoch:221 from 100000\n",
      "loss: 0.019642394210677594\n",
      "epoch:222 from 100000\n",
      "loss: 0.01907481293892488\n",
      "epoch:223 from 100000\n",
      "loss: 0.018561587436124682\n",
      "epoch:224 from 100000\n",
      "loss: 0.017788660421501845\n",
      "epoch:225 from 100000\n",
      "loss: 0.01856706547550857\n",
      "epoch:226 from 100000\n",
      "loss: 0.018847601546440274\n",
      "epoch:227 from 100000\n",
      "loss: 0.016195241041714326\n",
      "epoch:228 from 100000\n",
      "loss: 0.019726400380022824\n",
      "epoch:229 from 100000\n",
      "1024804loss: 0.019695592869538814\n",
      "epoch:230 from 100000\n",
      "loss: 0.017927706299815327\n",
      "epoch:231 from 100000\n",
      "loss: 0.01881492865504697\n",
      "epoch:232 from 100000\n",
      "loss: 0.017846850852947682\n",
      "epoch:233 from 100000\n",
      "loss: 0.020827076921705157\n",
      "epoch:234 from 100000\n",
      "loss: 0.020672104321420193\n",
      "epoch:235 from 100000\n",
      "loss: 0.018118185791536234\n",
      "epoch:236 from 100000\n",
      "loss: 0.01989078664337285\n",
      "epoch:237 from 100000\n",
      "loss: 0.019802019465714693\n",
      "epoch:238 from 100000\n",
      "loss: 0.02285575115820393\n",
      "epoch:239 from 100000\n",
      "loss: 0.01917082618456334\n",
      "epoch:240 from 100000\n",
      "loss: 0.019438575254753232\n",
      "epoch:241 from 100000\n",
      "loss: 0.020066533761564642\n",
      "epoch:242 from 100000\n",
      "loss: 0.019517566601280123\n",
      "epoch:243 from 100000\n",
      "loss: 0.01931156759383157\n",
      "epoch:244 from 100000\n",
      "loss: 0.01965087786084041\n",
      "epoch:245 from 100000\n",
      "loss: 0.019631852803286165\n",
      "epoch:246 from 100000\n",
      "loss: 0.019184136937838048\n",
      "epoch:247 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8250.pt\n",
      "loss: 0.018393440346699208\n",
      "epoch:248 from 100000\n",
      "loss: 0.02080426865722984\n",
      "epoch:249 from 100000\n",
      "loss: 0.018550293461885303\n",
      "epoch:250 from 100000\n",
      "loss: 0.020605324301868677\n",
      "epoch:251 from 100000\n",
      "loss: 0.01789012271910906\n",
      "epoch:252 from 100000\n",
      "loss: 0.017512532358523458\n",
      "epoch:253 from 100000\n",
      "loss: 0.017868396418634802\n",
      "epoch:254 from 100000\n",
      "loss: 0.01978950761258602\n",
      "epoch:255 from 100000\n",
      "loss: 0.0185348350496497\n",
      "epoch:256 from 100000\n",
      "loss: 0.02129565880750306\n",
      "epoch:257 from 100000\n",
      "loss: 0.021713844791520387\n",
      "epoch:258 from 100000\n",
      "loss: 0.017945466010132805\n",
      "epoch:259 from 100000\n",
      "loss: 0.0199471180094406\n",
      "epoch:260 from 100000\n",
      "loss: 0.019542429829016328\n",
      "epoch:261 from 100000\n",
      "loss: 0.020606527279596776\n",
      "epoch:262 from 100000\n",
      "loss: 0.01857554801972583\n",
      "epoch:263 from 100000\n",
      "loss: 0.019485252647427842\n",
      "epoch:264 from 100000\n",
      "loss: 0.018676234525628388\n",
      "epoch:265 from 100000\n",
      "loss: 0.020950087462551892\n",
      "epoch:266 from 100000\n",
      "loss: 0.01832876104163006\n",
      "epoch:267 from 100000\n",
      "loss: 0.01853080844739452\n",
      "epoch:268 from 100000\n",
      "loss: 0.020247350679710507\n",
      "epoch:269 from 100000\n",
      "loss: 0.021987283194903284\n",
      "epoch:270 from 100000\n",
      "loss: 0.019459070434095338\n",
      "epoch:271 from 100000\n",
      "loss: 0.020127550698816776\n",
      "epoch:272 from 100000\n",
      "loss: 0.01988494209945202\n",
      "epoch:273 from 100000\n",
      "loss: 0.018298755690921098\n",
      "epoch:274 from 100000\n",
      "loss: 0.019449264742434025\n",
      "epoch:275 from 100000\n",
      "loss: 0.01913442346267402\n",
      "epoch:276 from 100000\n",
      "loss: 0.020949007186573\n",
      "epoch:277 from 100000\n",
      "loss: 0.020665550604462624\n",
      "epoch:278 from 100000\n",
      "loss: 0.0224884728086181\n",
      "epoch:279 from 100000\n",
      "loss: 0.01961345848394558\n",
      "epoch:280 from 100000\n",
      "loss: 0.019469592662062496\n",
      "epoch:281 from 100000\n",
      "loss: 0.020451867079827935\n",
      "epoch:282 from 100000\n",
      "loss: 0.0189686450175941\n",
      "epoch:283 from 100000\n",
      "loss: 0.023073466727510095\n",
      "epoch:284 from 100000\n",
      "loss: 0.018241676676552743\n",
      "epoch:285 from 100000\n",
      "loss: 0.01858956491923891\n",
      "epoch:286 from 100000\n",
      "loss: 0.01805765921017155\n",
      "epoch:287 from 100000\n",
      "loss: 0.02079803525703028\n",
      "epoch:288 from 100000\n",
      "loss: 0.01610307180089876\n",
      "epoch:289 from 100000\n",
      "loss: 0.01662174059310928\n",
      "epoch:290 from 100000\n",
      "loss: 0.018316812231205404\n",
      "epoch:291 from 100000\n",
      "loss: 0.019094584917183965\n",
      "epoch:292 from 100000\n",
      "loss: 0.02018826245330274\n",
      "epoch:293 from 100000\n",
      "loss: 0.02072291763033718\n",
      "epoch:294 from 100000\n",
      "loss: 0.019145720405504107\n",
      "epoch:295 from 100000\n",
      "loss: 0.01719449134543538\n",
      "epoch:296 from 100000\n",
      "loss: 0.0194827513769269\n",
      "epoch:297 from 100000\n",
      "loss: 0.017986958438996226\n",
      "epoch:298 from 100000\n",
      "loss: 0.02003398071974516\n",
      "epoch:299 from 100000\n",
      "loss: 0.019221344962716103\n",
      "epoch:300 from 100000\n",
      "loss: 0.020221331797074527\n",
      "epoch:301 from 100000\n",
      "loss: 0.020654882420785725\n",
      "epoch:302 from 100000\n",
      "loss: 0.01886650233063847\n",
      "epoch:303 from 100000\n",
      "loss: 0.01802308642072603\n",
      "epoch:304 from 100000\n",
      "loss: 0.018093482358381152\n",
      "epoch:305 from 100000\n",
      "loss: 0.020722014945931733\n",
      "epoch:306 from 100000\n",
      "loss: 0.016842726967297494\n",
      "epoch:307 from 100000\n",
      "loss: 0.021268098847940564\n",
      "epoch:308 from 100000\n",
      "loss: 0.021583204274065793\n",
      "epoch:309 from 100000\n",
      "loss: 0.019871979602612555\n",
      "epoch:310 from 100000\n",
      "loss: 0.020490835653617978\n",
      "epoch:311 from 100000\n",
      "loss: 0.01742638845462352\n",
      "epoch:312 from 100000\n",
      "loss: 0.020033217209856957\n",
      "epoch:313 from 100000\n",
      "loss: 0.02335900504840538\n",
      "epoch:314 from 100000\n",
      "loss: 0.02043239149497822\n",
      "epoch:315 from 100000\n",
      "loss: 0.020473253563977778\n",
      "epoch:316 from 100000\n",
      "loss: 0.01938482333207503\n",
      "epoch:317 from 100000\n",
      "loss: 0.01945773750776425\n",
      "epoch:318 from 100000\n",
      "loss: 0.01864571962505579\n",
      "epoch:319 from 100000\n",
      "loss: 0.01831849862355739\n",
      "epoch:320 from 100000\n",
      "loss: 0.018462816602550447\n",
      "epoch:321 from 100000\n",
      "loss: 0.017398366704583168\n",
      "epoch:322 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8325.pt\n",
      "loss: 0.021144180209375918\n",
      "epoch:323 from 100000\n",
      "loss: 0.020070738217327744\n",
      "epoch:324 from 100000\n",
      "loss: 0.01718181249452755\n",
      "epoch:325 from 100000\n",
      "loss: 0.017582187661901116\n",
      "epoch:326 from 100000\n",
      "loss: 0.019800190057139844\n",
      "epoch:327 from 100000\n",
      "loss: 0.018143149907700717\n",
      "epoch:328 from 100000\n",
      "loss: 0.018993995152413845\n",
      "epoch:329 from 100000\n",
      "loss: 0.01933105767238885\n",
      "epoch:330 from 100000\n",
      "1040341loss: 0.0189850993338041\n",
      "epoch:331 from 100000\n",
      "loss: 0.017584009387064725\n",
      "epoch:332 from 100000\n",
      "loss: 0.018719621817581356\n",
      "epoch:333 from 100000\n",
      "loss: 0.017499547509942204\n",
      "epoch:334 from 100000\n",
      "loss: 0.017795719380956143\n",
      "epoch:335 from 100000\n",
      "loss: 0.019211959093809128\n",
      "epoch:336 from 100000\n",
      "loss: 0.019896214071195573\n",
      "epoch:337 from 100000\n",
      "loss: 0.019322049396578223\n",
      "epoch:338 from 100000\n",
      "loss: 0.018999492574948817\n",
      "epoch:339 from 100000\n",
      "loss: 0.02031367039307952\n",
      "epoch:340 from 100000\n",
      "loss: 0.02016918919980526\n",
      "epoch:341 from 100000\n",
      "loss: 0.018406152550596744\n",
      "epoch:342 from 100000\n",
      "loss: 0.016407351489760913\n",
      "epoch:343 from 100000\n",
      "loss: 0.020068579469807446\n",
      "epoch:344 from 100000\n",
      "loss: 0.0223816511570476\n",
      "epoch:345 from 100000\n",
      "loss: 0.02021341578802094\n",
      "epoch:346 from 100000\n",
      "loss: 0.01884120426257141\n",
      "epoch:347 from 100000\n",
      "loss: 0.018771921895677224\n",
      "epoch:348 from 100000\n",
      "loss: 0.023589746560901403\n",
      "epoch:349 from 100000\n",
      "loss: 0.02085045725107193\n",
      "epoch:350 from 100000\n",
      "loss: 0.01818349218228832\n",
      "epoch:351 from 100000\n",
      "loss: 0.02230815897928551\n",
      "epoch:352 from 100000\n",
      "loss: 0.018819322460331023\n",
      "epoch:353 from 100000\n",
      "loss: 0.019985311955679208\n",
      "epoch:354 from 100000\n",
      "loss: 0.017763300624210387\n",
      "epoch:355 from 100000\n",
      "loss: 0.02032117242924869\n",
      "epoch:356 from 100000\n",
      "loss: 0.021018212661147118\n",
      "epoch:357 from 100000\n",
      "loss: 0.01876611926127225\n",
      "epoch:358 from 100000\n",
      "loss: 0.021882193919736892\n",
      "epoch:359 from 100000\n",
      "loss: 0.020097913802601397\n",
      "epoch:360 from 100000\n",
      "loss: 0.017196985194459558\n",
      "epoch:361 from 100000\n",
      "loss: 0.01895984064321965\n",
      "epoch:362 from 100000\n",
      "loss: 0.01804390552570112\n",
      "epoch:363 from 100000\n",
      "loss: 0.01906025130301714\n",
      "epoch:364 from 100000\n",
      "loss: 0.02053349622292444\n",
      "epoch:365 from 100000\n",
      "loss: 0.018318519432796165\n",
      "epoch:366 from 100000\n",
      "loss: 0.02235927782021463\n",
      "epoch:367 from 100000\n",
      "loss: 0.019723060016985983\n",
      "epoch:368 from 100000\n",
      "loss: 0.01991277711931616\n",
      "epoch:369 from 100000\n",
      "loss: 0.018905667937360704\n",
      "epoch:370 from 100000\n",
      "loss: 0.018686050549149513\n",
      "epoch:371 from 100000\n",
      "loss: 0.01841964674531482\n",
      "epoch:372 from 100000\n",
      "loss: 0.020188559574307874\n",
      "epoch:373 from 100000\n",
      "loss: 0.02139008737867698\n",
      "epoch:374 from 100000\n",
      "loss: 0.01922561481478624\n",
      "epoch:375 from 100000\n",
      "loss: 0.018966109433677047\n",
      "epoch:376 from 100000\n",
      "loss: 0.020471215539146215\n",
      "epoch:377 from 100000\n",
      "loss: 0.02057002659421414\n",
      "epoch:378 from 100000\n",
      "loss: 0.019855136808473617\n",
      "epoch:379 from 100000\n",
      "loss: 0.01964441849850118\n",
      "epoch:380 from 100000\n",
      "loss: 0.02037286397535354\n",
      "epoch:381 from 100000\n",
      "loss: 0.01815235585672781\n",
      "epoch:382 from 100000\n",
      "loss: 0.019721550081158057\n",
      "epoch:383 from 100000\n",
      "loss: 0.020541844598483294\n",
      "epoch:384 from 100000\n",
      "loss: 0.01986379368463531\n",
      "epoch:385 from 100000\n",
      "loss: 0.01916610135231167\n",
      "epoch:386 from 100000\n",
      "loss: 0.01961143419612199\n",
      "epoch:387 from 100000\n",
      "loss: 0.016566413280088454\n",
      "epoch:388 from 100000\n",
      "loss: 0.019718986877705902\n",
      "epoch:389 from 100000\n",
      "loss: 0.019420095341047272\n",
      "epoch:390 from 100000\n",
      "loss: 0.01869395439280197\n",
      "epoch:391 from 100000\n",
      "loss: 0.02208294888259843\n",
      "epoch:392 from 100000\n",
      "loss: 0.019103753322269768\n",
      "epoch:393 from 100000\n",
      "loss: 0.020162143337074667\n",
      "epoch:394 from 100000\n",
      "loss: 0.019478299072943628\n",
      "epoch:395 from 100000\n",
      "loss: 0.020505736290942878\n",
      "epoch:396 from 100000\n",
      "loss: 0.018318986287340522\n",
      "epoch:397 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8400.pt\n",
      "loss: 0.01862040301784873\n",
      "epoch:398 from 100000\n",
      "loss: 0.018932652310468256\n",
      "epoch:399 from 100000\n",
      "loss: 0.018594486988149583\n",
      "epoch:400 from 100000\n",
      "loss: 0.018638411129359156\n",
      "epoch:401 from 100000\n",
      "loss: 0.01764176454162225\n",
      "epoch:402 from 100000\n",
      "loss: 0.019660254823975265\n",
      "epoch:403 from 100000\n",
      "loss: 0.01863915374269709\n",
      "epoch:404 from 100000\n",
      "loss: 0.020548248721752316\n",
      "epoch:405 from 100000\n",
      "loss: 0.018429317511618137\n",
      "epoch:406 from 100000\n",
      "loss: 0.019281757762655616\n",
      "epoch:407 from 100000\n",
      "loss: 0.0202894639223814\n",
      "epoch:408 from 100000\n",
      "loss: 0.018821953213773668\n",
      "epoch:409 from 100000\n",
      "loss: 0.02001911960542202\n",
      "epoch:410 from 100000\n",
      "loss: 0.018392155703622848\n",
      "epoch:411 from 100000\n",
      "loss: 0.02020920760696754\n",
      "epoch:412 from 100000\n",
      "loss: 0.019211578648537397\n",
      "epoch:413 from 100000\n",
      "loss: 0.01894639228703454\n",
      "epoch:414 from 100000\n",
      "loss: 0.019964980136137456\n",
      "epoch:415 from 100000\n",
      "loss: 0.01824213599320501\n",
      "epoch:416 from 100000\n",
      "loss: 0.019027290283702314\n",
      "epoch:417 from 100000\n",
      "loss: 0.019047371111810207\n",
      "epoch:418 from 100000\n",
      "loss: 0.019092065864242613\n",
      "epoch:419 from 100000\n",
      "loss: 0.01784193463390693\n",
      "epoch:420 from 100000\n",
      "loss: 0.020214468386257067\n",
      "epoch:421 from 100000\n",
      "loss: 0.020583245728630573\n",
      "epoch:422 from 100000\n",
      "loss: 0.018160151375923306\n",
      "epoch:423 from 100000\n",
      "loss: 0.018795120471622795\n",
      "epoch:424 from 100000\n",
      "loss: 0.01932352245785296\n",
      "epoch:425 from 100000\n",
      "loss: 0.021780998155009\n",
      "epoch:426 from 100000\n",
      "loss: 0.018374828970991075\n",
      "epoch:427 from 100000\n",
      "loss: 0.018882401345763355\n",
      "epoch:428 from 100000\n",
      "loss: 0.01743702939711511\n",
      "epoch:429 from 100000\n",
      "loss: 0.019077069126069546\n",
      "epoch:430 from 100000\n",
      "loss: 0.01978592309751548\n",
      "epoch:431 from 100000\n",
      "loss: 0.019782487768679857\n",
      "epoch:432 from 100000\n",
      "loss: 0.02044847863726318\n",
      "epoch:433 from 100000\n",
      "loss: 0.019816043961327523\n",
      "epoch:434 from 100000\n",
      "loss: 0.020098572043934837\n",
      "epoch:435 from 100000\n",
      "loss: 0.020221399783622473\n",
      "epoch:436 from 100000\n",
      "loss: 0.019938624755013734\n",
      "epoch:437 from 100000\n",
      "loss: 0.018361208320129663\n",
      "epoch:438 from 100000\n",
      "loss: 0.01998081390047446\n",
      "epoch:439 from 100000\n",
      "loss: 0.02195258712163195\n",
      "epoch:440 from 100000\n",
      "loss: 0.01785138648119755\n",
      "epoch:441 from 100000\n",
      "loss: 0.018275250040460378\n",
      "epoch:442 from 100000\n",
      "loss: 0.01995176775380969\n",
      "epoch:443 from 100000\n",
      "loss: 0.02015056647360325\n",
      "epoch:444 from 100000\n",
      "loss: 0.018696678860578686\n",
      "epoch:445 from 100000\n",
      "loss: 0.016532475216081366\n",
      "epoch:446 from 100000\n",
      "loss: 0.021266347030177712\n",
      "epoch:447 from 100000\n",
      "1060405loss: 0.019091600144747645\n",
      "epoch:448 from 100000\n",
      "loss: 0.020388121949508786\n",
      "epoch:449 from 100000\n",
      "loss: 0.018243906437419355\n",
      "epoch:450 from 100000\n",
      "loss: 0.02127718407427892\n",
      "epoch:451 from 100000\n",
      "loss: 0.020335643901489675\n",
      "epoch:452 from 100000\n",
      "loss: 0.02097714168485254\n",
      "epoch:453 from 100000\n",
      "loss: 0.016346754011465237\n",
      "epoch:454 from 100000\n",
      "loss: 0.020523678045719862\n",
      "epoch:455 from 100000\n",
      "loss: 0.02114572550635785\n",
      "epoch:456 from 100000\n",
      "loss: 0.02113056043162942\n",
      "epoch:457 from 100000\n",
      "loss: 0.022862337937112898\n",
      "epoch:458 from 100000\n",
      "loss: 0.02022308617597446\n",
      "epoch:459 from 100000\n",
      "loss: 0.01888897840399295\n",
      "epoch:460 from 100000\n",
      "loss: 0.020767681999132037\n",
      "epoch:461 from 100000\n",
      "loss: 0.018583076540380716\n",
      "epoch:462 from 100000\n",
      "loss: 0.02180710737593472\n",
      "epoch:463 from 100000\n",
      "loss: 0.020248671469744295\n",
      "epoch:464 from 100000\n",
      "loss: 0.019162742682965472\n",
      "epoch:465 from 100000\n",
      "loss: 0.01865314005408436\n",
      "epoch:466 from 100000\n",
      "loss: 0.02043193212011829\n",
      "epoch:467 from 100000\n",
      "loss: 0.019508711469825357\n",
      "epoch:468 from 100000\n",
      "loss: 0.019040160172153264\n",
      "epoch:469 from 100000\n",
      "1063322loss: 0.019273035461083055\n",
      "epoch:470 from 100000\n",
      "loss: 0.020847749547101557\n",
      "epoch:471 from 100000\n",
      "loss: 0.019588533381465822\n",
      "epoch:472 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8475.pt\n",
      "loss: 0.018253270303830504\n",
      "epoch:473 from 100000\n",
      "loss: 0.018860563402995467\n",
      "epoch:474 from 100000\n",
      "loss: 0.016095871105790138\n",
      "epoch:475 from 100000\n",
      "loss: 0.019585472997277975\n",
      "epoch:476 from 100000\n",
      "loss: 0.018901005329098552\n",
      "epoch:477 from 100000\n",
      "loss: 0.01744948187842965\n",
      "epoch:478 from 100000\n",
      "loss: 0.01839122109231539\n",
      "epoch:479 from 100000\n",
      "loss: 0.018334721797145903\n",
      "epoch:480 from 100000\n",
      "loss: 0.017354895069729537\n",
      "epoch:481 from 100000\n",
      "loss: 0.019808100420050323\n",
      "epoch:482 from 100000\n",
      "loss: 0.01970581046771258\n",
      "epoch:483 from 100000\n",
      "loss: 0.020372662227600813\n",
      "epoch:484 from 100000\n",
      "loss: 0.018222714483272284\n",
      "epoch:485 from 100000\n",
      "loss: 0.021868991432711482\n",
      "epoch:486 from 100000\n",
      "loss: 0.018844117905246094\n",
      "epoch:487 from 100000\n",
      "loss: 0.01978070748737082\n",
      "epoch:488 from 100000\n",
      "loss: 0.016000192845240235\n",
      "epoch:489 from 100000\n",
      "loss: 0.01947125932201743\n",
      "epoch:490 from 100000\n",
      "loss: 0.019373868824914098\n",
      "epoch:491 from 100000\n",
      "loss: 0.021023088018409908\n",
      "epoch:492 from 100000\n",
      "loss: 0.020575020636897534\n",
      "epoch:493 from 100000\n",
      "loss: 0.0203511476283893\n",
      "epoch:494 from 100000\n",
      "loss: 0.016617051558569074\n",
      "epoch:495 from 100000\n",
      "loss: 0.019501477596350014\n",
      "epoch:496 from 100000\n",
      "loss: 0.017403508187271655\n",
      "epoch:497 from 100000\n",
      "loss: 0.020665269810706377\n",
      "epoch:498 from 100000\n",
      "loss: 0.020755158504471183\n",
      "epoch:499 from 100000\n",
      "loss: 0.019306336995214224\n",
      "epoch:500 from 100000\n",
      "loss: 0.02002318250015378\n",
      "epoch:501 from 100000\n",
      "loss: 0.021437289949972183\n",
      "epoch:502 from 100000\n",
      "loss: 0.019340021128300577\n",
      "epoch:503 from 100000\n",
      "loss: 0.02130619651870802\n",
      "epoch:504 from 100000\n",
      "loss: 0.020595404610503465\n",
      "epoch:505 from 100000\n",
      "loss: 0.019934907963033766\n",
      "epoch:506 from 100000\n",
      "loss: 0.01964646141277626\n",
      "epoch:507 from 100000\n",
      "loss: 0.019692245085025206\n",
      "epoch:508 from 100000\n",
      "loss: 0.01880391128361225\n",
      "epoch:509 from 100000\n",
      "loss: 0.019599432533141226\n",
      "epoch:510 from 100000\n",
      "loss: 0.021289174968842417\n",
      "epoch:511 from 100000\n",
      "loss: 0.016375392122427\n",
      "epoch:512 from 100000\n",
      "loss: 0.01827907533152029\n",
      "epoch:513 from 100000\n",
      "loss: 0.020394752034917474\n",
      "epoch:514 from 100000\n",
      "loss: 0.0213300361065194\n",
      "epoch:515 from 100000\n",
      "loss: 0.016989702300634235\n",
      "epoch:516 from 100000\n",
      "loss: 0.02211439039092511\n",
      "epoch:517 from 100000\n",
      "loss: 0.02009257284225896\n",
      "epoch:518 from 100000\n",
      "loss: 0.019587195245549083\n",
      "epoch:519 from 100000\n",
      "loss: 0.016957739309873432\n",
      "epoch:520 from 100000\n",
      "loss: 0.019435537396930158\n",
      "epoch:521 from 100000\n",
      "loss: 0.018980772991199046\n",
      "epoch:522 from 100000\n",
      "loss: 0.021666366374120116\n",
      "epoch:523 from 100000\n",
      "loss: 0.01910726720234379\n",
      "epoch:524 from 100000\n",
      "loss: 0.017122630670201033\n",
      "epoch:525 from 100000\n",
      "loss: 0.01867914039758034\n",
      "epoch:526 from 100000\n",
      "loss: 0.01643077179323882\n",
      "epoch:527 from 100000\n",
      "loss: 0.021007075789384544\n",
      "epoch:528 from 100000\n",
      "loss: 0.018960021843668073\n",
      "epoch:529 from 100000\n",
      "loss: 0.02190658653853461\n",
      "epoch:530 from 100000\n",
      "loss: 0.02128255646675825\n",
      "epoch:531 from 100000\n",
      "loss: 0.02040085307089612\n",
      "epoch:532 from 100000\n",
      "loss: 0.017893911368446425\n",
      "epoch:533 from 100000\n",
      "loss: 0.020623770775273442\n",
      "epoch:534 from 100000\n",
      "loss: 0.020458400307688862\n",
      "epoch:535 from 100000\n",
      "loss: 0.018631772720254958\n",
      "epoch:536 from 100000\n",
      "loss: 0.018830617249477655\n",
      "epoch:537 from 100000\n",
      "loss: 0.020038610615301877\n",
      "epoch:538 from 100000\n",
      "loss: 0.019330994866322726\n",
      "epoch:539 from 100000\n",
      "loss: 0.019270835968200117\n",
      "epoch:540 from 100000\n",
      "loss: 0.01887788443127647\n",
      "epoch:541 from 100000\n",
      "loss: 0.021104876999743283\n",
      "epoch:542 from 100000\n",
      "loss: 0.0198274870053865\n",
      "epoch:543 from 100000\n",
      "loss: 0.02059671259485185\n",
      "epoch:544 from 100000\n",
      "loss: 0.019201504299417138\n",
      "epoch:545 from 100000\n",
      "loss: 0.018939251720439643\n",
      "epoch:546 from 100000\n",
      "loss: 0.017531468824017793\n",
      "epoch:547 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8550.pt\n",
      "loss: 0.018389148695860058\n",
      "epoch:548 from 100000\n",
      "loss: 0.018274854752235115\n",
      "epoch:549 from 100000\n",
      "loss: 0.018491823982913047\n",
      "epoch:550 from 100000\n",
      "loss: 0.019742165051866323\n",
      "epoch:551 from 100000\n",
      "loss: 0.01681250345427543\n",
      "epoch:552 from 100000\n",
      "loss: 0.017156401794636622\n",
      "epoch:553 from 100000\n",
      "loss: 0.0177277977054473\n",
      "epoch:554 from 100000\n",
      "loss: 0.019007870054338127\n",
      "epoch:555 from 100000\n",
      "loss: 0.01682910628733225\n",
      "epoch:556 from 100000\n",
      "loss: 0.01994132250547409\n",
      "epoch:557 from 100000\n",
      "loss: 0.02132193191209808\n",
      "epoch:558 from 100000\n",
      "loss: 0.02097411680733785\n",
      "epoch:559 from 100000\n",
      "loss: 0.019706412218511105\n",
      "epoch:560 from 100000\n",
      "loss: 0.01909010950475931\n",
      "epoch:561 from 100000\n",
      "loss: 0.020522551785688847\n",
      "epoch:562 from 100000\n",
      "loss: 0.021980259101837873\n",
      "epoch:563 from 100000\n",
      "loss: 0.01967430906370282\n",
      "epoch:564 from 100000\n",
      "loss: 0.01884147140663117\n",
      "epoch:565 from 100000\n",
      "loss: 0.019427588558755815\n",
      "epoch:566 from 100000\n",
      "retrying for data\n",
      "loss: 0.021118437056429684\n",
      "epoch:567 from 100000\n",
      "loss: 0.020249555993359536\n",
      "epoch:568 from 100000\n",
      "loss: 0.019153786590322852\n",
      "epoch:569 from 100000\n",
      "loss: 0.01874042203417048\n",
      "epoch:570 from 100000\n",
      "loss: 0.018893635598942637\n",
      "epoch:571 from 100000\n",
      "loss: 0.01825775357428938\n",
      "epoch:572 from 100000\n",
      "loss: 0.02044738456606865\n",
      "epoch:573 from 100000\n",
      "loss: 0.020643232332076877\n",
      "epoch:574 from 100000\n",
      "loss: 0.01857808348722756\n",
      "epoch:575 from 100000\n",
      "loss: 0.018572790519101545\n",
      "epoch:576 from 100000\n",
      "loss: 0.018456037272699177\n",
      "epoch:577 from 100000\n",
      "loss: 0.019225771364290267\n",
      "epoch:578 from 100000\n",
      "loss: 0.019566651550121605\n",
      "epoch:579 from 100000\n",
      "loss: 0.02005711296806112\n",
      "epoch:580 from 100000\n",
      "1081211loss: 0.020924131793435663\n",
      "epoch:581 from 100000\n",
      "loss: 0.019344019587151706\n",
      "epoch:582 from 100000\n",
      "loss: 0.0197109094588086\n",
      "epoch:583 from 100000\n",
      "loss: 0.020346927747596055\n",
      "epoch:584 from 100000\n",
      "loss: 0.01659599906997755\n",
      "epoch:585 from 100000\n",
      "loss: 0.019967459491454065\n",
      "epoch:586 from 100000\n",
      "loss: 0.020652260805945843\n",
      "epoch:587 from 100000\n",
      "loss: 0.01796192504116334\n",
      "epoch:588 from 100000\n",
      "loss: 0.02037857478717342\n",
      "epoch:589 from 100000\n",
      "loss: 0.019237811968196183\n",
      "epoch:590 from 100000\n",
      "loss: 0.019750459294300526\n",
      "epoch:591 from 100000\n",
      "loss: 0.019618321326561272\n",
      "epoch:592 from 100000\n",
      "loss: 0.01868458546232432\n",
      "epoch:593 from 100000\n",
      "loss: 0.01858970313332975\n",
      "epoch:594 from 100000\n",
      "loss: 0.020781907049240544\n",
      "epoch:595 from 100000\n",
      "loss: 0.019915333308745176\n",
      "epoch:596 from 100000\n",
      "loss: 0.018797921657096595\n",
      "epoch:597 from 100000\n",
      "loss: 0.017788328230381012\n",
      "epoch:598 from 100000\n",
      "loss: 0.01861212495714426\n",
      "epoch:599 from 100000\n",
      "loss: 0.01997268811101094\n",
      "epoch:600 from 100000\n",
      "loss: 0.01891776913544163\n",
      "epoch:601 from 100000\n",
      "loss: 0.01853593165287748\n",
      "epoch:602 from 100000\n",
      "loss: 0.020733808574732393\n",
      "epoch:603 from 100000\n",
      "loss: 0.021136138879228383\n",
      "epoch:604 from 100000\n",
      "loss: 0.020451010845135897\n",
      "epoch:605 from 100000\n",
      "loss: 0.020459382445551455\n",
      "epoch:606 from 100000\n",
      "loss: 0.018980765074957162\n",
      "epoch:607 from 100000\n",
      "loss: 0.016974676924291998\n",
      "epoch:608 from 100000\n",
      "loss: 0.019222548871766776\n",
      "epoch:609 from 100000\n",
      "loss: 0.01977817388251424\n",
      "epoch:610 from 100000\n",
      "loss: 0.021309264295268804\n",
      "epoch:611 from 100000\n",
      "loss: 0.02093528490513563\n",
      "epoch:612 from 100000\n",
      "loss: 0.017101213976275176\n",
      "epoch:613 from 100000\n",
      "loss: 0.018771748058497906\n",
      "epoch:614 from 100000\n",
      "loss: 0.018037794274277985\n",
      "epoch:615 from 100000\n",
      "loss: 0.02193632087437436\n",
      "epoch:616 from 100000\n",
      "loss: 0.017203480761963874\n",
      "epoch:617 from 100000\n",
      "loss: 0.01891914807492867\n",
      "epoch:618 from 100000\n",
      "loss: 0.020876408379990608\n",
      "epoch:619 from 100000\n",
      "loss: 0.018353164079599082\n",
      "epoch:620 from 100000\n",
      "loss: 0.01718364405678585\n",
      "epoch:621 from 100000\n",
      "loss: 0.019004403904546052\n",
      "epoch:622 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8625.pt\n",
      "loss: 0.018785893393214792\n",
      "epoch:623 from 100000\n",
      "loss: 0.019303826498799026\n",
      "epoch:624 from 100000\n",
      "loss: 0.02111758111277595\n",
      "epoch:625 from 100000\n",
      "loss: 0.019444003060925752\n",
      "epoch:626 from 100000\n",
      "loss: 0.022254440817050636\n",
      "epoch:627 from 100000\n",
      "loss: 0.018131774268113077\n",
      "epoch:628 from 100000\n",
      "loss: 0.019488496880512685\n",
      "epoch:629 from 100000\n",
      "loss: 0.021565587783697993\n",
      "epoch:630 from 100000\n",
      "loss: 0.017528936732560396\n",
      "epoch:631 from 100000\n",
      "loss: 0.020897236419841647\n",
      "epoch:632 from 100000\n",
      "loss: 0.019584909779950976\n",
      "epoch:633 from 100000\n",
      "loss: 0.017554978607222438\n",
      "epoch:634 from 100000\n",
      "loss: 0.018795440497342497\n",
      "epoch:635 from 100000\n",
      "loss: 0.02014947118004784\n",
      "epoch:636 from 100000\n",
      "loss: 0.020122740708757192\n",
      "epoch:637 from 100000\n",
      "loss: 0.017434780835174024\n",
      "epoch:638 from 100000\n",
      "loss: 0.020323701086454093\n",
      "epoch:639 from 100000\n",
      "loss: 0.02129707846324891\n",
      "epoch:640 from 100000\n",
      "loss: 0.018610356200952083\n",
      "epoch:641 from 100000\n",
      "loss: 0.01906299701659009\n",
      "epoch:642 from 100000\n",
      "loss: 0.017086210777051747\n",
      "epoch:643 from 100000\n",
      "loss: 0.02014462393708527\n",
      "epoch:644 from 100000\n",
      "loss: 0.01979147261590697\n",
      "epoch:645 from 100000\n",
      "1091481loss: 0.01867473585298285\n",
      "epoch:646 from 100000\n",
      "loss: 0.017975220107473433\n",
      "epoch:647 from 100000\n",
      "loss: 0.020410290453583002\n",
      "epoch:648 from 100000\n",
      "loss: 0.019056880788411945\n",
      "epoch:649 from 100000\n",
      "loss: 0.016614381631370634\n",
      "epoch:650 from 100000\n",
      "loss: 0.018473382166121155\n",
      "epoch:651 from 100000\n",
      "loss: 0.02211041614646092\n",
      "epoch:652 from 100000\n",
      "loss: 0.01856610394315794\n",
      "epoch:653 from 100000\n",
      "loss: 0.01920979714486748\n",
      "epoch:654 from 100000\n",
      "loss: 0.020976210333174095\n",
      "epoch:655 from 100000\n",
      "retrying for data\n",
      "loss: 0.01941138569964096\n",
      "epoch:656 from 100000\n",
      "loss: 0.01825670903781429\n",
      "epoch:657 from 100000\n",
      "loss: 0.020621600793674588\n",
      "epoch:658 from 100000\n",
      "loss: 0.020620830182451755\n",
      "epoch:659 from 100000\n",
      "loss: 0.017146992671769112\n",
      "epoch:660 from 100000\n",
      "loss: 0.017136740556452423\n",
      "epoch:661 from 100000\n",
      "loss: 0.019955961382947862\n",
      "epoch:662 from 100000\n",
      "loss: 0.01858718291623518\n",
      "epoch:663 from 100000\n",
      "loss: 0.01807687582913786\n",
      "epoch:664 from 100000\n",
      "loss: 0.02030359487980604\n",
      "epoch:665 from 100000\n",
      "loss: 0.018030247767455876\n",
      "epoch:666 from 100000\n",
      "loss: 0.018419345549773425\n",
      "epoch:667 from 100000\n",
      "loss: 0.018579322728328407\n",
      "epoch:668 from 100000\n",
      "loss: 0.01966836245264858\n",
      "epoch:669 from 100000\n",
      "loss: 0.019465776276774704\n",
      "epoch:670 from 100000\n",
      "loss: 0.01986241078702733\n",
      "epoch:671 from 100000\n",
      "loss: 0.0181450744275935\n",
      "epoch:672 from 100000\n",
      "loss: 0.022189535782672465\n",
      "epoch:673 from 100000\n",
      "loss: 0.020108686934690922\n",
      "epoch:674 from 100000\n",
      "loss: 0.019965972169302404\n",
      "epoch:675 from 100000\n",
      "loss: 0.019525422423612326\n",
      "epoch:676 from 100000\n",
      "loss: 0.0198130143689923\n",
      "epoch:677 from 100000\n",
      "loss: 0.021555902145337313\n",
      "epoch:678 from 100000\n",
      "loss: 0.01851984948734753\n",
      "epoch:679 from 100000\n",
      "loss: 0.020179081067908555\n",
      "epoch:680 from 100000\n",
      "loss: 0.020041727810166776\n",
      "epoch:681 from 100000\n",
      "loss: 0.017440163937862962\n",
      "epoch:682 from 100000\n",
      "loss: 0.019765190198086202\n",
      "epoch:683 from 100000\n",
      "loss: 0.020337439491413534\n",
      "epoch:684 from 100000\n",
      "loss: 0.019634566793683916\n",
      "epoch:685 from 100000\n",
      "loss: 0.01825942419236526\n",
      "epoch:686 from 100000\n",
      "loss: 0.018491615541279316\n",
      "epoch:687 from 100000\n",
      "retrying for data\n",
      "loss: 0.020117512496653944\n",
      "epoch:688 from 100000\n",
      "loss: 0.01893846067832783\n",
      "epoch:689 from 100000\n",
      "loss: 0.0207904678536579\n",
      "epoch:690 from 100000\n",
      "loss: 0.020428250485565513\n",
      "epoch:691 from 100000\n",
      "loss: 0.018224642670247704\n",
      "epoch:692 from 100000\n",
      "loss: 0.020026313606649637\n",
      "epoch:693 from 100000\n",
      "loss: 0.019620439677964896\n",
      "epoch:694 from 100000\n",
      "loss: 0.019437571812886745\n",
      "epoch:695 from 100000\n",
      "loss: 0.018183944921474904\n",
      "epoch:696 from 100000\n",
      "loss: 0.02007272091577761\n",
      "epoch:697 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8700.pt\n",
      "loss: 0.019089462468400598\n",
      "epoch:698 from 100000\n",
      "loss: 0.0177880140254274\n",
      "epoch:699 from 100000\n",
      "loss: 0.01992740953573957\n",
      "epoch:700 from 100000\n",
      "loss: 0.02117792540229857\n",
      "epoch:701 from 100000\n",
      "loss: 0.016590056649874896\n",
      "epoch:702 from 100000\n",
      "loss: 0.022086250712163746\n",
      "epoch:703 from 100000\n",
      "loss: 0.02094785706140101\n",
      "epoch:704 from 100000\n",
      "loss: 0.018339755828492343\n",
      "epoch:705 from 100000\n",
      "loss: 0.01907034986652434\n",
      "epoch:706 from 100000\n",
      "loss: 0.02190376544604078\n",
      "epoch:707 from 100000\n",
      "loss: 0.01947889500297606\n",
      "epoch:708 from 100000\n",
      "loss: 0.018209721834864467\n",
      "epoch:709 from 100000\n",
      "loss: 0.019022972614038736\n",
      "epoch:710 from 100000\n",
      "loss: 0.01879718340933323\n",
      "epoch:711 from 100000\n",
      "loss: 0.01905850990442559\n",
      "epoch:712 from 100000\n",
      "loss: 0.021009106712881476\n",
      "epoch:713 from 100000\n",
      "loss: 0.017259680898860097\n",
      "epoch:714 from 100000\n",
      "loss: 0.017390672030160204\n",
      "epoch:715 from 100000\n",
      "1101803loss: 0.017819681263063103\n",
      "epoch:716 from 100000\n",
      "loss: 0.019058381323702633\n",
      "epoch:717 from 100000\n",
      "loss: 0.019844678579829633\n",
      "epoch:718 from 100000\n",
      "loss: 0.021392583148553967\n",
      "epoch:719 from 100000\n",
      "retrying for data\n",
      "loss: 0.019305132678709924\n",
      "epoch:720 from 100000\n",
      "loss: 0.018315425084438175\n",
      "epoch:721 from 100000\n",
      "loss: 0.020231237343978137\n",
      "epoch:722 from 100000\n",
      "loss: 0.019378209253773093\n",
      "epoch:723 from 100000\n",
      "loss: 0.01765689451713115\n",
      "epoch:724 from 100000\n",
      "loss: 0.018085146963130683\n",
      "epoch:725 from 100000\n",
      "loss: 0.016259681491646916\n",
      "epoch:726 from 100000\n",
      "loss: 0.01995227881707251\n",
      "epoch:727 from 100000\n",
      "loss: 0.019841081753838807\n",
      "epoch:728 from 100000\n",
      "loss: 0.020969684701412916\n",
      "epoch:729 from 100000\n",
      "loss: 0.019381130550755188\n",
      "epoch:730 from 100000\n",
      "loss: 0.02019702084362507\n",
      "epoch:731 from 100000\n",
      "loss: 0.019989114545751363\n",
      "epoch:732 from 100000\n",
      "loss: 0.021197321475483477\n",
      "epoch:733 from 100000\n",
      "loss: 0.019337530568009242\n",
      "epoch:734 from 100000\n",
      "loss: 0.0206081448122859\n",
      "epoch:735 from 100000\n",
      "loss: 0.019443129596766084\n",
      "epoch:736 from 100000\n",
      "loss: 0.01832498048315756\n",
      "epoch:737 from 100000\n",
      "loss: 0.018978488311404362\n",
      "epoch:738 from 100000\n",
      "loss: 0.018163841450586915\n",
      "epoch:739 from 100000\n",
      "loss: 0.021458728471770883\n",
      "epoch:740 from 100000\n",
      "loss: 0.017555179190821946\n",
      "epoch:741 from 100000\n",
      "loss: 0.018668133299797773\n",
      "epoch:742 from 100000\n",
      "loss: 0.019548550102626905\n",
      "epoch:743 from 100000\n",
      "loss: 0.020629604812711477\n",
      "epoch:744 from 100000\n",
      "loss: 0.020721348468214273\n",
      "epoch:745 from 100000\n",
      "loss: 0.019438323157373816\n",
      "epoch:746 from 100000\n",
      "loss: 0.01923789462307468\n",
      "epoch:747 from 100000\n",
      "loss: 0.01885389385279268\n",
      "epoch:748 from 100000\n",
      "loss: 0.016926283191423863\n",
      "epoch:749 from 100000\n",
      "loss: 0.020219496014760807\n",
      "epoch:750 from 100000\n",
      "loss: 0.02090260380646214\n",
      "epoch:751 from 100000\n",
      "loss: 0.0153914880938828\n",
      "epoch:752 from 100000\n",
      "loss: 0.020532354130409658\n",
      "epoch:753 from 100000\n",
      "loss: 0.01784329058136791\n",
      "epoch:754 from 100000\n",
      "loss: 0.023774737608619034\n",
      "epoch:755 from 100000\n",
      "loss: 0.018469179281964898\n",
      "epoch:756 from 100000\n",
      "loss: 0.017303567990893498\n",
      "epoch:757 from 100000\n",
      "loss: 0.020192389434669167\n",
      "epoch:758 from 100000\n",
      "loss: 0.02072314452379942\n",
      "epoch:759 from 100000\n",
      "loss: 0.017529947857838124\n",
      "epoch:760 from 100000\n",
      "loss: 0.01900133240269497\n",
      "epoch:761 from 100000\n",
      "loss: 0.01961173495510593\n",
      "epoch:762 from 100000\n",
      "loss: 0.018098373257089406\n",
      "epoch:763 from 100000\n",
      "loss: 0.01994337045471184\n",
      "epoch:764 from 100000\n",
      "loss: 0.02011730696540326\n",
      "epoch:765 from 100000\n",
      "loss: 0.01838675222825259\n",
      "epoch:766 from 100000\n",
      "loss: 0.01806269644293934\n",
      "epoch:767 from 100000\n",
      "loss: 0.022178346873261034\n",
      "epoch:768 from 100000\n",
      "loss: 0.018683640781091526\n",
      "epoch:769 from 100000\n",
      "loss: 0.019144183897878975\n",
      "epoch:770 from 100000\n",
      "loss: 0.018100597604643553\n",
      "epoch:771 from 100000\n",
      "loss: 0.019450912717729807\n",
      "epoch:772 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8775.pt\n",
      "loss: 0.019079628749750555\n",
      "epoch:773 from 100000\n",
      "loss: 0.01957267348188907\n",
      "epoch:774 from 100000\n",
      "loss: 0.022829771973192692\n",
      "epoch:775 from 100000\n",
      "loss: 0.019675030664075166\n",
      "epoch:776 from 100000\n",
      "loss: 0.02040254120947793\n",
      "epoch:777 from 100000\n",
      "loss: 0.017442930169636384\n",
      "epoch:778 from 100000\n",
      "loss: 0.020046582503709942\n",
      "epoch:779 from 100000\n",
      "loss: 0.017978392832446843\n",
      "epoch:780 from 100000\n",
      "loss: 0.018703130423091352\n",
      "epoch:781 from 100000\n",
      "loss: 0.019640444195829332\n",
      "epoch:782 from 100000\n",
      "loss: 0.01820616004988551\n",
      "epoch:783 from 100000\n",
      "loss: 0.017744366923579946\n",
      "epoch:784 from 100000\n",
      "loss: 0.020738411811180413\n",
      "epoch:785 from 100000\n",
      "loss: 0.017789174860809\n",
      "epoch:786 from 100000\n",
      "loss: 0.017205819371156394\n",
      "epoch:787 from 100000\n",
      "loss: 0.01782894803909585\n",
      "epoch:788 from 100000\n",
      "loss: 0.01791806926485151\n",
      "epoch:789 from 100000\n",
      "loss: 0.02105327829485759\n",
      "epoch:790 from 100000\n",
      "loss: 0.0183410911122337\n",
      "epoch:791 from 100000\n",
      "loss: 0.018107454583514482\n",
      "epoch:792 from 100000\n",
      "loss: 0.019172062806319445\n",
      "epoch:793 from 100000\n",
      "loss: 0.01818510435987264\n",
      "epoch:794 from 100000\n",
      "loss: 0.017980077245738357\n",
      "epoch:795 from 100000\n",
      "loss: 0.01743253241875209\n",
      "epoch:796 from 100000\n",
      "loss: 0.018382490903604776\n",
      "epoch:797 from 100000\n",
      "loss: 0.019244973082095385\n",
      "epoch:798 from 100000\n",
      "loss: 0.019727271574083716\n",
      "epoch:799 from 100000\n",
      "loss: 0.020688530581537634\n",
      "epoch:800 from 100000\n",
      "loss: 0.020408570067957044\n",
      "epoch:801 from 100000\n",
      "loss: 0.019426122249569744\n",
      "epoch:802 from 100000\n",
      "loss: 0.01813492685323581\n",
      "epoch:803 from 100000\n",
      "loss: 0.019236403692048043\n",
      "epoch:804 from 100000\n",
      "loss: 0.017234859929885715\n",
      "epoch:805 from 100000\n",
      "loss: 0.01582374796271324\n",
      "epoch:806 from 100000\n",
      "loss: 0.01913425902603194\n",
      "epoch:807 from 100000\n",
      "loss: 0.018854590714909136\n",
      "epoch:808 from 100000\n",
      "loss: 0.020132498786551878\n",
      "epoch:809 from 100000\n",
      "loss: 0.018399117223452777\n",
      "epoch:810 from 100000\n",
      "loss: 0.017464435775764287\n",
      "epoch:811 from 100000\n",
      "loss: 0.02078497872571461\n",
      "epoch:812 from 100000\n",
      "loss: 0.021021937718614936\n",
      "epoch:813 from 100000\n",
      "loss: 0.018511730595491827\n",
      "epoch:814 from 100000\n",
      "loss: 0.020361098286230117\n",
      "epoch:815 from 100000\n",
      "loss: 0.01649986725533381\n",
      "epoch:816 from 100000\n",
      "loss: 0.019817632128251716\n",
      "epoch:817 from 100000\n",
      "loss: 0.021613799210172147\n",
      "epoch:818 from 100000\n",
      "loss: 0.02007619693176821\n",
      "epoch:819 from 100000\n",
      "loss: 0.01639660948421806\n",
      "epoch:820 from 100000\n",
      "loss: 0.019695772032719105\n",
      "epoch:821 from 100000\n",
      "loss: 0.018902416428318247\n",
      "epoch:822 from 100000\n",
      "loss: 0.018600831332150847\n",
      "epoch:823 from 100000\n",
      "loss: 0.019175074237864465\n",
      "epoch:824 from 100000\n",
      "loss: 0.02038515155436471\n",
      "epoch:825 from 100000\n",
      "loss: 0.01891782198799774\n",
      "epoch:826 from 100000\n",
      "loss: 0.019675409595947713\n",
      "epoch:827 from 100000\n",
      "loss: 0.020210007729474455\n",
      "epoch:828 from 100000\n",
      "loss: 0.01973775471560657\n",
      "epoch:829 from 100000\n",
      "loss: 0.021069870854262263\n",
      "epoch:830 from 100000\n",
      "loss: 0.019860102562233806\n",
      "epoch:831 from 100000\n",
      "loss: 0.02154355705715716\n",
      "epoch:832 from 100000\n",
      "loss: 0.020106103154830635\n",
      "epoch:833 from 100000\n",
      "loss: 0.01820489508099854\n",
      "epoch:834 from 100000\n",
      "loss: 0.01990879775257781\n",
      "epoch:835 from 100000\n",
      "loss: 0.01862580730812624\n",
      "epoch:836 from 100000\n",
      "loss: 0.01943696301896125\n",
      "epoch:837 from 100000\n",
      "loss: 0.019750220759306103\n",
      "epoch:838 from 100000\n",
      "loss: 0.018457570229656994\n",
      "epoch:839 from 100000\n",
      "loss: 0.018849907151889056\n",
      "epoch:840 from 100000\n",
      "loss: 0.019711635424755514\n",
      "epoch:841 from 100000\n",
      "loss: 0.02090537262847647\n",
      "epoch:842 from 100000\n",
      "loss: 0.0206384010380134\n",
      "epoch:843 from 100000\n",
      "loss: 0.02042673871619627\n",
      "epoch:844 from 100000\n",
      "loss: 0.018358470813836902\n",
      "epoch:845 from 100000\n",
      "loss: 0.020835701667238027\n",
      "epoch:846 from 100000\n",
      "loss: 0.017848517833044752\n",
      "epoch:847 from 100000\n",
      "retrying for data\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8850.pt\n",
      "loss: 0.018074404331855476\n",
      "epoch:848 from 100000\n",
      "loss: 0.020844048936851323\n",
      "epoch:849 from 100000\n",
      "loss: 0.019124784565065056\n",
      "epoch:850 from 100000\n",
      "loss: 0.01953322405461222\n",
      "epoch:851 from 100000\n",
      "loss: 0.019393389811739326\n",
      "epoch:852 from 100000\n",
      "loss: 0.019351467839442194\n",
      "epoch:853 from 100000\n",
      "loss: 0.0177891009952873\n",
      "epoch:854 from 100000\n",
      "loss: 0.018030198581982404\n",
      "epoch:855 from 100000\n",
      "loss: 0.019669508677907288\n",
      "epoch:856 from 100000\n",
      "loss: 0.019713360292371362\n",
      "epoch:857 from 100000\n",
      "loss: 0.01881440996658057\n",
      "epoch:858 from 100000\n",
      "loss: 0.01842104777460918\n",
      "epoch:859 from 100000\n",
      "loss: 0.018555106304120272\n",
      "epoch:860 from 100000\n",
      "loss: 0.019768189929891378\n",
      "epoch:861 from 100000\n",
      "loss: 0.019372042850591242\n",
      "epoch:862 from 100000\n",
      "loss: 0.01705131438211538\n",
      "epoch:863 from 100000\n",
      "loss: 0.020120898145250976\n",
      "epoch:864 from 100000\n",
      "loss: 0.01910315576242283\n",
      "epoch:865 from 100000\n",
      "loss: 0.01800027332501486\n",
      "epoch:866 from 100000\n",
      "loss: 0.016963625384960324\n",
      "epoch:867 from 100000\n",
      "loss: 0.01936882856534794\n",
      "epoch:868 from 100000\n",
      "loss: 0.019605419831350446\n",
      "epoch:869 from 100000\n",
      "loss: 0.018060152477119118\n",
      "epoch:870 from 100000\n",
      "loss: 0.01883183902828023\n",
      "epoch:871 from 100000\n",
      "loss: 0.018883089593145996\n",
      "epoch:872 from 100000\n",
      "loss: 0.018332141858991235\n",
      "epoch:873 from 100000\n",
      "loss: 0.018878996663261205\n",
      "epoch:874 from 100000\n",
      "loss: 0.017270719865337014\n",
      "epoch:875 from 100000\n",
      "loss: 0.020117082458455116\n",
      "epoch:876 from 100000\n",
      "loss: 0.018258456082548946\n",
      "epoch:877 from 100000\n",
      "1127482loss: 0.01798557728761807\n",
      "epoch:878 from 100000\n",
      "loss: 0.02139117696788162\n",
      "epoch:879 from 100000\n",
      "retrying for data\n",
      "loss: 0.02001610171282664\n",
      "epoch:880 from 100000\n",
      "loss: 0.022363953292369843\n",
      "epoch:881 from 100000\n",
      "loss: 0.017285400768741965\n",
      "epoch:882 from 100000\n",
      "loss: 0.021056848752778023\n",
      "epoch:883 from 100000\n",
      "loss: 0.01990828980342485\n",
      "epoch:884 from 100000\n",
      "loss: 0.019007816386874765\n",
      "epoch:885 from 100000\n",
      "loss: 0.01804308162536472\n",
      "epoch:886 from 100000\n",
      "loss: 0.019466742291115224\n",
      "epoch:887 from 100000\n",
      "loss: 0.021974846487864852\n",
      "epoch:888 from 100000\n",
      "loss: 0.018385461007710546\n",
      "epoch:889 from 100000\n",
      "loss: 0.020138628082349896\n",
      "epoch:890 from 100000\n",
      "loss: 0.020933614461682737\n",
      "epoch:891 from 100000\n",
      "loss: 0.017826363793574274\n",
      "epoch:892 from 100000\n",
      "loss: 0.01976374175865203\n",
      "epoch:893 from 100000\n",
      "loss: 0.018531569570768625\n",
      "epoch:894 from 100000\n",
      "loss: 0.01849080139072612\n",
      "epoch:895 from 100000\n",
      "loss: 0.01950034312903881\n",
      "epoch:896 from 100000\n",
      "loss: 0.018708413816057146\n",
      "epoch:897 from 100000\n",
      "loss: 0.02046835594228469\n",
      "epoch:898 from 100000\n",
      "loss: 0.01847432629438117\n",
      "epoch:899 from 100000\n",
      "loss: 0.017318072263151407\n",
      "epoch:900 from 100000\n",
      "loss: 0.019995803420897573\n",
      "epoch:901 from 100000\n",
      "loss: 0.0203773251560051\n",
      "epoch:902 from 100000\n",
      "loss: 0.020289520092774183\n",
      "epoch:903 from 100000\n",
      "loss: 0.019864989793859422\n",
      "epoch:904 from 100000\n",
      "loss: 0.019699124502949417\n",
      "epoch:905 from 100000\n",
      "loss: 0.019918454869184643\n",
      "epoch:906 from 100000\n",
      "loss: 0.01776038354728371\n",
      "epoch:907 from 100000\n",
      "loss: 0.02175758220255375\n",
      "epoch:908 from 100000\n",
      "loss: 0.018682793015614152\n",
      "epoch:909 from 100000\n",
      "loss: 0.01885684352600947\n",
      "epoch:910 from 100000\n",
      "loss: 0.01916356774745509\n",
      "epoch:911 from 100000\n",
      "loss: 0.020601028169039637\n",
      "epoch:912 from 100000\n",
      "loss: 0.019534249207936227\n",
      "epoch:913 from 100000\n",
      "loss: 0.018985852890182287\n",
      "epoch:914 from 100000\n",
      "loss: 0.020319128932897\n",
      "epoch:915 from 100000\n",
      "loss: 0.0186088751652278\n",
      "epoch:916 from 100000\n",
      "loss: 0.018306754936929792\n",
      "epoch:917 from 100000\n",
      "loss: 0.018998282961547375\n",
      "epoch:918 from 100000\n",
      "loss: 0.01788777660112828\n",
      "epoch:919 from 100000\n",
      "loss: 0.018032926484011114\n",
      "epoch:920 from 100000\n",
      "loss: 0.02371911541558802\n",
      "epoch:921 from 100000\n",
      "loss: 0.01813208038220182\n",
      "epoch:922 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.8925.pt\n",
      "loss: 0.02178283332614228\n",
      "epoch:923 from 100000\n",
      "loss: 0.01974333793623373\n",
      "epoch:924 from 100000\n",
      "loss: 0.018121508765034378\n",
      "epoch:925 from 100000\n",
      "loss: 0.021421958692371845\n",
      "epoch:926 from 100000\n",
      "loss: 0.019623022060841322\n",
      "epoch:927 from 100000\n",
      "loss: 0.017879117687698454\n",
      "epoch:928 from 100000\n",
      "loss: 0.01828468730673194\n",
      "epoch:929 from 100000\n",
      "loss: 0.019397976459003985\n",
      "epoch:930 from 100000\n",
      "loss: 0.020305665442720056\n",
      "epoch:931 from 100000\n",
      "loss: 0.02174941182602197\n",
      "epoch:932 from 100000\n",
      "loss: 0.01883791311411187\n",
      "epoch:933 from 100000\n",
      "loss: 0.018413506157230586\n",
      "epoch:934 from 100000\n",
      "loss: 0.01687118358677253\n",
      "epoch:935 from 100000\n",
      "loss: 0.01775361894397065\n",
      "epoch:936 from 100000\n",
      "loss: 0.018580591306090355\n",
      "epoch:937 from 100000\n",
      "loss: 0.01799335837131366\n",
      "epoch:938 from 100000\n",
      "loss: 0.020476740843150765\n",
      "epoch:939 from 100000\n",
      "loss: 0.01915418467251584\n",
      "epoch:940 from 100000\n",
      "loss: 0.020174182893242687\n",
      "epoch:941 from 100000\n",
      "loss: 0.018587055907119066\n",
      "epoch:942 from 100000\n",
      "loss: 0.019002353947144\n",
      "epoch:943 from 100000\n",
      "loss: 0.018800255667883903\n",
      "epoch:944 from 100000\n",
      "loss: 0.01908311987062916\n",
      "epoch:945 from 100000\n",
      "loss: 0.020182104781270027\n",
      "epoch:946 from 100000\n",
      "loss: 0.01968642621068284\n",
      "epoch:947 from 100000\n",
      "loss: 0.016952614241745323\n",
      "epoch:948 from 100000\n",
      "loss: 0.018081846501445398\n",
      "epoch:949 from 100000\n",
      "loss: 0.01666802680119872\n",
      "epoch:950 from 100000\n",
      "loss: 0.02041442022891715\n",
      "epoch:951 from 100000\n",
      "loss: 0.0194254707894288\n",
      "epoch:952 from 100000\n",
      "loss: 0.01835967361694202\n",
      "epoch:953 from 100000\n",
      "loss: 0.019571799144614488\n",
      "epoch:954 from 100000\n",
      "loss: 0.017530703160446137\n",
      "epoch:955 from 100000\n",
      "loss: 0.01905670526321046\n",
      "epoch:956 from 100000\n",
      "loss: 0.017018728714901954\n",
      "epoch:957 from 100000\n",
      "loss: 0.016550207685213536\n",
      "epoch:958 from 100000\n",
      "loss: 0.019490728562232107\n",
      "epoch:959 from 100000\n",
      "loss: 0.019770731159951538\n",
      "epoch:960 from 100000\n",
      "loss: 0.021679178811609745\n",
      "epoch:961 from 100000\n",
      "loss: 0.01993149652844295\n",
      "epoch:962 from 100000\n",
      "loss: 0.01604768290417269\n",
      "epoch:963 from 100000\n",
      "loss: 0.017848396091721952\n",
      "epoch:964 from 100000\n",
      "loss: 0.018632100662216544\n",
      "epoch:965 from 100000\n",
      "loss: 0.01628495252225548\n",
      "epoch:966 from 100000\n",
      "loss: 0.01786468384671025\n",
      "epoch:967 from 100000\n",
      "loss: 0.018179181904997677\n",
      "epoch:968 from 100000\n",
      "loss: 0.019377511634957045\n",
      "epoch:969 from 100000\n",
      "loss: 0.019990538334241137\n",
      "epoch:970 from 100000\n",
      "loss: 0.018808840948622674\n",
      "epoch:971 from 100000\n",
      "loss: 0.017326002940535545\n",
      "epoch:972 from 100000\n",
      "loss: 0.01899834821233526\n",
      "epoch:973 from 100000\n",
      "loss: 0.016777256299974397\n",
      "epoch:974 from 100000\n",
      "loss: 0.01835075585404411\n",
      "epoch:975 from 100000\n",
      "loss: 0.018927546974737197\n",
      "epoch:976 from 100000\n",
      "loss: 0.02065457432763651\n",
      "epoch:977 from 100000\n",
      "loss: 0.01703696488402784\n",
      "epoch:978 from 100000\n",
      "loss: 0.019796022621449083\n",
      "epoch:979 from 100000\n",
      "loss: 0.015730133891338482\n",
      "epoch:980 from 100000\n",
      "loss: 0.020064631651621312\n",
      "epoch:981 from 100000\n",
      "loss: 0.01787632770719938\n",
      "epoch:982 from 100000\n",
      "loss: 0.018982359557412565\n",
      "epoch:983 from 100000\n",
      "loss: 0.017310377093963325\n",
      "epoch:984 from 100000\n",
      "loss: 0.01838052910170518\n",
      "epoch:985 from 100000\n",
      "loss: 0.020573118003085256\n",
      "epoch:986 from 100000\n",
      "loss: 0.020933164283633232\n",
      "epoch:987 from 100000\n",
      "loss: 0.019084470986854285\n",
      "epoch:988 from 100000\n",
      "loss: 0.01962741877650842\n",
      "epoch:989 from 100000\n",
      "loss: 0.019321761617902666\n",
      "epoch:990 from 100000\n",
      "loss: 0.01680552714969963\n",
      "epoch:991 from 100000\n",
      "retrying for data\n",
      "loss: 0.021190650761127472\n",
      "epoch:992 from 100000\n",
      "loss: 0.015906864951830357\n",
      "epoch:993 from 100000\n",
      "loss: 0.01906709762988612\n",
      "epoch:994 from 100000\n",
      "loss: 0.020123694965150207\n",
      "epoch:995 from 100000\n",
      "loss: 0.018419352127239108\n",
      "epoch:996 from 100000\n",
      "loss: 0.018357579974690452\n",
      "epoch:997 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9000.pt\n",
      "loss: 0.022857798379845917\n",
      "epoch:998 from 100000\n",
      "loss: 0.017868873314000666\n",
      "epoch:999 from 100000\n",
      "loss: 0.020247225183993578\n",
      "epoch:1000 from 100000\n",
      "loss: 0.018105129536706954\n",
      "epoch:1001 from 100000\n",
      "loss: 0.021078153513371944\n",
      "epoch:1002 from 100000\n",
      "loss: 0.017669654451310635\n",
      "epoch:1003 from 100000\n",
      "loss: 0.018498242425266653\n",
      "epoch:1004 from 100000\n",
      "loss: 0.020087550743483007\n",
      "epoch:1005 from 100000\n",
      "loss: 0.01876598980743438\n",
      "epoch:1006 from 100000\n",
      "loss: 0.019392618152778596\n",
      "epoch:1007 from 100000\n",
      "loss: 0.022113364713732153\n",
      "epoch:1008 from 100000\n",
      "loss: 0.02021731116110459\n",
      "epoch:1009 from 100000\n",
      "loss: 0.019011515600141138\n",
      "epoch:1010 from 100000\n",
      "loss: 0.02069906028918922\n",
      "epoch:1011 from 100000\n",
      "loss: 0.01955265848664567\n",
      "epoch:1012 from 100000\n",
      "loss: 0.019061482104007155\n",
      "epoch:1013 from 100000\n",
      "loss: 0.019197510177036747\n",
      "epoch:1014 from 100000\n",
      "loss: 0.017170937615446746\n",
      "epoch:1015 from 100000\n",
      "loss: 0.021858743391931057\n",
      "epoch:1016 from 100000\n",
      "loss: 0.02145320491399616\n",
      "epoch:1017 from 100000\n",
      "loss: 0.017657835327554494\n",
      "epoch:1018 from 100000\n",
      "loss: 0.017981169337872416\n",
      "epoch:1019 from 100000\n",
      "loss: 0.01854089056723751\n",
      "epoch:1020 from 100000\n",
      "loss: 0.019491762446705252\n",
      "epoch:1021 from 100000\n",
      "loss: 0.018689509422983974\n",
      "epoch:1022 from 100000\n",
      "loss: 0.018872860062401742\n",
      "epoch:1023 from 100000\n",
      "loss: 0.018040831841062754\n",
      "epoch:1024 from 100000\n",
      "loss: 0.017932650516740978\n",
      "epoch:1025 from 100000\n",
      "loss: 0.019411839719396085\n",
      "epoch:1026 from 100000\n",
      "loss: 0.020208132395055145\n",
      "epoch:1027 from 100000\n",
      "loss: 0.020807874505408108\n",
      "epoch:1028 from 100000\n",
      "loss: 0.019525017589330673\n",
      "epoch:1029 from 100000\n",
      "loss: 0.018944296170957386\n",
      "epoch:1030 from 100000\n",
      "loss: 0.019314223260153085\n",
      "epoch:1031 from 100000\n",
      "loss: 0.018115728453267366\n",
      "epoch:1032 from 100000\n",
      "loss: 0.018508580600610003\n",
      "epoch:1033 from 100000\n",
      "loss: 0.021122769656358287\n",
      "epoch:1034 from 100000\n",
      "loss: 0.019872823846526444\n",
      "epoch:1035 from 100000\n",
      "loss: 0.019664921623189002\n",
      "epoch:1036 from 100000\n",
      "loss: 0.0196906701894477\n",
      "epoch:1037 from 100000\n",
      "loss: 0.020856989722233266\n",
      "epoch:1038 from 100000\n",
      "loss: 0.017886545974761248\n",
      "epoch:1039 from 100000\n",
      "loss: 0.021679317578673363\n",
      "epoch:1040 from 100000\n",
      "loss: 0.018701445951592177\n",
      "epoch:1041 from 100000\n",
      "loss: 0.019140660820994526\n",
      "epoch:1042 from 100000\n",
      "loss: 0.016473995347041637\n",
      "epoch:1043 from 100000\n",
      "loss: 0.020917301560984924\n",
      "epoch:1044 from 100000\n",
      "loss: 0.019783033872954547\n",
      "epoch:1045 from 100000\n",
      "loss: 0.01992197014624253\n",
      "epoch:1046 from 100000\n",
      "loss: 0.021077641053125262\n",
      "epoch:1047 from 100000\n",
      "loss: 0.019402551639359444\n",
      "epoch:1048 from 100000\n",
      "loss: 0.019957788550527766\n",
      "epoch:1049 from 100000\n",
      "loss: 0.01975091313943267\n",
      "epoch:1050 from 100000\n",
      "loss: 0.02053785987664014\n",
      "epoch:1051 from 100000\n",
      "loss: 0.01801141310716048\n",
      "epoch:1052 from 100000\n",
      "loss: 0.019095000170636922\n",
      "epoch:1053 from 100000\n",
      "loss: 0.019536056788638234\n",
      "epoch:1054 from 100000\n",
      "loss: 0.0214368590968661\n",
      "epoch:1055 from 100000\n",
      "loss: 0.020552600675728172\n",
      "epoch:1056 from 100000\n",
      "loss: 0.018247306055855006\n",
      "epoch:1057 from 100000\n",
      "loss: 0.01879150787135586\n",
      "epoch:1058 from 100000\n",
      "loss: 0.01737432455411181\n",
      "epoch:1059 from 100000\n",
      "loss: 0.018563511897809803\n",
      "epoch:1060 from 100000\n",
      "loss: 0.02018014050554484\n",
      "epoch:1061 from 100000\n",
      "loss: 0.018515347444918007\n",
      "epoch:1062 from 100000\n",
      "loss: 0.018854325753636658\n",
      "epoch:1063 from 100000\n",
      "loss: 0.02094796986784786\n",
      "epoch:1064 from 100000\n",
      "loss: 0.01979249104624614\n",
      "epoch:1065 from 100000\n",
      "loss: 0.02021975925890729\n",
      "epoch:1066 from 100000\n",
      "loss: 0.018581070937216282\n",
      "epoch:1067 from 100000\n",
      "loss: 0.0194144647102803\n",
      "epoch:1068 from 100000\n",
      "loss: 0.016397885454352945\n",
      "epoch:1069 from 100000\n",
      "loss: 0.019090175395831466\n",
      "epoch:1070 from 100000\n",
      "loss: 0.01858217379776761\n",
      "epoch:1071 from 100000\n",
      "loss: 0.020682759350165725\n",
      "epoch:1072 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9075.pt\n",
      "loss: 0.019113305141218007\n",
      "epoch:1073 from 100000\n",
      "loss: 0.019369712565094233\n",
      "epoch:1074 from 100000\n",
      "loss: 0.01937396317953244\n",
      "epoch:1075 from 100000\n",
      "loss: 0.017628770030569285\n",
      "epoch:1076 from 100000\n",
      "loss: 0.01939877140102908\n",
      "epoch:1077 from 100000\n",
      "loss: 0.01891294459346682\n",
      "epoch:1078 from 100000\n",
      "loss: 0.017471389641286805\n",
      "epoch:1079 from 100000\n",
      "loss: 0.01949021831387654\n",
      "epoch:1080 from 100000\n",
      "loss: 0.01957066304748878\n",
      "epoch:1081 from 100000\n",
      "loss: 0.022688429977279156\n",
      "epoch:1082 from 100000\n",
      "loss: 0.01848092523869127\n",
      "epoch:1083 from 100000\n",
      "loss: 0.018156660662498325\n",
      "epoch:1084 from 100000\n",
      "loss: 0.02017981599783525\n",
      "epoch:1085 from 100000\n",
      "loss: 0.01894679816905409\n",
      "epoch:1086 from 100000\n",
      "loss: 0.02044803136959672\n",
      "epoch:1087 from 100000\n",
      "loss: 0.0176741445902735\n",
      "epoch:1088 from 100000\n",
      "loss: 0.022424666676670313\n",
      "epoch:1089 from 100000\n",
      "retrying for data\n",
      "loss: 0.018821143254172057\n",
      "epoch:1090 from 100000\n",
      "loss: 0.01849948341259733\n",
      "epoch:1091 from 100000\n",
      "loss: 0.01918620930518955\n",
      "epoch:1092 from 100000\n",
      "loss: 0.018432206416036934\n",
      "epoch:1093 from 100000\n",
      "loss: 0.019787565281149\n",
      "epoch:1094 from 100000\n",
      "loss: 0.019452190666925162\n",
      "epoch:1095 from 100000\n",
      "loss: 0.01835589943220839\n",
      "epoch:1096 from 100000\n",
      "loss: 0.018653032544534653\n",
      "epoch:1097 from 100000\n",
      "loss: 0.023887525429017842\n",
      "epoch:1098 from 100000\n",
      "loss: 0.0187789419433102\n",
      "epoch:1099 from 100000\n",
      "loss: 0.019699260883498937\n",
      "epoch:1100 from 100000\n",
      "loss: 0.018496218894142658\n",
      "epoch:1101 from 100000\n",
      "loss: 0.01619686058256775\n",
      "epoch:1102 from 100000\n",
      "loss: 0.018552460271166638\n",
      "epoch:1103 from 100000\n",
      "loss: 0.019722886790987104\n",
      "epoch:1104 from 100000\n",
      "loss: 0.018037484667729586\n",
      "epoch:1105 from 100000\n",
      "loss: 0.019347435503732413\n",
      "epoch:1106 from 100000\n",
      "loss: 0.01813444256549701\n",
      "epoch:1107 from 100000\n",
      "loss: 0.018162045278586447\n",
      "epoch:1108 from 100000\n",
      "loss: 0.01774689508602023\n",
      "epoch:1109 from 100000\n",
      "loss: 0.01973431950318627\n",
      "epoch:1110 from 100000\n",
      "loss: 0.021681778191123158\n",
      "epoch:1111 from 100000\n",
      "loss: 0.018643585208337754\n",
      "epoch:1112 from 100000\n",
      "loss: 0.02176189242163673\n",
      "epoch:1113 from 100000\n",
      "loss: 0.017858949897345155\n",
      "epoch:1114 from 100000\n",
      "loss: 0.017984943580813706\n",
      "epoch:1115 from 100000\n",
      "loss: 0.019130079832393676\n",
      "epoch:1116 from 100000\n",
      "loss: 0.01872832083608955\n",
      "epoch:1117 from 100000\n",
      "loss: 0.01876609437749721\n",
      "epoch:1118 from 100000\n",
      "loss: 0.02338345005409792\n",
      "epoch:1119 from 100000\n",
      "loss: 0.01847725606057793\n",
      "epoch:1120 from 100000\n",
      "loss: 0.01999105414142832\n",
      "epoch:1121 from 100000\n",
      "loss: 0.018907436809968203\n",
      "epoch:1122 from 100000\n",
      "loss: 0.019419635325903073\n",
      "epoch:1123 from 100000\n",
      "loss: 0.019366833323147148\n",
      "epoch:1124 from 100000\n",
      "loss: 0.019022199732717127\n",
      "epoch:1125 from 100000\n",
      "loss: 0.017687351792119443\n",
      "epoch:1126 from 100000\n",
      "loss: 0.020197107107378542\n",
      "epoch:1127 from 100000\n",
      "loss: 0.01850329921580851\n",
      "epoch:1128 from 100000\n",
      "loss: 0.020090367819648236\n",
      "epoch:1129 from 100000\n",
      "loss: 0.018894118897151202\n",
      "epoch:1130 from 100000\n",
      "loss: 0.020395074068801478\n",
      "epoch:1131 from 100000\n",
      "loss: 0.021270554163493216\n",
      "epoch:1132 from 100000\n",
      "loss: 0.020598283619619906\n",
      "epoch:1133 from 100000\n",
      "loss: 0.01880888914456591\n",
      "epoch:1134 from 100000\n",
      "loss: 0.01996239641448483\n",
      "epoch:1135 from 100000\n",
      "retrying for data\n",
      "loss: 0.018064307107124478\n",
      "epoch:1136 from 100000\n",
      "loss: 0.01849631906952709\n",
      "epoch:1137 from 100000\n",
      "loss: 0.017435224348446354\n",
      "epoch:1138 from 100000\n",
      "loss: 0.01935216720448807\n",
      "epoch:1139 from 100000\n",
      "loss: 0.018982141627930105\n",
      "epoch:1140 from 100000\n",
      "loss: 0.01937621209071949\n",
      "epoch:1141 from 100000\n",
      "loss: 0.019371689821127802\n",
      "epoch:1142 from 100000\n",
      "loss: 0.019341798324603587\n",
      "epoch:1143 from 100000\n",
      "loss: 0.018991118296980858\n",
      "epoch:1144 from 100000\n",
      "loss: 0.020268008462153375\n",
      "epoch:1145 from 100000\n",
      "loss: 0.01921015908010304\n",
      "epoch:1146 from 100000\n",
      "loss: 0.01922335574636236\n",
      "epoch:1147 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9150.pt\n",
      "loss: 0.017434186360333115\n",
      "epoch:1148 from 100000\n",
      "loss: 0.020895291992928833\n",
      "epoch:1149 from 100000\n",
      "loss: 0.01909707870800048\n",
      "epoch:1150 from 100000\n",
      "loss: 0.02111528709065169\n",
      "epoch:1151 from 100000\n",
      "loss: 0.01900278532411903\n",
      "epoch:1152 from 100000\n",
      "loss: 0.020176033314783126\n",
      "epoch:1153 from 100000\n",
      "loss: 0.01897113845916465\n",
      "epoch:1154 from 100000\n",
      "loss: 0.01883888605516404\n",
      "epoch:1155 from 100000\n",
      "loss: 0.02133166848216206\n",
      "epoch:1156 from 100000\n",
      "loss: 0.01919248403282836\n",
      "epoch:1157 from 100000\n",
      "loss: 0.017902005783980712\n",
      "epoch:1158 from 100000\n",
      "loss: 0.021010059484979138\n",
      "epoch:1159 from 100000\n",
      "loss: 0.02019603317603469\n",
      "epoch:1160 from 100000\n",
      "loss: 0.018031078070634976\n",
      "epoch:1161 from 100000\n",
      "loss: 0.019594052428146824\n",
      "epoch:1162 from 100000\n",
      "loss: 0.01725365419406444\n",
      "epoch:1163 from 100000\n",
      "loss: 0.019192643580026925\n",
      "epoch:1164 from 100000\n",
      "loss: 0.0193598055629991\n",
      "epoch:1165 from 100000\n",
      "loss: 0.020392899285070598\n",
      "epoch:1166 from 100000\n",
      "loss: 0.019804884039331228\n",
      "epoch:1167 from 100000\n",
      "loss: 0.02077959047164768\n",
      "epoch:1168 from 100000\n",
      "loss: 0.020734194200485945\n",
      "epoch:1169 from 100000\n",
      "loss: 0.016821450262796134\n",
      "epoch:1170 from 100000\n",
      "loss: 0.018476892495527864\n",
      "epoch:1171 from 100000\n",
      "loss: 0.019884774344973266\n",
      "epoch:1172 from 100000\n",
      "loss: 0.016750488139223307\n",
      "epoch:1173 from 100000\n",
      "loss: 0.01972366770496592\n",
      "epoch:1174 from 100000\n",
      "loss: 0.018117705680197105\n",
      "epoch:1175 from 100000\n",
      "loss: 0.02213901322102174\n",
      "epoch:1176 from 100000\n",
      "loss: 0.018039022339507937\n",
      "epoch:1177 from 100000\n",
      "loss: 0.01699540502158925\n",
      "epoch:1178 from 100000\n",
      "loss: 0.018352186016272753\n",
      "epoch:1179 from 100000\n",
      "loss: 0.020742204505950212\n",
      "epoch:1180 from 100000\n",
      "loss: 0.0201030409662053\n",
      "epoch:1181 from 100000\n",
      "loss: 0.020038586982991546\n",
      "epoch:1182 from 100000\n",
      "loss: 0.01880436995998025\n",
      "epoch:1183 from 100000\n",
      "loss: 0.019442945369519293\n",
      "epoch:1184 from 100000\n",
      "loss: 0.01966269640251994\n",
      "epoch:1185 from 100000\n",
      "loss: 0.019921929808333516\n",
      "epoch:1186 from 100000\n",
      "loss: 0.018120666907634586\n",
      "epoch:1187 from 100000\n",
      "loss: 0.018132669560145587\n",
      "epoch:1188 from 100000\n",
      "loss: 0.01696415978949517\n",
      "epoch:1189 from 100000\n",
      "loss: 0.02021015778882429\n",
      "epoch:1190 from 100000\n",
      "loss: 0.01809120026882738\n",
      "epoch:1191 from 100000\n",
      "loss: 0.018773764168145135\n",
      "epoch:1192 from 100000\n",
      "loss: 0.018693374877329916\n",
      "epoch:1193 from 100000\n",
      "loss: 0.01820376329123974\n",
      "epoch:1194 from 100000\n",
      "loss: 0.017890860326588154\n",
      "epoch:1195 from 100000\n",
      "loss: 0.01859998266445473\n",
      "epoch:1196 from 100000\n",
      "loss: 0.018693749501835555\n",
      "epoch:1197 from 100000\n",
      "loss: 0.019360232225153595\n",
      "epoch:1198 from 100000\n",
      "loss: 0.018710573436692357\n",
      "epoch:1199 from 100000\n",
      "loss: 0.018659225199371576\n",
      "epoch:1200 from 100000\n",
      "loss: 0.020426287257578224\n",
      "epoch:1201 from 100000\n",
      "loss: 0.019095972005743533\n",
      "epoch:1202 from 100000\n",
      "loss: 0.01803287919028662\n",
      "epoch:1203 from 100000\n",
      "loss: 0.019083775230683386\n",
      "epoch:1204 from 100000\n",
      "loss: 0.019908845890313387\n",
      "epoch:1205 from 100000\n",
      "loss: 0.018585825338959694\n",
      "epoch:1206 from 100000\n",
      "loss: 0.016315144312102348\n",
      "epoch:1207 from 100000\n",
      "loss: 0.018724794092122465\n",
      "epoch:1208 from 100000\n",
      "loss: 0.018318758346140385\n",
      "epoch:1209 from 100000\n",
      "loss: 0.017963089630939066\n",
      "epoch:1210 from 100000\n",
      "loss: 0.019414349924772978\n",
      "epoch:1211 from 100000\n",
      "loss: 0.018524062528740615\n",
      "epoch:1212 from 100000\n",
      "loss: 0.018480410217307508\n",
      "epoch:1213 from 100000\n",
      "loss: 0.01955254835775122\n",
      "epoch:1214 from 100000\n",
      "loss: 0.019965069310273975\n",
      "epoch:1215 from 100000\n",
      "loss: 0.018880990566685796\n",
      "epoch:1216 from 100000\n",
      "loss: 0.019071750401053578\n",
      "epoch:1217 from 100000\n",
      "loss: 0.016181229904759675\n",
      "epoch:1218 from 100000\n",
      "loss: 0.01948742297827266\n",
      "epoch:1219 from 100000\n",
      "loss: 0.020776259887497872\n",
      "epoch:1220 from 100000\n",
      "loss: 0.019221888738684356\n",
      "epoch:1221 from 100000\n",
      "loss: 0.019919747370295227\n",
      "epoch:1222 from 100000\n",
      "retrying for data\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9225.pt\n",
      "loss: 0.02020173240453005\n",
      "epoch:1223 from 100000\n",
      "loss: 0.02011656094691716\n",
      "epoch:1224 from 100000\n",
      "loss: 0.0192588705685921\n",
      "epoch:1225 from 100000\n",
      "loss: 0.01906073809368536\n",
      "epoch:1226 from 100000\n",
      "loss: 0.019428492756560445\n",
      "epoch:1227 from 100000\n",
      "loss: 0.017179541697259992\n",
      "epoch:1228 from 100000\n",
      "loss: 0.019039559294469655\n",
      "epoch:1229 from 100000\n",
      "loss: 0.022279295430053025\n",
      "epoch:1230 from 100000\n",
      "loss: 0.020165511697996408\n",
      "epoch:1231 from 100000\n",
      "loss: 0.020210135844536126\n",
      "epoch:1232 from 100000\n",
      "loss: 0.01780728215817362\n",
      "epoch:1233 from 100000\n",
      "loss: 0.019161567033734173\n",
      "epoch:1234 from 100000\n",
      "loss: 0.0200405478826724\n",
      "epoch:1235 from 100000\n",
      "loss: 0.017726612044498324\n",
      "epoch:1236 from 100000\n",
      "loss: 0.0182947643334046\n",
      "epoch:1237 from 100000\n",
      "loss: 0.01940037519671023\n",
      "epoch:1238 from 100000\n",
      "loss: 0.01932369137648493\n",
      "epoch:1239 from 100000\n",
      "loss: 0.019534891413059086\n",
      "epoch:1240 from 100000\n",
      "loss: 0.01928351423703134\n",
      "epoch:1241 from 100000\n",
      "loss: 0.018713576428126544\n",
      "epoch:1242 from 100000\n",
      "loss: 0.02308201463893056\n",
      "epoch:1243 from 100000\n",
      "loss: 0.01777138764737174\n",
      "epoch:1244 from 100000\n",
      "loss: 0.01905508787604049\n",
      "epoch:1245 from 100000\n",
      "loss: 0.018514121533371508\n",
      "epoch:1246 from 100000\n",
      "loss: 0.021037634811364114\n",
      "epoch:1247 from 100000\n",
      "loss: 0.018999177496880293\n",
      "epoch:1248 from 100000\n",
      "loss: 0.021332379372324795\n",
      "epoch:1249 from 100000\n",
      "loss: 0.0198380557121709\n",
      "epoch:1250 from 100000\n",
      "loss: 0.018230706395115703\n",
      "epoch:1251 from 100000\n",
      "loss: 0.020083919924218208\n",
      "epoch:1252 from 100000\n",
      "loss: 0.01958390063373372\n",
      "epoch:1253 from 100000\n",
      "1188746loss: 0.019317926577059552\n",
      "epoch:1254 from 100000\n",
      "loss: 0.018119812826626003\n",
      "epoch:1255 from 100000\n",
      "loss: 0.019201103423256427\n",
      "epoch:1256 from 100000\n",
      "loss: 0.02004735410446301\n",
      "epoch:1257 from 100000\n",
      "loss: 0.02130790095543489\n",
      "epoch:1258 from 100000\n",
      "loss: 0.01754037698265165\n",
      "epoch:1259 from 100000\n",
      "loss: 0.019979695789515972\n",
      "epoch:1260 from 100000\n",
      "loss: 0.020342050935141742\n",
      "epoch:1261 from 100000\n",
      "loss: 0.017580554413143545\n",
      "epoch:1262 from 100000\n",
      "loss: 0.019680289668031037\n",
      "epoch:1263 from 100000\n",
      "loss: 0.0202945182682015\n",
      "epoch:1264 from 100000\n",
      "loss: 0.021014962054323405\n",
      "epoch:1265 from 100000\n",
      "loss: 0.018646675045602024\n",
      "epoch:1266 from 100000\n",
      "loss: 0.020673662424087524\n",
      "epoch:1267 from 100000\n",
      "loss: 0.019722250232007354\n",
      "epoch:1268 from 100000\n",
      "loss: 0.019323243759572506\n",
      "epoch:1269 from 100000\n",
      "loss: 0.020190107927192003\n",
      "epoch:1270 from 100000\n",
      "loss: 0.019577068509534\n",
      "epoch:1271 from 100000\n",
      "loss: 0.018956156156491488\n",
      "epoch:1272 from 100000\n",
      "loss: 0.019037379359360784\n",
      "epoch:1273 from 100000\n",
      "loss: 0.01772094494663179\n",
      "epoch:1274 from 100000\n",
      "loss: 0.02073516830569133\n",
      "epoch:1275 from 100000\n",
      "loss: 0.01902773286565207\n",
      "epoch:1276 from 100000\n",
      "loss: 0.020250322704669088\n",
      "epoch:1277 from 100000\n",
      "loss: 0.019263265712652355\n",
      "epoch:1278 from 100000\n",
      "loss: 0.020221444545313716\n",
      "epoch:1279 from 100000\n",
      "loss: 0.018886432517319918\n",
      "epoch:1280 from 100000\n",
      "loss: 0.020023830351419747\n",
      "epoch:1281 from 100000\n",
      "loss: 0.017833331250585616\n",
      "epoch:1282 from 100000\n",
      "loss: 0.020789755217265338\n",
      "epoch:1283 from 100000\n",
      "loss: 0.020030630752444267\n",
      "epoch:1284 from 100000\n",
      "loss: 0.021340853883884847\n",
      "epoch:1285 from 100000\n",
      "loss: 0.016588673170190305\n",
      "epoch:1286 from 100000\n",
      "loss: 0.019917718542274088\n",
      "epoch:1287 from 100000\n",
      "loss: 0.019223466981202364\n",
      "epoch:1288 from 100000\n",
      "loss: 0.018256044771987945\n",
      "epoch:1289 from 100000\n",
      "loss: 0.022150640608742833\n",
      "epoch:1290 from 100000\n",
      "loss: 0.019109857617877424\n",
      "epoch:1291 from 100000\n",
      "loss: 0.020115321327466518\n",
      "epoch:1292 from 100000\n",
      "loss: 0.018752521893475205\n",
      "epoch:1293 from 100000\n",
      "loss: 0.020115777908358723\n",
      "epoch:1294 from 100000\n",
      "1194060loss: 0.019396190182305872\n",
      "epoch:1295 from 100000\n",
      "retrying for data\n",
      "loss: 0.019024139852263033\n",
      "epoch:1296 from 100000\n",
      "loss: 0.01757934904890135\n",
      "epoch:1297 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9300.pt\n",
      "loss: 0.01823417958803475\n",
      "epoch:1298 from 100000\n",
      "loss: 0.020903853874187917\n",
      "epoch:1299 from 100000\n",
      "loss: 0.022023701632861048\n",
      "epoch:1300 from 100000\n",
      "loss: 0.01985796500230208\n",
      "epoch:1301 from 100000\n",
      "loss: 0.01905237464234233\n",
      "epoch:1302 from 100000\n",
      "loss: 0.016696423379471526\n",
      "epoch:1303 from 100000\n",
      "loss: 0.01906154945027083\n",
      "epoch:1304 from 100000\n",
      "loss: 0.02140625228639692\n",
      "epoch:1305 from 100000\n",
      "loss: 0.01952398131834343\n",
      "epoch:1306 from 100000\n",
      "loss: 0.018749725131783634\n",
      "epoch:1307 from 100000\n",
      "loss: 0.01922517636558041\n",
      "epoch:1308 from 100000\n",
      "loss: 0.021462657605297863\n",
      "epoch:1309 from 100000\n",
      "loss: 0.01928174021304585\n",
      "epoch:1310 from 100000\n",
      "loss: 0.020087470766156912\n",
      "epoch:1311 from 100000\n",
      "loss: 0.01981735962908715\n",
      "epoch:1312 from 100000\n",
      "loss: 0.01649546908447519\n",
      "epoch:1313 from 100000\n",
      "loss: 0.017621802049688995\n",
      "epoch:1314 from 100000\n",
      "loss: 0.019536060659447685\n",
      "epoch:1315 from 100000\n",
      "loss: 0.018649333040229976\n",
      "epoch:1316 from 100000\n",
      "loss: 0.02270599518669769\n",
      "epoch:1317 from 100000\n",
      "loss: 0.01957833959022537\n",
      "epoch:1318 from 100000\n",
      "loss: 0.02175508445361629\n",
      "epoch:1319 from 100000\n",
      "loss: 0.020569043408613652\n",
      "epoch:1320 from 100000\n",
      "loss: 0.0161554827936925\n",
      "epoch:1321 from 100000\n",
      "loss: 0.021894802106544375\n",
      "epoch:1322 from 100000\n",
      "loss: 0.020141997432801872\n",
      "epoch:1323 from 100000\n",
      "loss: 0.017907258879859\n",
      "epoch:1324 from 100000\n",
      "loss: 0.019904179498553276\n",
      "epoch:1325 from 100000\n",
      "loss: 0.016567304264754057\n",
      "epoch:1326 from 100000\n",
      "loss: 0.02069752151146531\n",
      "epoch:1327 from 100000\n",
      "loss: 0.02033197565469891\n",
      "epoch:1328 from 100000\n",
      "loss: 0.019374614814296365\n",
      "epoch:1329 from 100000\n",
      "loss: 0.021382608450949192\n",
      "epoch:1330 from 100000\n",
      "loss: 0.018899696005973965\n",
      "epoch:1331 from 100000\n",
      "loss: 0.02108556480379775\n",
      "epoch:1332 from 100000\n",
      "loss: 0.018991196004208177\n",
      "epoch:1333 from 100000\n",
      "loss: 0.01809491403400898\n",
      "epoch:1334 from 100000\n",
      "loss: 0.019473552441922948\n",
      "epoch:1335 from 100000\n",
      "loss: 0.01846521202242002\n",
      "epoch:1336 from 100000\n",
      "loss: 0.01805432024411857\n",
      "epoch:1337 from 100000\n",
      "loss: 0.019950776651967317\n",
      "epoch:1338 from 100000\n",
      "loss: 0.01737658234196715\n",
      "epoch:1339 from 100000\n",
      "loss: 0.02181933610700071\n",
      "epoch:1340 from 100000\n",
      "loss: 0.019740831630770117\n",
      "epoch:1341 from 100000\n",
      "loss: 0.016863450582604855\n",
      "epoch:1342 from 100000\n",
      "loss: 0.020766680885571986\n",
      "epoch:1343 from 100000\n",
      "loss: 0.01856152043910697\n",
      "epoch:1344 from 100000\n",
      "loss: 0.021465201396495104\n",
      "epoch:1345 from 100000\n",
      "loss: 0.019658247765619308\n",
      "epoch:1346 from 100000\n",
      "loss: 0.016597469395492226\n",
      "epoch:1347 from 100000\n",
      "loss: 0.0172638050862588\n",
      "epoch:1348 from 100000\n",
      "loss: 0.01776265329681337\n",
      "epoch:1349 from 100000\n",
      "loss: 0.019161201285896823\n",
      "epoch:1350 from 100000\n",
      "loss: 0.018998203158844262\n",
      "epoch:1351 from 100000\n",
      "loss: 0.018534813192673028\n",
      "epoch:1352 from 100000\n",
      "loss: 0.01782566396286711\n",
      "epoch:1353 from 100000\n",
      "loss: 0.018150240590330213\n",
      "epoch:1354 from 100000\n",
      "loss: 0.021275565202813596\n",
      "epoch:1355 from 100000\n",
      "loss: 0.019549419041140936\n",
      "epoch:1356 from 100000\n",
      "loss: 0.018112901889253408\n",
      "epoch:1357 from 100000\n",
      "loss: 0.019491089216899127\n",
      "epoch:1358 from 100000\n",
      "loss: 0.01772163639543578\n",
      "epoch:1359 from 100000\n",
      "loss: 0.0164819901692681\n",
      "epoch:1360 from 100000\n",
      "loss: 0.020445089496206492\n",
      "epoch:1361 from 100000\n",
      "loss: 0.019951736147049814\n",
      "epoch:1362 from 100000\n",
      "loss: 0.0196037984569557\n",
      "epoch:1363 from 100000\n",
      "loss: 0.018606982426717877\n",
      "epoch:1364 from 100000\n",
      "loss: 0.01868035161169246\n",
      "epoch:1365 from 100000\n",
      "loss: 0.01781637573731132\n",
      "epoch:1366 from 100000\n",
      "loss: 0.017482109426055104\n",
      "epoch:1367 from 100000\n",
      "loss: 0.01902395993238315\n",
      "epoch:1368 from 100000\n",
      "loss: 0.017325402761343867\n",
      "epoch:1369 from 100000\n",
      "loss: 0.01850062859011814\n",
      "epoch:1370 from 100000\n",
      "loss: 0.019789182697422802\n",
      "epoch:1371 from 100000\n",
      "loss: 0.01997675927123055\n",
      "epoch:1372 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9375.pt\n",
      "loss: 0.01855938497465104\n",
      "epoch:1373 from 100000\n",
      "loss: 0.018817157833836973\n",
      "epoch:1374 from 100000\n",
      "loss: 0.020834174763876945\n",
      "epoch:1375 from 100000\n",
      "loss: 0.017987641942454502\n",
      "epoch:1376 from 100000\n",
      "loss: 0.020586866477970034\n",
      "epoch:1377 from 100000\n",
      "loss: 0.017715567315462977\n",
      "epoch:1378 from 100000\n",
      "loss: 0.017586502654012293\n",
      "epoch:1379 from 100000\n",
      "loss: 0.02038390311645344\n",
      "epoch:1380 from 100000\n",
      "loss: 0.019160501076839864\n",
      "epoch:1381 from 100000\n",
      "loss: 0.019186683872248977\n",
      "epoch:1382 from 100000\n",
      "loss: 0.019005644891876727\n",
      "epoch:1383 from 100000\n",
      "loss: 0.020803297753445804\n",
      "epoch:1384 from 100000\n",
      "loss: 0.018597450602101162\n",
      "epoch:1385 from 100000\n",
      "loss: 0.018004321376793087\n",
      "epoch:1386 from 100000\n",
      "loss: 0.020409375661984086\n",
      "epoch:1387 from 100000\n",
      "loss: 0.01885714684613049\n",
      "epoch:1388 from 100000\n",
      "loss: 0.02140897448407486\n",
      "epoch:1389 from 100000\n",
      "loss: 0.018674523395020515\n",
      "epoch:1390 from 100000\n",
      "loss: 0.016806909639853984\n",
      "epoch:1391 from 100000\n",
      "loss: 0.02033322924398817\n",
      "epoch:1392 from 100000\n",
      "loss: 0.019929201691411436\n",
      "epoch:1393 from 100000\n",
      "loss: 0.020817826152779162\n",
      "epoch:1394 from 100000\n",
      "loss: 0.0170037315110676\n",
      "epoch:1395 from 100000\n",
      "loss: 0.021549032477196306\n",
      "epoch:1396 from 100000\n",
      "loss: 0.01795449946075678\n",
      "epoch:1397 from 100000\n",
      "loss: 0.01823479391168803\n",
      "epoch:1398 from 100000\n",
      "loss: 0.019506680662743747\n",
      "epoch:1399 from 100000\n",
      "loss: 0.015695569629315287\n",
      "epoch:1400 from 100000\n",
      "loss: 0.02142899384489283\n",
      "epoch:1401 from 100000\n",
      "loss: 0.018602938391268253\n",
      "epoch:1402 from 100000\n",
      "loss: 0.01887162437196821\n",
      "epoch:1403 from 100000\n",
      "loss: 0.017792243452277035\n",
      "epoch:1404 from 100000\n",
      "loss: 0.018534194852691144\n",
      "epoch:1405 from 100000\n",
      "loss: 0.01948172732954845\n",
      "epoch:1406 from 100000\n",
      "loss: 0.01895881973905489\n",
      "epoch:1407 from 100000\n",
      "retrying for data\n",
      "retrying for data\n",
      "loss: 0.01793286227621138\n",
      "epoch:1408 from 100000\n",
      "loss: 0.01984466757858172\n",
      "epoch:1409 from 100000\n",
      "loss: 0.019453779619652778\n",
      "epoch:1410 from 100000\n",
      "loss: 0.021799896436277777\n",
      "epoch:1411 from 100000\n",
      "loss: 0.019327996531501412\n",
      "epoch:1412 from 100000\n",
      "loss: 0.02045329171232879\n",
      "epoch:1413 from 100000\n",
      "loss: 0.018138143117539585\n",
      "epoch:1414 from 100000\n",
      "loss: 0.019739613984711468\n",
      "epoch:1415 from 100000\n",
      "loss: 0.0206352187669836\n",
      "epoch:1416 from 100000\n",
      "loss: 0.018934185791295022\n",
      "epoch:1417 from 100000\n",
      "loss: 0.018890271370764822\n",
      "epoch:1418 from 100000\n",
      "loss: 0.021043797489255667\n",
      "epoch:1419 from 100000\n",
      "loss: 0.020887755206786096\n",
      "epoch:1420 from 100000\n",
      "loss: 0.019070402311626822\n",
      "epoch:1421 from 100000\n",
      "loss: 0.01941880857339129\n",
      "epoch:1422 from 100000\n",
      "loss: 0.019142423989251256\n",
      "epoch:1423 from 100000\n",
      "loss: 0.01936057535931468\n",
      "epoch:1424 from 100000\n",
      "loss: 0.02045704855117947\n",
      "epoch:1425 from 100000\n",
      "loss: 0.020037083188071847\n",
      "epoch:1426 from 100000\n",
      "loss: 0.02251006942242384\n",
      "epoch:1427 from 100000\n",
      "loss: 0.018041740986518562\n",
      "epoch:1428 from 100000\n",
      "loss: 0.01899005990708247\n",
      "epoch:1429 from 100000\n",
      "loss: 0.017161377298180014\n",
      "epoch:1430 from 100000\n",
      "loss: 0.01953601452987641\n",
      "epoch:1431 from 100000\n",
      "loss: 0.018435083620715886\n",
      "epoch:1432 from 100000\n",
      "loss: 0.019181698036845773\n",
      "epoch:1433 from 100000\n",
      "loss: 0.018706014787312597\n",
      "epoch:1434 from 100000\n",
      "loss: 0.01839972607558593\n",
      "epoch:1435 from 100000\n",
      "loss: 0.021457020426169038\n",
      "epoch:1436 from 100000\n",
      "loss: 0.02105140214553103\n",
      "epoch:1437 from 100000\n",
      "loss: 0.01821556079084985\n",
      "epoch:1438 from 100000\n",
      "loss: 0.018951439182274044\n",
      "epoch:1439 from 100000\n",
      "loss: 0.017372879665344954\n",
      "epoch:1440 from 100000\n",
      "loss: 0.017298301972914487\n",
      "epoch:1441 from 100000\n",
      "loss: 0.01896662311628461\n",
      "epoch:1442 from 100000\n",
      "loss: 0.020254953240510076\n",
      "epoch:1443 from 100000\n",
      "loss: 0.018933297076728195\n",
      "epoch:1444 from 100000\n",
      "loss: 0.01832327153533697\n",
      "epoch:1445 from 100000\n",
      "loss: 0.019663222250528634\n",
      "epoch:1446 from 100000\n",
      "loss: 0.01729334658011794\n",
      "epoch:1447 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9450.pt\n",
      "loss: 0.020200674422085285\n",
      "epoch:1448 from 100000\n",
      "loss: 0.01833917124895379\n",
      "epoch:1449 from 100000\n",
      "loss: 0.018984781054314226\n",
      "epoch:1450 from 100000\n",
      "loss: 0.017729464394506067\n",
      "epoch:1451 from 100000\n",
      "retrying for data\n",
      "loss: 0.02036645053885877\n",
      "epoch:1452 from 100000\n",
      "loss: 0.01879333221586421\n",
      "epoch:1453 from 100000\n",
      "loss: 0.01616198889678344\n",
      "epoch:1454 from 100000\n",
      "loss: 0.020248185872333124\n",
      "epoch:1455 from 100000\n",
      "loss: 0.0184809896745719\n",
      "epoch:1456 from 100000\n",
      "loss: 0.01816404319833964\n",
      "epoch:1457 from 100000\n",
      "loss: 0.019437108392594382\n",
      "epoch:1458 from 100000\n",
      "loss: 0.016659880348015577\n",
      "epoch:1459 from 100000\n",
      "loss: 0.018928426783531904\n",
      "epoch:1460 from 100000\n",
      "loss: 0.020057261746842414\n",
      "epoch:1461 from 100000\n",
      "loss: 0.017157402238808572\n",
      "epoch:1462 from 100000\n",
      "loss: 0.01971522968960926\n",
      "epoch:1463 from 100000\n",
      "loss: 0.019185560900950804\n",
      "epoch:1464 from 100000\n",
      "loss: 0.019564477377571166\n",
      "epoch:1465 from 100000\n",
      "loss: 0.02078298997366801\n",
      "epoch:1466 from 100000\n",
      "loss: 0.019086370652075857\n",
      "epoch:1467 from 100000\n",
      "loss: 0.01909465662902221\n",
      "epoch:1468 from 100000\n",
      "loss: 0.017484779498772696\n",
      "epoch:1469 from 100000\n",
      "loss: 0.018082196649629623\n",
      "epoch:1470 from 100000\n",
      "loss: 0.01960918091936037\n",
      "epoch:1471 from 100000\n",
      "loss: 0.019859726075083017\n",
      "epoch:1472 from 100000\n",
      "loss: 0.019418809039052576\n",
      "epoch:1473 from 100000\n",
      "loss: 0.019757899164687842\n",
      "epoch:1474 from 100000\n",
      "loss: 0.018611945735756308\n",
      "epoch:1475 from 100000\n",
      "loss: 0.018132483557565138\n",
      "epoch:1476 from 100000\n",
      "loss: 0.01813635660801083\n",
      "epoch:1477 from 100000\n",
      "loss: 0.019794677675236017\n",
      "epoch:1478 from 100000\n",
      "loss: 0.019032015290576965\n",
      "epoch:1479 from 100000\n",
      "loss: 0.01809832706931047\n",
      "epoch:1480 from 100000\n",
      "loss: 0.017969617969356477\n",
      "epoch:1481 from 100000\n",
      "loss: 0.01957865501753986\n",
      "epoch:1482 from 100000\n",
      "loss: 0.017105322680436075\n",
      "epoch:1483 from 100000\n",
      "loss: 0.019721788121387362\n",
      "epoch:1484 from 100000\n",
      "loss: 0.02077209361596033\n",
      "epoch:1485 from 100000\n",
      "loss: 0.02029404597124085\n",
      "epoch:1486 from 100000\n",
      "loss: 0.020208013418596238\n",
      "epoch:1487 from 100000\n",
      "loss: 0.019654479285236448\n",
      "epoch:1488 from 100000\n",
      "loss: 0.018851681263186038\n",
      "epoch:1489 from 100000\n",
      "loss: 0.020289360487367958\n",
      "epoch:1490 from 100000\n",
      "loss: 0.021301403816323727\n",
      "epoch:1491 from 100000\n",
      "loss: 0.019136085058562458\n",
      "epoch:1492 from 100000\n",
      "loss: 0.019981337420176715\n",
      "epoch:1493 from 100000\n",
      "loss: 0.017932250280864537\n",
      "epoch:1494 from 100000\n",
      "loss: 0.021406419051345438\n",
      "epoch:1495 from 100000\n",
      "loss: 0.018762022722512484\n",
      "epoch:1496 from 100000\n",
      "loss: 0.019457868009340018\n",
      "epoch:1497 from 100000\n",
      "loss: 0.017541347013320774\n",
      "epoch:1498 from 100000\n",
      "loss: 0.018330248014535755\n",
      "epoch:1499 from 100000\n",
      "loss: 0.01984140934655443\n",
      "epoch:1500 from 100000\n",
      "loss: 0.019703755737282336\n",
      "epoch:1501 from 100000\n",
      "loss: 0.018970024888403714\n",
      "epoch:1502 from 100000\n",
      "loss: 0.018516838375944644\n",
      "epoch:1503 from 100000\n",
      "loss: 0.017719795170705765\n",
      "epoch:1504 from 100000\n",
      "loss: 0.017472906270995736\n",
      "epoch:1505 from 100000\n",
      "loss: 0.019507720426190645\n",
      "epoch:1506 from 100000\n",
      "loss: 0.01916875026654452\n",
      "epoch:1507 from 100000\n",
      "loss: 0.019440058938926086\n",
      "epoch:1508 from 100000\n",
      "loss: 0.018445127876475453\n",
      "epoch:1509 from 100000\n",
      "loss: 0.018385426315944642\n",
      "epoch:1510 from 100000\n",
      "loss: 0.016547585313674062\n",
      "epoch:1511 from 100000\n",
      "loss: 0.019043371721636504\n",
      "epoch:1512 from 100000\n",
      "loss: 0.01749180513434112\n",
      "epoch:1513 from 100000\n",
      "loss: 0.017898949095979333\n",
      "epoch:1514 from 100000\n",
      "loss: 0.01852749998215586\n",
      "epoch:1515 from 100000\n",
      "loss: 0.0177474589436315\n",
      "epoch:1516 from 100000\n",
      "loss: 0.016104207490570843\n",
      "epoch:1517 from 100000\n",
      "loss: 0.021115105861099437\n",
      "epoch:1518 from 100000\n",
      "loss: 0.02129280788358301\n",
      "epoch:1519 from 100000\n",
      "loss: 0.019934382697101682\n",
      "epoch:1520 from 100000\n",
      "loss: 0.016974673548247665\n",
      "epoch:1521 from 100000\n",
      "loss: 0.021796069340780377\n",
      "epoch:1522 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9525.pt\n",
      "loss: 0.017646575812250376\n",
      "epoch:1523 from 100000\n",
      "loss: 0.018451293231919408\n",
      "epoch:1524 from 100000\n",
      "loss: 0.01782968535553664\n",
      "epoch:1525 from 100000\n",
      "loss: 0.017733160872012377\n",
      "epoch:1526 from 100000\n",
      "loss: 0.018714135454501957\n",
      "epoch:1527 from 100000\n",
      "loss: 0.021873143268749118\n",
      "epoch:1528 from 100000\n",
      "loss: 0.019609907700214535\n",
      "epoch:1529 from 100000\n",
      "loss: 0.017852363584097475\n",
      "epoch:1530 from 100000\n",
      "loss: 0.022434615821111947\n",
      "epoch:1531 from 100000\n",
      "loss: 0.021295069018378854\n",
      "epoch:1532 from 100000\n",
      "loss: 0.020419914042577147\n",
      "epoch:1533 from 100000\n",
      "loss: 0.019450126856099814\n",
      "epoch:1534 from 100000\n",
      "loss: 0.018899533548392355\n",
      "epoch:1535 from 100000\n",
      "loss: 0.01987758604809642\n",
      "epoch:1536 from 100000\n",
      "loss: 0.020297530631069094\n",
      "epoch:1537 from 100000\n",
      "loss: 0.019442767661530524\n",
      "epoch:1538 from 100000\n",
      "loss: 0.019188892387319356\n",
      "epoch:1539 from 100000\n",
      "loss: 0.01918075530556962\n",
      "epoch:1540 from 100000\n",
      "loss: 0.01841657972545363\n",
      "epoch:1541 from 100000\n",
      "loss: 0.018763173808110878\n",
      "epoch:1542 from 100000\n",
      "loss: 0.01770704094087705\n",
      "epoch:1543 from 100000\n",
      "loss: 0.01956790452823043\n",
      "epoch:1544 from 100000\n",
      "loss: 0.019851668912451714\n",
      "epoch:1545 from 100000\n",
      "loss: 0.02087854576529935\n",
      "epoch:1546 from 100000\n",
      "loss: 0.020065489108674228\n",
      "epoch:1547 from 100000\n",
      "loss: 0.015482725837500766\n",
      "epoch:1548 from 100000\n",
      "loss: 0.02049299661302939\n",
      "epoch:1549 from 100000\n",
      "loss: 0.020279165939427912\n",
      "epoch:1550 from 100000\n",
      "loss: 0.01989134243922308\n",
      "epoch:1551 from 100000\n",
      "loss: 0.021249032928608358\n",
      "epoch:1552 from 100000\n",
      "loss: 0.018877030845033005\n",
      "epoch:1553 from 100000\n",
      "loss: 0.01658773352392018\n",
      "epoch:1554 from 100000\n",
      "loss: 0.018303178600035608\n",
      "epoch:1555 from 100000\n",
      "loss: 0.019659185432828963\n",
      "epoch:1556 from 100000\n",
      "loss: 0.018445028457790613\n",
      "epoch:1557 from 100000\n",
      "loss: 0.01793779170839116\n",
      "epoch:1558 from 100000\n",
      "loss: 0.017485526099335402\n",
      "epoch:1559 from 100000\n",
      "loss: 0.01912981312489137\n",
      "epoch:1560 from 100000\n",
      "1237489loss: 0.017295324010774493\n",
      "epoch:1561 from 100000\n",
      "loss: 0.019077469070907682\n",
      "epoch:1562 from 100000\n",
      "loss: 0.02125162840820849\n",
      "epoch:1563 from 100000\n",
      "loss: 0.017075643874704838\n",
      "epoch:1564 from 100000\n",
      "loss: 0.019350607006344944\n",
      "epoch:1565 from 100000\n",
      "loss: 0.017108746891608462\n",
      "epoch:1566 from 100000\n",
      "loss: 0.018688329379074275\n",
      "epoch:1567 from 100000\n",
      "loss: 0.020639205176848918\n",
      "epoch:1568 from 100000\n",
      "loss: 0.01986535481410101\n",
      "epoch:1569 from 100000\n",
      "loss: 0.019508018216583878\n",
      "epoch:1570 from 100000\n",
      "loss: 0.018390242796158418\n",
      "epoch:1571 from 100000\n",
      "loss: 0.018985687929671258\n",
      "epoch:1572 from 100000\n",
      "loss: 0.016787541506346315\n",
      "epoch:1573 from 100000\n",
      "loss: 0.017543797759572044\n",
      "epoch:1574 from 100000\n",
      "loss: 0.019551891484297812\n",
      "epoch:1575 from 100000\n",
      "loss: 0.01822927634930238\n",
      "epoch:1576 from 100000\n",
      "loss: 0.0188815075380262\n",
      "epoch:1577 from 100000\n",
      "loss: 0.01926375977927819\n",
      "epoch:1578 from 100000\n",
      "loss: 0.020332530344603583\n",
      "epoch:1579 from 100000\n",
      "loss: 0.02063925057882443\n",
      "epoch:1580 from 100000\n",
      "loss: 0.021100781217683107\n",
      "epoch:1581 from 100000\n",
      "loss: 0.018325381563045084\n",
      "epoch:1582 from 100000\n",
      "loss: 0.01896337087964639\n",
      "epoch:1583 from 100000\n",
      "loss: 0.019157304894179106\n",
      "epoch:1584 from 100000\n",
      "loss: 0.021450872940476984\n",
      "epoch:1585 from 100000\n",
      "loss: 0.017703173158224672\n",
      "epoch:1586 from 100000\n",
      "loss: 0.017848817631602287\n",
      "epoch:1587 from 100000\n",
      "loss: 0.016915094573050737\n",
      "epoch:1588 from 100000\n",
      "loss: 0.01739118341356516\n",
      "epoch:1589 from 100000\n",
      "loss: 0.0179679281427525\n",
      "epoch:1590 from 100000\n",
      "loss: 0.022387482167687267\n",
      "epoch:1591 from 100000\n",
      "loss: 0.020018144510686398\n",
      "epoch:1592 from 100000\n",
      "loss: 0.01985455898102373\n",
      "epoch:1593 from 100000\n",
      "loss: 0.01888825133210048\n",
      "epoch:1594 from 100000\n",
      "loss: 0.01905735064065084\n",
      "epoch:1595 from 100000\n",
      "loss: 0.021343896514736116\n",
      "epoch:1596 from 100000\n",
      "loss: 0.016165031644050032\n",
      "epoch:1597 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9600.pt\n",
      "loss: 0.021324931120034307\n",
      "epoch:1598 from 100000\n",
      "loss: 0.020154589030425996\n",
      "epoch:1599 from 100000\n",
      "retrying for data\n",
      "loss: 0.018586729449452832\n",
      "epoch:1600 from 100000\n",
      "loss: 0.017325647233519703\n",
      "epoch:1601 from 100000\n",
      "loss: 0.022085847216658294\n",
      "epoch:1602 from 100000\n",
      "loss: 0.021038336388301104\n",
      "epoch:1603 from 100000\n",
      "loss: 0.01795228401897475\n",
      "epoch:1604 from 100000\n",
      "loss: 0.018608829530421644\n",
      "epoch:1605 from 100000\n",
      "loss: 0.018887142650783062\n",
      "epoch:1606 from 100000\n",
      "loss: 0.018771994742564857\n",
      "epoch:1607 from 100000\n",
      "loss: 0.01634517933416646\n",
      "epoch:1608 from 100000\n",
      "loss: 0.02041440230095759\n",
      "epoch:1609 from 100000\n",
      "loss: 0.019470571482088417\n",
      "epoch:1610 from 100000\n",
      "loss: 0.019452898297458887\n",
      "epoch:1611 from 100000\n",
      "loss: 0.02006812102627009\n",
      "epoch:1612 from 100000\n",
      "loss: 0.020241392718162388\n",
      "epoch:1613 from 100000\n",
      "loss: 0.018406467337626964\n",
      "epoch:1614 from 100000\n",
      "1245251loss: 0.020215585711412132\n",
      "epoch:1615 from 100000\n",
      "loss: 0.015967123268637806\n",
      "epoch:1616 from 100000\n",
      "loss: 0.017150646715890616\n",
      "epoch:1617 from 100000\n",
      "loss: 0.021327578055206686\n",
      "epoch:1618 from 100000\n",
      "loss: 0.0180448989267461\n",
      "epoch:1619 from 100000\n",
      "loss: 0.01940308656776324\n",
      "epoch:1620 from 100000\n",
      "loss: 0.019193237938452512\n",
      "epoch:1621 from 100000\n",
      "loss: 0.020701935165561736\n",
      "epoch:1622 from 100000\n",
      "loss: 0.019140700867865235\n",
      "epoch:1623 from 100000\n",
      "loss: 0.016700856998795643\n",
      "epoch:1624 from 100000\n",
      "loss: 0.01842620735988021\n",
      "epoch:1625 from 100000\n",
      "loss: 0.016802273283246905\n",
      "epoch:1626 from 100000\n",
      "loss: 0.018908324011135846\n",
      "epoch:1627 from 100000\n",
      "loss: 0.01876363530755043\n",
      "epoch:1628 from 100000\n",
      "loss: 0.017722182965371758\n",
      "epoch:1629 from 100000\n",
      "loss: 0.0191648414474912\n",
      "epoch:1630 from 100000\n",
      "loss: 0.018510775815229863\n",
      "epoch:1631 from 100000\n",
      "retrying for data\n",
      "loss: 0.020032240019645542\n",
      "epoch:1632 from 100000\n",
      "loss: 0.021124158753082156\n",
      "epoch:1633 from 100000\n",
      "loss: 0.020592155342455953\n",
      "epoch:1634 from 100000\n",
      "loss: 0.020023504010168836\n",
      "epoch:1635 from 100000\n",
      "loss: 0.021297518687788397\n",
      "epoch:1636 from 100000\n",
      "loss: 0.016604246222414076\n",
      "epoch:1637 from 100000\n",
      "loss: 0.018973321391968057\n",
      "epoch:1638 from 100000\n",
      "loss: 0.018012863816693425\n",
      "epoch:1639 from 100000\n",
      "loss: 0.018999604450073093\n",
      "epoch:1640 from 100000\n",
      "loss: 0.01829084410564974\n",
      "epoch:1641 from 100000\n",
      "loss: 0.017021542909787968\n",
      "epoch:1642 from 100000\n",
      "loss: 0.019606245157774538\n",
      "epoch:1643 from 100000\n",
      "loss: 0.020770856470335275\n",
      "epoch:1644 from 100000\n",
      "loss: 0.021443450823426247\n",
      "epoch:1645 from 100000\n",
      "loss: 0.020944263029377908\n",
      "epoch:1646 from 100000\n",
      "loss: 0.02123496276908554\n",
      "epoch:1647 from 100000\n",
      "loss: 0.01982506236527115\n",
      "epoch:1648 from 100000\n",
      "loss: 0.018276617454830557\n",
      "epoch:1649 from 100000\n",
      "loss: 0.018601214804220945\n",
      "epoch:1650 from 100000\n",
      "loss: 0.019711815228220075\n",
      "epoch:1651 from 100000\n",
      "loss: 0.02033263840712607\n",
      "epoch:1652 from 100000\n",
      "loss: 0.019610883435234427\n",
      "epoch:1653 from 100000\n",
      "loss: 0.01891495962627232\n",
      "epoch:1654 from 100000\n",
      "loss: 0.017836734594311565\n",
      "epoch:1655 from 100000\n",
      "loss: 0.020365651056636125\n",
      "epoch:1656 from 100000\n",
      "loss: 0.018469457980245352\n",
      "epoch:1657 from 100000\n",
      "loss: 0.019047012669034302\n",
      "epoch:1658 from 100000\n",
      "loss: 0.01885411946568638\n",
      "epoch:1659 from 100000\n",
      "loss: 0.017681920435279608\n",
      "epoch:1660 from 100000\n",
      "loss: 0.01951990759698674\n",
      "epoch:1661 from 100000\n",
      "loss: 0.018940054054837674\n",
      "epoch:1662 from 100000\n",
      "loss: 0.017455145076382905\n",
      "epoch:1663 from 100000\n",
      "loss: 0.016384960967116058\n",
      "epoch:1664 from 100000\n",
      "loss: 0.020528894499875605\n",
      "epoch:1665 from 100000\n",
      "loss: 0.021002196066547185\n",
      "epoch:1666 from 100000\n",
      "loss: 0.019094416464213282\n",
      "epoch:1667 from 100000\n",
      "loss: 0.019021867483388633\n",
      "epoch:1668 from 100000\n",
      "loss: 0.0186565428157337\n",
      "epoch:1669 from 100000\n",
      "loss: 0.02035206730943173\n",
      "epoch:1670 from 100000\n",
      "loss: 0.0198876287904568\n",
      "epoch:1671 from 100000\n",
      "loss: 0.01842442189808935\n",
      "epoch:1672 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9675.pt\n",
      "loss: 0.020043274969793856\n",
      "epoch:1673 from 100000\n",
      "loss: 0.01866805664030835\n",
      "epoch:1674 from 100000\n",
      "1255484loss: 0.0185399207402952\n",
      "epoch:1675 from 100000\n",
      "loss: 0.01925097784260288\n",
      "epoch:1676 from 100000\n",
      "loss: 0.018837021430954337\n",
      "epoch:1677 from 100000\n",
      "loss: 0.01809790206607431\n",
      "epoch:1678 from 100000\n",
      "loss: 0.01779967048787512\n",
      "epoch:1679 from 100000\n",
      "loss: 0.01922709430800751\n",
      "epoch:1680 from 100000\n",
      "loss: 0.019341300416272134\n",
      "epoch:1681 from 100000\n",
      "loss: 0.017678030882962048\n",
      "epoch:1682 from 100000\n",
      "loss: 0.019097666547168046\n",
      "epoch:1683 from 100000\n",
      "loss: 0.01855589385377243\n",
      "epoch:1684 from 100000\n",
      "loss: 0.017702347307931632\n",
      "epoch:1685 from 100000\n",
      "loss: 0.015316643402911723\n",
      "epoch:1686 from 100000\n",
      "loss: 0.018469449307303876\n",
      "epoch:1687 from 100000\n",
      "loss: 0.019574226927943528\n",
      "epoch:1688 from 100000\n",
      "loss: 0.020599315292201936\n",
      "epoch:1689 from 100000\n",
      "loss: 0.017874096636660397\n",
      "epoch:1690 from 100000\n",
      "loss: 0.020154088211711496\n",
      "epoch:1691 from 100000\n",
      "loss: 0.01791391836013645\n",
      "epoch:1692 from 100000\n",
      "loss: 0.020780458580702543\n",
      "epoch:1693 from 100000\n",
      "loss: 0.022630070336163044\n",
      "epoch:1694 from 100000\n",
      "loss: 0.019638586265500635\n",
      "epoch:1695 from 100000\n",
      "loss: 0.0206919745542109\n",
      "epoch:1696 from 100000\n",
      "loss: 0.018145731126423925\n",
      "epoch:1697 from 100000\n",
      "loss: 0.016963947418844327\n",
      "epoch:1698 from 100000\n",
      "loss: 0.0182772197003942\n",
      "epoch:1699 from 100000\n",
      "loss: 0.017797301756218076\n",
      "epoch:1700 from 100000\n",
      "loss: 0.019804889103397727\n",
      "epoch:1701 from 100000\n",
      "loss: 0.0213700876920484\n",
      "epoch:1702 from 100000\n",
      "loss: 0.017510306963231415\n",
      "epoch:1703 from 100000\n",
      "loss: 0.01986580592347309\n",
      "epoch:1704 from 100000\n",
      "loss: 0.017777125700376928\n",
      "epoch:1705 from 100000\n",
      "loss: 0.019226673466619104\n",
      "epoch:1706 from 100000\n",
      "loss: 0.020030308922287077\n",
      "epoch:1707 from 100000\n",
      "loss: 0.018788641085848212\n",
      "epoch:1708 from 100000\n",
      "loss: 0.020995816390495747\n",
      "epoch:1709 from 100000\n",
      "loss: 0.017815064260503277\n",
      "epoch:1710 from 100000\n",
      "loss: 0.017956494993995875\n",
      "epoch:1711 from 100000\n",
      "loss: 0.016174222284462303\n",
      "epoch:1712 from 100000\n",
      "loss: 0.018874285626225173\n",
      "epoch:1713 from 100000\n",
      "loss: 0.0174511851510033\n",
      "epoch:1714 from 100000\n",
      "loss: 0.015934461203869432\n",
      "epoch:1715 from 100000\n",
      "loss: 0.019714835449121892\n",
      "epoch:1716 from 100000\n",
      "loss: 0.01777072626282461\n",
      "epoch:1717 from 100000\n",
      "loss: 0.01691196084721014\n",
      "epoch:1718 from 100000\n",
      "loss: 0.020150429802015424\n",
      "epoch:1719 from 100000\n",
      "loss: 0.018139266525395215\n",
      "epoch:1720 from 100000\n",
      "loss: 0.018798974342644215\n",
      "epoch:1721 from 100000\n",
      "loss: 0.01851996115874499\n",
      "epoch:1722 from 100000\n",
      "loss: 0.021465684927534312\n",
      "epoch:1723 from 100000\n",
      "loss: 0.01871635572751984\n",
      "epoch:1724 from 100000\n",
      "loss: 0.018138237879611552\n",
      "epoch:1725 from 100000\n",
      "loss: 0.02036414173198864\n",
      "epoch:1726 from 100000\n",
      "loss: 0.01843502896372229\n",
      "epoch:1727 from 100000\n",
      "retrying for data\n",
      "loss: 0.020681608410086483\n",
      "epoch:1728 from 100000\n",
      "loss: 0.021172129025217146\n",
      "epoch:1729 from 100000\n",
      "loss: 0.019381152815185487\n",
      "epoch:1730 from 100000\n",
      "loss: 0.018857351853512228\n",
      "epoch:1731 from 100000\n",
      "loss: 0.020033817796502262\n",
      "epoch:1732 from 100000\n",
      "loss: 0.020333605294581503\n",
      "epoch:1733 from 100000\n",
      "loss: 0.018372158927377313\n",
      "epoch:1734 from 100000\n",
      "loss: 0.02039323397912085\n",
      "epoch:1735 from 100000\n",
      "loss: 0.018997982726432383\n",
      "epoch:1736 from 100000\n",
      "loss: 0.019659575424157083\n",
      "epoch:1737 from 100000\n",
      "loss: 0.019682139449287206\n",
      "epoch:1738 from 100000\n",
      "loss: 0.01580648816889152\n",
      "epoch:1739 from 100000\n",
      "loss: 0.01839059655321762\n",
      "epoch:1740 from 100000\n",
      "loss: 0.021177530812565237\n",
      "epoch:1741 from 100000\n",
      "loss: 0.019834257662296295\n",
      "epoch:1742 from 100000\n",
      "loss: 0.02076513390056789\n",
      "epoch:1743 from 100000\n",
      "loss: 0.01882021623896435\n",
      "epoch:1744 from 100000\n",
      "loss: 0.01853960333392024\n",
      "epoch:1745 from 100000\n",
      "loss: 0.021462459466420114\n",
      "epoch:1746 from 100000\n",
      "loss: 0.02021068800240755\n",
      "epoch:1747 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9750.pt\n",
      "loss: 0.018852019391488284\n",
      "epoch:1748 from 100000\n",
      "loss: 0.018430989235639572\n",
      "epoch:1749 from 100000\n",
      "loss: 0.019799791916739196\n",
      "epoch:1750 from 100000\n",
      "loss: 0.018920320842880756\n",
      "epoch:1751 from 100000\n",
      "loss: 0.020801702281460166\n",
      "epoch:1752 from 100000\n",
      "loss: 0.019370617577806115\n",
      "epoch:1753 from 100000\n",
      "loss: 0.02063938626088202\n",
      "epoch:1754 from 100000\n",
      "1268270loss: 0.01930929289665073\n",
      "epoch:1755 from 100000\n",
      "loss: 0.016780457663116977\n",
      "epoch:1756 from 100000\n",
      "loss: 0.018785884778480977\n",
      "epoch:1757 from 100000\n",
      "loss: 0.020017703500343487\n",
      "epoch:1758 from 100000\n",
      "loss: 0.021527936798520386\n",
      "epoch:1759 from 100000\n",
      "loss: 0.01935306639643386\n",
      "epoch:1760 from 100000\n",
      "loss: 0.017312268842943013\n",
      "epoch:1761 from 100000\n",
      "loss: 0.020564195176120847\n",
      "epoch:1762 from 100000\n",
      "loss: 0.018360965535975993\n",
      "epoch:1763 from 100000\n",
      "loss: 0.020835217961575836\n",
      "epoch:1764 from 100000\n",
      "loss: 0.01875194173771888\n",
      "epoch:1765 from 100000\n",
      "loss: 0.020519012643489987\n",
      "epoch:1766 from 100000\n",
      "loss: 0.01900927280075848\n",
      "epoch:1767 from 100000\n",
      "loss: 0.01953011442674324\n",
      "epoch:1768 from 100000\n",
      "loss: 0.01850586023647338\n",
      "epoch:1769 from 100000\n",
      "loss: 0.018286621576407924\n",
      "epoch:1770 from 100000\n",
      "loss: 0.017177183617604896\n",
      "epoch:1771 from 100000\n",
      "loss: 0.018816101015545428\n",
      "epoch:1772 from 100000\n",
      "loss: 0.017845718073658645\n",
      "epoch:1773 from 100000\n",
      "loss: 0.01993803435470909\n",
      "epoch:1774 from 100000\n",
      "loss: 0.01929622475290671\n",
      "epoch:1775 from 100000\n",
      "loss: 0.02026142179965973\n",
      "epoch:1776 from 100000\n",
      "loss: 0.019212464394513518\n",
      "epoch:1777 from 100000\n",
      "loss: 0.015466194308828562\n",
      "epoch:1778 from 100000\n",
      "loss: 0.0191905302926898\n",
      "epoch:1779 from 100000\n",
      "loss: 0.01655817119171843\n",
      "epoch:1780 from 100000\n",
      "loss: 0.018551180517533794\n",
      "epoch:1781 from 100000\n",
      "loss: 0.017954872630070895\n",
      "epoch:1782 from 100000\n",
      "loss: 0.018742629035841674\n",
      "epoch:1783 from 100000\n",
      "loss: 0.019304865098092705\n",
      "epoch:1784 from 100000\n",
      "loss: 0.018227604101412\n",
      "epoch:1785 from 100000\n",
      "loss: 0.02115131140453741\n",
      "epoch:1786 from 100000\n",
      "loss: 0.01764706027461216\n",
      "epoch:1787 from 100000\n",
      "loss: 0.01939564204076305\n",
      "epoch:1788 from 100000\n",
      "loss: 0.019920892198570073\n",
      "epoch:1789 from 100000\n",
      "loss: 0.02043635305017233\n",
      "epoch:1790 from 100000\n",
      "loss: 0.017960057011805475\n",
      "epoch:1791 from 100000\n",
      "loss: 0.01872738922247663\n",
      "epoch:1792 from 100000\n",
      "loss: 0.01749080716399476\n",
      "epoch:1793 from 100000\n",
      "loss: 0.019245135772507638\n",
      "epoch:1794 from 100000\n",
      "loss: 0.017505204887129366\n",
      "epoch:1795 from 100000\n",
      "loss: 0.018881754076573998\n",
      "epoch:1796 from 100000\n",
      "loss: 0.018231734167784452\n",
      "epoch:1797 from 100000\n",
      "loss: 0.020734642865136266\n",
      "epoch:1798 from 100000\n",
      "loss: 0.01829278125660494\n",
      "epoch:1799 from 100000\n",
      "loss: 0.019449634535703808\n",
      "epoch:1800 from 100000\n",
      "loss: 0.019844115187879652\n",
      "epoch:1801 from 100000\n",
      "loss: 0.020635333377867937\n",
      "epoch:1802 from 100000\n",
      "loss: 0.018019786337390542\n",
      "epoch:1803 from 100000\n",
      "loss: 0.01835746061988175\n",
      "epoch:1804 from 100000\n",
      "loss: 0.021571595629211515\n",
      "epoch:1805 from 100000\n",
      "loss: 0.017667488718871027\n",
      "epoch:1806 from 100000\n",
      "loss: 0.019170105399098247\n",
      "epoch:1807 from 100000\n",
      "loss: 0.01902297924971208\n",
      "epoch:1808 from 100000\n",
      "loss: 0.017939089389983565\n",
      "epoch:1809 from 100000\n",
      "loss: 0.01980633829953149\n",
      "epoch:1810 from 100000\n",
      "loss: 0.019396277843043208\n",
      "epoch:1811 from 100000\n",
      "loss: 0.018406025104923174\n",
      "epoch:1812 from 100000\n",
      "loss: 0.02139581204392016\n",
      "epoch:1813 from 100000\n",
      "loss: 0.020773283613380045\n",
      "epoch:1814 from 100000\n",
      "loss: 0.01767280968488194\n",
      "epoch:1815 from 100000\n",
      "loss: 0.021026224363595247\n",
      "epoch:1816 from 100000\n",
      "loss: 0.01934863848146051\n",
      "epoch:1817 from 100000\n",
      "loss: 0.01957009080797434\n",
      "epoch:1818 from 100000\n",
      "loss: 0.01779771427391097\n",
      "epoch:1819 from 100000\n",
      "loss: 0.01761915668612346\n",
      "epoch:1820 from 100000\n",
      "loss: 0.017645246611209586\n",
      "epoch:1821 from 100000\n",
      "loss: 0.018731131742242724\n",
      "epoch:1822 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9825.pt\n",
      "loss: 0.015460091934073716\n",
      "epoch:1823 from 100000\n",
      "loss: 0.0178226480493322\n",
      "epoch:1824 from 100000\n",
      "loss: 0.01818360754987225\n",
      "epoch:1825 from 100000\n",
      "loss: 0.021077739424072206\n",
      "epoch:1826 from 100000\n",
      "loss: 0.021868843818083405\n",
      "epoch:1827 from 100000\n",
      "loss: 0.021365395456086844\n",
      "epoch:1828 from 100000\n",
      "loss: 0.01995283953147009\n",
      "epoch:1829 from 100000\n",
      "loss: 0.020161770458798856\n",
      "epoch:1830 from 100000\n",
      "loss: 0.018603355041705072\n",
      "epoch:1831 from 100000\n",
      "loss: 0.020923173520714045\n",
      "epoch:1832 from 100000\n",
      "loss: 0.018531624227762222\n",
      "epoch:1833 from 100000\n",
      "loss: 0.01888134324690327\n",
      "epoch:1834 from 100000\n",
      "loss: 0.018504685256630182\n",
      "epoch:1835 from 100000\n",
      "loss: 0.017545298556797206\n",
      "epoch:1836 from 100000\n",
      "loss: 0.018680568027775735\n",
      "epoch:1837 from 100000\n",
      "loss: 0.021003829722758383\n",
      "epoch:1838 from 100000\n",
      "loss: 0.01904861006187275\n",
      "epoch:1839 from 100000\n",
      "loss: 0.01867582873092033\n",
      "epoch:1840 from 100000\n",
      "loss: 0.01938265428179875\n",
      "epoch:1841 from 100000\n",
      "loss: 0.01679117581807077\n",
      "epoch:1842 from 100000\n",
      "loss: 0.016403446294134483\n",
      "epoch:1843 from 100000\n",
      "loss: 0.017551714467117563\n",
      "epoch:1844 from 100000\n",
      "loss: 0.018692316341912374\n",
      "epoch:1845 from 100000\n",
      "loss: 0.019199081580154598\n",
      "epoch:1846 from 100000\n",
      "loss: 0.02107120893197134\n",
      "epoch:1847 from 100000\n",
      "loss: 0.016277972026728094\n",
      "epoch:1848 from 100000\n",
      "loss: 0.020110778452362865\n",
      "epoch:1849 from 100000\n",
      "loss: 0.01777500577736646\n",
      "epoch:1850 from 100000\n",
      "loss: 0.018702699046116322\n",
      "epoch:1851 from 100000\n",
      "loss: 0.019654478004667908\n",
      "epoch:1852 from 100000\n",
      "loss: 0.021763251745142043\n",
      "epoch:1853 from 100000\n",
      "loss: 0.020864841353613883\n",
      "epoch:1854 from 100000\n",
      "loss: 0.019208282174076885\n",
      "epoch:1855 from 100000\n",
      "retrying for data\n",
      "loss: 0.018441700551193208\n",
      "epoch:1856 from 100000\n",
      "loss: 0.019140965247061104\n",
      "epoch:1857 from 100000\n",
      "loss: 0.019822811183985323\n",
      "epoch:1858 from 100000\n",
      "loss: 0.01795353216584772\n",
      "epoch:1859 from 100000\n",
      "loss: 0.018461489235050976\n",
      "epoch:1860 from 100000\n",
      "loss: 0.018992232042364776\n",
      "epoch:1861 from 100000\n",
      "loss: 0.021090795227792114\n",
      "epoch:1862 from 100000\n",
      "loss: 0.018542112782597542\n",
      "epoch:1863 from 100000\n",
      "loss: 0.01722180360229686\n",
      "epoch:1864 from 100000\n",
      "loss: 0.02010133268777281\n",
      "epoch:1865 from 100000\n",
      "loss: 0.01989507384132594\n",
      "epoch:1866 from 100000\n",
      "loss: 0.02086972602410242\n",
      "epoch:1867 from 100000\n",
      "loss: 0.01914104982279241\n",
      "epoch:1868 from 100000\n",
      "loss: 0.0174386115395464\n",
      "epoch:1869 from 100000\n",
      "loss: 0.019602078245952725\n",
      "epoch:1870 from 100000\n",
      "loss: 0.018119358108378947\n",
      "epoch:1871 from 100000\n",
      "loss: 0.020925826160237193\n",
      "epoch:1872 from 100000\n",
      "loss: 0.018430932541377842\n",
      "epoch:1873 from 100000\n",
      "loss: 0.01751216931734234\n",
      "epoch:1874 from 100000\n",
      "loss: 0.018781742954161018\n",
      "epoch:1875 from 100000\n",
      "loss: 0.01979536993894726\n",
      "epoch:1876 from 100000\n",
      "loss: 0.018854358524549752\n",
      "epoch:1877 from 100000\n",
      "loss: 0.019956401141826063\n",
      "epoch:1878 from 100000\n",
      "loss: 0.018292168388143182\n",
      "epoch:1879 from 100000\n",
      "loss: 0.02004601518274285\n",
      "epoch:1880 from 100000\n",
      "loss: 0.01875357102835551\n",
      "epoch:1881 from 100000\n",
      "loss: 0.017709437001030892\n",
      "epoch:1882 from 100000\n",
      "loss: 0.019722540251677856\n",
      "epoch:1883 from 100000\n",
      "loss: 0.019015877915080637\n",
      "epoch:1884 from 100000\n",
      "loss: 0.018776885408442467\n",
      "epoch:1885 from 100000\n",
      "loss: 0.017979016760364175\n",
      "epoch:1886 from 100000\n",
      "loss: 0.01829002477461472\n",
      "epoch:1887 from 100000\n",
      "loss: 0.021747962338849902\n",
      "epoch:1888 from 100000\n",
      "loss: 0.018211650021839887\n",
      "epoch:1889 from 100000\n",
      "loss: 0.018268010637257248\n",
      "epoch:1890 from 100000\n",
      "loss: 0.018417753861285746\n",
      "epoch:1891 from 100000\n",
      "loss: 0.019168261467712\n",
      "epoch:1892 from 100000\n",
      "loss: 0.02086963056353852\n",
      "epoch:1893 from 100000\n",
      "loss: 0.019328524474985898\n",
      "epoch:1894 from 100000\n",
      "loss: 0.022898952767718583\n",
      "epoch:1895 from 100000\n",
      "loss: 0.01828684232896194\n",
      "epoch:1896 from 100000\n",
      "loss: 0.01800999796250835\n",
      "epoch:1897 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9900.pt\n",
      "loss: 0.01732031482970342\n",
      "epoch:1898 from 100000\n",
      "loss: 0.020451157703064382\n",
      "epoch:1899 from 100000\n",
      "loss: 0.021184648328926414\n",
      "epoch:1900 from 100000\n",
      "loss: 0.021237040346022695\n",
      "epoch:1901 from 100000\n",
      "loss: 0.018211902061011642\n",
      "epoch:1902 from 100000\n",
      "loss: 0.020555411465466022\n",
      "epoch:1903 from 100000\n",
      "loss: 0.01857681045657955\n",
      "epoch:1904 from 100000\n",
      "loss: 0.020859489974100143\n",
      "epoch:1905 from 100000\n",
      "loss: 0.019340812868904322\n",
      "epoch:1906 from 100000\n",
      "loss: 0.0179769818787463\n",
      "epoch:1907 from 100000\n",
      "loss: 0.019356267934199423\n",
      "epoch:1908 from 100000\n",
      "loss: 0.02283618610817939\n",
      "epoch:1909 from 100000\n",
      "loss: 0.0163097879558336\n",
      "epoch:1910 from 100000\n",
      "loss: 0.017956951865926385\n",
      "epoch:1911 from 100000\n",
      "loss: 0.017923536419402808\n",
      "epoch:1912 from 100000\n",
      "loss: 0.01877054217038676\n",
      "epoch:1913 from 100000\n",
      "loss: 0.017419423500541598\n",
      "epoch:1914 from 100000\n",
      "loss: 0.01801598776364699\n",
      "epoch:1915 from 100000\n",
      "loss: 0.02040151704568416\n",
      "epoch:1916 from 100000\n",
      "loss: 0.016882256255485117\n",
      "epoch:1917 from 100000\n",
      "loss: 0.017867416667286307\n",
      "epoch:1918 from 100000\n",
      "loss: 0.017317728779744357\n",
      "epoch:1919 from 100000\n",
      "loss: 0.017588422051630914\n",
      "epoch:1920 from 100000\n",
      "loss: 0.019513253879267722\n",
      "epoch:1921 from 100000\n",
      "loss: 0.018424877198413014\n",
      "epoch:1922 from 100000\n",
      "loss: 0.016913972212933004\n",
      "epoch:1923 from 100000\n",
      "loss: 0.018979885411681607\n",
      "epoch:1924 from 100000\n",
      "loss: 0.019394178525544703\n",
      "epoch:1925 from 100000\n",
      "loss: 0.020650558231864125\n",
      "epoch:1926 from 100000\n",
      "loss: 0.019363029452506453\n",
      "epoch:1927 from 100000\n",
      "loss: 0.018910210812464356\n",
      "epoch:1928 from 100000\n",
      "loss: 0.0182556850486435\n",
      "epoch:1929 from 100000\n",
      "loss: 0.01782442379044369\n",
      "epoch:1930 from 100000\n",
      "loss: 0.020247221982572228\n",
      "epoch:1931 from 100000\n",
      "loss: 0.021681413636542857\n",
      "epoch:1932 from 100000\n",
      "loss: 0.019305240333778784\n",
      "epoch:1933 from 100000\n",
      "loss: 0.020644917094614357\n",
      "epoch:1934 from 100000\n",
      "loss: 0.01780167140532285\n",
      "epoch:1935 from 100000\n",
      "loss: 0.01954532990930602\n",
      "epoch:1936 from 100000\n",
      "loss: 0.019985603517852724\n",
      "epoch:1937 from 100000\n",
      "loss: 0.01939837512327358\n",
      "epoch:1938 from 100000\n",
      "loss: 0.019603082444518805\n",
      "epoch:1939 from 100000\n",
      "loss: 0.01936859975103289\n",
      "epoch:1940 from 100000\n",
      "loss: 0.01790963060921058\n",
      "epoch:1941 from 100000\n",
      "loss: 0.018265595834236592\n",
      "epoch:1942 from 100000\n",
      "loss: 0.018365588679444045\n",
      "epoch:1943 from 100000\n",
      "loss: 0.01956707250792533\n",
      "epoch:1944 from 100000\n",
      "loss: 0.020577296963892877\n",
      "epoch:1945 from 100000\n",
      "loss: 0.019962743506766856\n",
      "epoch:1946 from 100000\n",
      "loss: 0.01889781409408897\n",
      "epoch:1947 from 100000\n",
      "loss: 0.02062010468216613\n",
      "epoch:1948 from 100000\n",
      "loss: 0.017446650366764516\n",
      "epoch:1949 from 100000\n",
      "loss: 0.016387729323469102\n",
      "epoch:1950 from 100000\n",
      "loss: 0.01937171194003895\n",
      "epoch:1951 from 100000\n",
      "loss: 0.020049538230523467\n",
      "epoch:1952 from 100000\n",
      "loss: 0.02042780793271959\n",
      "epoch:1953 from 100000\n",
      "loss: 0.019160435418598354\n",
      "epoch:1954 from 100000\n",
      "loss: 0.01854848541552201\n",
      "epoch:1955 from 100000\n",
      "loss: 0.017570590774994344\n",
      "epoch:1956 from 100000\n",
      "loss: 0.021775773318950087\n",
      "epoch:1957 from 100000\n",
      "loss: 0.0203751579974778\n",
      "epoch:1958 from 100000\n",
      "loss: 0.017866597627289593\n",
      "epoch:1959 from 100000\n",
      "loss: 0.018278251867741346\n",
      "epoch:1960 from 100000\n",
      "loss: 0.01869457500288263\n",
      "epoch:1961 from 100000\n",
      "loss: 0.019438616058323532\n",
      "epoch:1962 from 100000\n",
      "loss: 0.01917432772461325\n",
      "epoch:1963 from 100000\n",
      "loss: 0.0189178257714957\n",
      "epoch:1964 from 100000\n",
      "loss: 0.019672776688821614\n",
      "epoch:1965 from 100000\n",
      "loss: 0.019407277344726026\n",
      "epoch:1966 from 100000\n",
      "loss: 0.019597690494265407\n",
      "epoch:1967 from 100000\n",
      "loss: 0.018362370727118105\n",
      "epoch:1968 from 100000\n",
      "loss: 0.019631414441391826\n",
      "epoch:1969 from 100000\n",
      "loss: 0.019388947228435427\n",
      "epoch:1970 from 100000\n",
      "loss: 0.01974753028480336\n",
      "epoch:1971 from 100000\n",
      "loss: 0.019075388205237687\n",
      "epoch:1972 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.9975.pt\n",
      "loss: 0.019296574406325817\n",
      "epoch:1973 from 100000\n",
      "loss: 0.01939451869111508\n",
      "epoch:1974 from 100000\n",
      "loss: 0.01809986273292452\n",
      "epoch:1975 from 100000\n",
      "loss: 0.01890334812924266\n",
      "epoch:1976 from 100000\n",
      "loss: 0.01851251639891416\n",
      "epoch:1977 from 100000\n",
      "loss: 0.020698911044746637\n",
      "epoch:1978 from 100000\n",
      "loss: 0.01892582286382094\n",
      "epoch:1979 from 100000\n",
      "loss: 0.019126436149235815\n",
      "epoch:1980 from 100000\n",
      "loss: 0.017730587802361697\n",
      "epoch:1981 from 100000\n",
      "loss: 0.019460068782791495\n",
      "epoch:1982 from 100000\n",
      "loss: 0.019412233552429825\n",
      "epoch:1983 from 100000\n",
      "loss: 0.016972691286355257\n",
      "epoch:1984 from 100000\n",
      "loss: 0.021912003780016676\n",
      "epoch:1985 from 100000\n",
      "loss: 0.018707247159909457\n",
      "epoch:1986 from 100000\n",
      "loss: 0.01885449601104483\n",
      "epoch:1987 from 100000\n",
      "loss: 0.018630619742907584\n",
      "epoch:1988 from 100000\n",
      "loss: 0.018807542277500033\n",
      "epoch:1989 from 100000\n",
      "loss: 0.017404005920980126\n",
      "epoch:1990 from 100000\n",
      "loss: 0.020987275638617575\n",
      "epoch:1991 from 100000\n",
      "loss: 0.01859390124445781\n",
      "epoch:1992 from 100000\n",
      "loss: 0.019021572545170784\n",
      "epoch:1993 from 100000\n",
      "loss: 0.01793214277131483\n",
      "epoch:1994 from 100000\n",
      "loss: 0.02019245200790465\n",
      "epoch:1995 from 100000\n",
      "loss: 0.020544069178868085\n",
      "epoch:1996 from 100000\n",
      "loss: 0.01788216852582991\n",
      "epoch:1997 from 100000\n",
      "loss: 0.020345296943560243\n",
      "epoch:1998 from 100000\n",
      "loss: 0.01969019605894573\n",
      "epoch:1999 from 100000\n",
      "loss: 0.019212271610740572\n",
      "epoch:2000 from 100000\n",
      "loss: 0.019310000527184457\n",
      "epoch:2001 from 100000\n",
      "loss: 0.018937839020509273\n",
      "epoch:2002 from 100000\n",
      "loss: 0.01997460430720821\n",
      "epoch:2003 from 100000\n",
      "loss: 0.01710288881440647\n",
      "epoch:2004 from 100000\n",
      "loss: 0.020213320443872362\n",
      "epoch:2005 from 100000\n",
      "loss: 0.02017498094937764\n",
      "epoch:2006 from 100000\n",
      "loss: 0.022302227560430765\n",
      "epoch:2007 from 100000\n",
      "loss: 0.017726457212120295\n",
      "epoch:2008 from 100000\n",
      "loss: 0.01918636617483571\n",
      "epoch:2009 from 100000\n",
      "loss: 0.019294756930321455\n",
      "epoch:2010 from 100000\n",
      "loss: 0.016626533877570182\n",
      "epoch:2011 from 100000\n",
      "loss: 0.020605026016710326\n",
      "epoch:2012 from 100000\n",
      "loss: 0.019446016987785697\n",
      "epoch:2013 from 100000\n",
      "loss: 0.019154569832608104\n",
      "epoch:2014 from 100000\n",
      "loss: 0.016168165137059987\n",
      "epoch:2015 from 100000\n",
      "loss: 0.0192992782976944\n",
      "epoch:2016 from 100000\n",
      "loss: 0.01848947280086577\n",
      "epoch:2017 from 100000\n",
      "loss: 0.016939485620241612\n",
      "epoch:2018 from 100000\n",
      "loss: 0.020700409542769194\n",
      "epoch:2019 from 100000\n",
      "loss: 0.019634930358733982\n",
      "epoch:2020 from 100000\n",
      "loss: 0.017911880364408717\n",
      "epoch:2021 from 100000\n",
      "loss: 0.019772691157413647\n",
      "epoch:2022 from 100000\n",
      "loss: 0.018897654954344034\n",
      "epoch:2023 from 100000\n",
      "loss: 0.018279484182130545\n",
      "epoch:2024 from 100000\n",
      "loss: 0.019330065057147294\n",
      "epoch:2025 from 100000\n",
      "loss: 0.02024080528644845\n",
      "epoch:2026 from 100000\n",
      "loss: 0.020545157603919506\n",
      "epoch:2027 from 100000\n",
      "loss: 0.02033689059317112\n",
      "epoch:2028 from 100000\n",
      "loss: 0.019404880062211305\n",
      "epoch:2029 from 100000\n",
      "loss: 0.016957352170720696\n",
      "epoch:2030 from 100000\n",
      "loss: 0.01671316201100126\n",
      "epoch:2031 from 100000\n",
      "loss: 0.019191200786735862\n",
      "epoch:2032 from 100000\n",
      "loss: 0.01774385740282014\n",
      "epoch:2033 from 100000\n",
      "loss: 0.016883509466424584\n",
      "epoch:2034 from 100000\n",
      "loss: 0.01850692502921447\n",
      "epoch:2035 from 100000\n",
      "loss: 0.019613041542470455\n",
      "epoch:2036 from 100000\n",
      "loss: 0.018016793532297015\n",
      "epoch:2037 from 100000\n",
      "loss: 0.019917495228582993\n",
      "epoch:2038 from 100000\n",
      "loss: 0.018386343668680638\n",
      "epoch:2039 from 100000\n",
      "loss: 0.018975874001625925\n",
      "epoch:2040 from 100000\n",
      "loss: 0.017724911333061755\n",
      "epoch:2041 from 100000\n",
      "loss: 0.020325477118603885\n",
      "epoch:2042 from 100000\n",
      "loss: 0.019311335578095168\n",
      "epoch:2043 from 100000\n",
      "loss: 0.020716481667477638\n",
      "epoch:2044 from 100000\n",
      "loss: 0.018207770539447665\n",
      "epoch:2045 from 100000\n",
      "loss: 0.019392904418054968\n",
      "epoch:2046 from 100000\n",
      "loss: 0.019662509090267122\n",
      "epoch:2047 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.10050.pt\n",
      "loss: 0.01886403647949919\n",
      "epoch:2048 from 100000\n",
      "loss: 0.018684002105146646\n",
      "epoch:2049 from 100000\n",
      "loss: 0.019106234540231526\n",
      "epoch:2050 from 100000\n",
      "loss: 0.017563863191753626\n",
      "epoch:2051 from 100000\n",
      "loss: 0.01976941537577659\n",
      "epoch:2052 from 100000\n",
      "loss: 0.018311380699742585\n",
      "epoch:2053 from 100000\n",
      "loss: 0.01875471038511023\n",
      "epoch:2054 from 100000\n",
      "loss: 0.01915137213654816\n",
      "epoch:2055 from 100000\n",
      "loss: 0.018501098558772355\n",
      "epoch:2056 from 100000\n",
      "loss: 0.019290010153781623\n",
      "epoch:2057 from 100000\n",
      "loss: 0.02081957127666101\n",
      "epoch:2058 from 100000\n",
      "loss: 0.020145176502410322\n",
      "epoch:2059 from 100000\n",
      "loss: 0.018267377570737153\n",
      "epoch:2060 from 100000\n",
      "loss: 0.018202430743258446\n",
      "epoch:2061 from 100000\n",
      "loss: 0.018239684810396284\n",
      "epoch:2062 from 100000\n",
      "loss: 0.01903123373631388\n",
      "epoch:2063 from 100000\n",
      "loss: 0.01711502083344385\n",
      "epoch:2064 from 100000\n",
      "loss: 0.01972594251856208\n",
      "epoch:2065 from 100000\n",
      "loss: 0.02020113807520829\n",
      "epoch:2066 from 100000\n",
      "loss: 0.01895829802379012\n",
      "epoch:2067 from 100000\n",
      "loss: 0.01757473696488887\n",
      "epoch:2068 from 100000\n",
      "loss: 0.017404301557689905\n",
      "epoch:2069 from 100000\n",
      "loss: 0.017054786381777376\n",
      "epoch:2070 from 100000\n",
      "loss: 0.019039290607906878\n",
      "epoch:2071 from 100000\n",
      "loss: 0.02033447928261012\n",
      "epoch:2072 from 100000\n",
      "loss: 0.018038766167592257\n",
      "epoch:2073 from 100000\n",
      "loss: 0.01938727276865393\n",
      "epoch:2074 from 100000\n",
      "loss: 0.020965328789316118\n",
      "epoch:2075 from 100000\n",
      "loss: 0.01848949957638979\n",
      "epoch:2076 from 100000\n",
      "loss: 0.020546838000882417\n",
      "epoch:2077 from 100000\n",
      "loss: 0.021182956756092608\n",
      "epoch:2078 from 100000\n",
      "loss: 0.017003313318127766\n",
      "epoch:2079 from 100000\n",
      "loss: 0.01878693187609315\n",
      "epoch:2080 from 100000\n",
      "loss: 0.017755866691004485\n",
      "epoch:2081 from 100000\n",
      "loss: 0.019552407145965844\n",
      "epoch:2082 from 100000\n",
      "loss: 0.020081971772015095\n",
      "epoch:2083 from 100000\n",
      "loss: 0.01804881906718947\n",
      "epoch:2084 from 100000\n",
      "loss: 0.016215380368521437\n",
      "epoch:2085 from 100000\n",
      "loss: 0.0198753367876634\n",
      "epoch:2086 from 100000\n",
      "loss: 0.019864631292875856\n",
      "epoch:2087 from 100000\n",
      "loss: 0.016543779813218862\n",
      "epoch:2088 from 100000\n",
      "loss: 0.017795312451198697\n",
      "epoch:2089 from 100000\n",
      "loss: 0.018277220951858908\n",
      "epoch:2090 from 100000\n",
      "loss: 0.019319775921758264\n",
      "epoch:2091 from 100000\n",
      "loss: 0.01888108204002492\n",
      "epoch:2092 from 100000\n",
      "loss: 0.0208801387634594\n",
      "epoch:2093 from 100000\n",
      "loss: 0.01817446091445163\n",
      "epoch:2094 from 100000\n",
      "loss: 0.021108899789396673\n",
      "epoch:2095 from 100000\n",
      "retrying for data\n",
      "retrying for data\n",
      "loss: 0.019915974291507155\n",
      "epoch:2096 from 100000\n",
      "loss: 0.018496451317332685\n",
      "epoch:2097 from 100000\n",
      "loss: 0.019364839245099574\n",
      "epoch:2098 from 100000\n",
      "loss: 0.01928130170563236\n",
      "epoch:2099 from 100000\n",
      "loss: 0.017822884023189545\n",
      "epoch:2100 from 100000\n",
      "loss: 0.018733574368525296\n",
      "epoch:2101 from 100000\n",
      "loss: 0.01834960945416242\n",
      "epoch:2102 from 100000\n",
      "loss: 0.01667314549558796\n",
      "epoch:2103 from 100000\n",
      "loss: 0.016346755321137607\n",
      "epoch:2104 from 100000\n",
      "loss: 0.019901953171938658\n",
      "epoch:2105 from 100000\n",
      "loss: 0.01831553300144151\n",
      "epoch:2106 from 100000\n",
      "loss: 0.01929919607937336\n",
      "epoch:2107 from 100000\n",
      "loss: 0.020675318082794547\n",
      "epoch:2108 from 100000\n",
      "loss: 0.019817276275716722\n",
      "epoch:2109 from 100000\n",
      "loss: 0.020351774583104998\n",
      "epoch:2110 from 100000\n",
      "loss: 0.018588349514175206\n",
      "epoch:2111 from 100000\n",
      "loss: 0.016067253542132676\n",
      "epoch:2112 from 100000\n",
      "loss: 0.021479763876413926\n",
      "epoch:2113 from 100000\n",
      "loss: 0.019131077511701733\n",
      "epoch:2114 from 100000\n",
      "loss: 0.018784638377837837\n",
      "epoch:2115 from 100000\n",
      "loss: 0.019372387032490224\n",
      "epoch:2116 from 100000\n",
      "loss: 0.017968443979043514\n",
      "epoch:2117 from 100000\n",
      "loss: 0.0210188576602377\n",
      "epoch:2118 from 100000\n",
      "loss: 0.021531730075366795\n",
      "epoch:2119 from 100000\n",
      "loss: 0.018639706075191498\n",
      "epoch:2120 from 100000\n",
      "loss: 0.021125744504388422\n",
      "epoch:2121 from 100000\n",
      "loss: 0.018150959454942495\n",
      "epoch:2122 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.10125.pt\n",
      "loss: 0.017613339936360717\n",
      "epoch:2123 from 100000\n",
      "loss: 0.022133496939204633\n",
      "epoch:2124 from 100000\n",
      "loss: 0.018027639103820547\n",
      "epoch:2125 from 100000\n",
      "loss: 0.017082271398976445\n",
      "epoch:2126 from 100000\n",
      "loss: 0.018060410191537812\n",
      "epoch:2127 from 100000\n",
      "retrying for data\n",
      "loss: 0.01590032287640497\n",
      "epoch:2128 from 100000\n",
      "loss: 0.019087112334091216\n",
      "epoch:2129 from 100000\n",
      "loss: 0.018206102453405038\n",
      "epoch:2130 from 100000\n",
      "loss: 0.017547272553201765\n",
      "epoch:2131 from 100000\n",
      "loss: 0.018655811727512628\n",
      "epoch:2132 from 100000\n",
      "loss: 0.02027878537774086\n",
      "epoch:2133 from 100000\n",
      "loss: 0.018856055045034736\n",
      "epoch:2134 from 100000\n",
      "loss: 0.01965338026639074\n",
      "epoch:2135 from 100000\n",
      "loss: 0.02013161324430257\n",
      "epoch:2136 from 100000\n",
      "loss: 0.0218522772192955\n",
      "epoch:2137 from 100000\n",
      "loss: 0.018912230851128697\n",
      "epoch:2138 from 100000\n",
      "loss: 0.019626224064268172\n",
      "epoch:2139 from 100000\n",
      "loss: 0.01977385627105832\n",
      "epoch:2140 from 100000\n",
      "loss: 0.019512239028699696\n",
      "epoch:2141 from 100000\n",
      "loss: 0.01927587407408282\n",
      "epoch:2142 from 100000\n",
      "loss: 0.017766596050933003\n",
      "epoch:2143 from 100000\n",
      "loss: 0.017255406943149865\n",
      "epoch:2144 from 100000\n",
      "loss: 0.02176660840632394\n",
      "epoch:2145 from 100000\n",
      "loss: 0.019792389182839543\n",
      "epoch:2146 from 100000\n",
      "loss: 0.018633450526976958\n",
      "epoch:2147 from 100000\n",
      "loss: 0.01926943176658824\n",
      "epoch:2148 from 100000\n",
      "loss: 0.021435295755509287\n",
      "epoch:2149 from 100000\n",
      "loss: 0.01827413192950189\n",
      "epoch:2150 from 100000\n",
      "loss: 0.01964782300638035\n",
      "epoch:2151 from 100000\n",
      "loss: 0.020758227445185184\n",
      "epoch:2152 from 100000\n",
      "loss: 0.017046646680682898\n",
      "epoch:2153 from 100000\n",
      "loss: 0.02100133488420397\n",
      "epoch:2154 from 100000\n",
      "loss: 0.019239062385167927\n",
      "epoch:2155 from 100000\n",
      "loss: 0.02213093650061637\n",
      "epoch:2156 from 100000\n",
      "loss: 0.020630101673305035\n",
      "epoch:2157 from 100000\n",
      "loss: 0.01716631365707144\n",
      "epoch:2158 from 100000\n",
      "loss: 0.01935970498016104\n",
      "epoch:2159 from 100000\n",
      "retrying for data\n",
      "loss: 0.01809370913542807\n",
      "epoch:2160 from 100000\n",
      "loss: 0.018661648326087743\n",
      "epoch:2161 from 100000\n",
      "loss: 0.020456051046494395\n",
      "epoch:2162 from 100000\n",
      "loss: 0.01895635388791561\n",
      "epoch:2163 from 100000\n",
      "loss: 0.018735129619017243\n",
      "epoch:2164 from 100000\n",
      "loss: 0.019334711047122255\n",
      "epoch:2165 from 100000\n",
      "loss: 0.016682219284120947\n",
      "epoch:2166 from 100000\n",
      "loss: 0.020137270272243768\n",
      "epoch:2167 from 100000\n",
      "loss: 0.017445982666686177\n",
      "epoch:2168 from 100000\n",
      "loss: 0.015182947972789407\n",
      "epoch:2169 from 100000\n",
      "loss: 0.01966777624329552\n",
      "epoch:2170 from 100000\n",
      "loss: 0.020617267698980868\n",
      "epoch:2171 from 100000\n",
      "loss: 0.020707060873974115\n",
      "epoch:2172 from 100000\n",
      "loss: 0.018538689328124747\n",
      "epoch:2173 from 100000\n",
      "loss: 0.018917339155450463\n",
      "epoch:2174 from 100000\n",
      "loss: 0.01894669356988743\n",
      "epoch:2175 from 100000\n",
      "loss: 0.020290925865992904\n",
      "epoch:2176 from 100000\n",
      "loss: 0.018896824098192155\n",
      "epoch:2177 from 100000\n",
      "loss: 0.019163413031492382\n",
      "epoch:2178 from 100000\n",
      "loss: 0.019604814529884607\n",
      "epoch:2179 from 100000\n",
      "loss: 0.018819614371750504\n",
      "epoch:2180 from 100000\n",
      "loss: 0.021597920916974545\n",
      "epoch:2181 from 100000\n",
      "loss: 0.017066895903553814\n",
      "epoch:2182 from 100000\n",
      "loss: 0.020925427495967597\n",
      "epoch:2183 from 100000\n",
      "loss: 0.01913033233722672\n",
      "epoch:2184 from 100000\n",
      "loss: 0.020669509889557958\n",
      "epoch:2185 from 100000\n",
      "loss: 0.020952225720975548\n",
      "epoch:2186 from 100000\n",
      "loss: 0.018181171384640038\n",
      "epoch:2187 from 100000\n",
      "loss: 0.018573416920844465\n",
      "epoch:2188 from 100000\n",
      "loss: 0.019809561024885625\n",
      "epoch:2189 from 100000\n",
      "loss: 0.018561051692813635\n",
      "epoch:2190 from 100000\n",
      "loss: 0.020762146159540862\n",
      "epoch:2191 from 100000\n",
      "loss: 0.02085408294806257\n",
      "epoch:2192 from 100000\n",
      "loss: 0.016841277509229258\n",
      "epoch:2193 from 100000\n",
      "loss: 0.01500748863327317\n",
      "epoch:2194 from 100000\n",
      "loss: 0.01942608051467687\n",
      "epoch:2195 from 100000\n",
      "loss: 0.0177604544442147\n",
      "epoch:2196 from 100000\n",
      "loss: 0.018545452563557774\n",
      "epoch:2197 from 100000\n",
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.10200.pt\n",
      "loss: 0.019271490105893463\n",
      "epoch:2198 from 100000\n",
      "loss: 0.020219832833390683\n",
      "epoch:2199 from 100000\n",
      "loss: 0.019136538088787347\n",
      "epoch:2200 from 100000\n",
      "loss: 0.01928794357809238\n",
      "epoch:2201 from 100000\n",
      "loss: 0.018010198255069554\n",
      "epoch:2202 from 100000\n",
      "loss: 0.01860198742360808\n",
      "epoch:2203 from 100000\n",
      "loss: 0.019991316134110093\n",
      "epoch:2204 from 100000\n",
      "loss: 0.021053804084658623\n",
      "epoch:2205 from 100000\n",
      "loss: 0.018208259192761034\n",
      "epoch:2206 from 100000\n",
      "loss: 0.019775408756686375\n",
      "epoch:2207 from 100000\n",
      "loss: 0.019336831232067198\n",
      "epoch:2208 from 100000\n",
      "loss: 0.02046053111553192\n",
      "epoch:2209 from 100000\n",
      "loss: 0.016566711099585518\n",
      "epoch:2210 from 100000\n",
      "loss: 0.01654846459859982\n",
      "epoch:2211 from 100000\n",
      "loss: 0.017675141629297286\n",
      "epoch:2212 from 100000\n",
      "loss: 0.016680072993040085\n",
      "epoch:2213 from 100000\n",
      "loss: 0.01852797018364072\n",
      "epoch:2214 from 100000\n",
      "loss: 0.021342075837310404\n",
      "epoch:2215 from 100000\n",
      "loss: 0.0205923086614348\n",
      "epoch:2216 from 100000\n",
      "loss: 0.018843264027964324\n",
      "epoch:2217 from 100000\n",
      "loss: 0.02133348915958777\n",
      "epoch:2218 from 100000\n",
      "loss: 0.017589724506251514\n",
      "epoch:2219 from 100000\n",
      "loss: 0.019025999295990914\n",
      "epoch:2220 from 100000\n",
      "loss: 0.01880697184242308\n",
      "epoch:2221 from 100000\n",
      "loss: 0.01969075994566083\n",
      "epoch:2222 from 100000\n",
      "loss: 0.01907513471087441\n",
      "epoch:2223 from 100000\n",
      "loss: 0.017739665985573083\n",
      "epoch:2224 from 100000\n",
      "loss: 0.020021744450787082\n",
      "epoch:2225 from 100000\n",
      "loss: 0.017813549551647156\n",
      "epoch:2226 from 100000\n",
      "loss: 0.021304983354639262\n",
      "epoch:2227 from 100000\n",
      "loss: 0.02211091050412506\n",
      "epoch:2228 from 100000\n",
      "loss: 0.01956761471228674\n",
      "epoch:2229 from 100000\n",
      "loss: 0.02138846303569153\n",
      "epoch:2230 from 100000\n",
      "loss: 0.019841662753606215\n",
      "epoch:2231 from 100000\n",
      "loss: 0.020356712164357305\n",
      "epoch:2232 from 100000\n",
      "loss: 0.017647312837652862\n",
      "epoch:2233 from 100000\n",
      "loss: 0.01865540351718664\n",
      "epoch:2234 from 100000\n",
      "loss: 0.019627163535915315\n",
      "epoch:2235 from 100000\n",
      "1345155loss: 0.017916686192620546\n",
      "epoch:2236 from 100000\n",
      "loss: 0.017768693156540394\n",
      "epoch:2237 from 100000\n",
      "loss: 0.020427074749022722\n",
      "epoch:2238 from 100000\n",
      "loss: 0.015018867386970669\n",
      "epoch:2239 from 100000\n",
      "loss: 0.01972164009930566\n",
      "epoch:2240 from 100000\n",
      "loss: 0.01822103711310774\n",
      "epoch:2241 from 100000\n",
      "loss: 0.017582697793841362\n",
      "epoch:2242 from 100000\n",
      "loss: 0.019898276892490685\n",
      "epoch:2243 from 100000\n",
      "loss: 0.018825264007318765\n",
      "epoch:2244 from 100000\n",
      "loss: 0.018490478745661676\n",
      "epoch:2245 from 100000\n",
      "loss: 0.019790963036939502\n",
      "epoch:2246 from 100000\n",
      "loss: 0.019382851489353925\n",
      "epoch:2247 from 100000\n",
      "loss: 0.018293463508598506\n",
      "epoch:2248 from 100000\n",
      "loss: 0.01777615665923804\n",
      "epoch:2249 from 100000\n",
      "loss: 0.02038993051974103\n",
      "epoch:2250 from 100000\n",
      "loss: 0.01944110036129132\n",
      "epoch:2251 from 100000\n",
      "loss: 0.018919803434982896\n",
      "epoch:2252 from 100000\n",
      "loss: 0.017857513565104455\n",
      "epoch:2253 from 100000\n",
      "loss: 0.01906990446150303\n",
      "epoch:2254 from 100000\n",
      "loss: 0.019493511208565906\n",
      "epoch:2255 from 100000\n",
      "loss: 0.01733609871007502\n",
      "epoch:2256 from 100000\n",
      "loss: 0.017477583955042064\n",
      "epoch:2257 from 100000\n",
      "loss: 0.019619299040641636\n",
      "epoch:2258 from 100000\n",
      "1349934\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#if not os.path.exists(imagen_samples_folder):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m#    os.makedirs(imagen_samples_folder)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m#trainer.load_from_checkpoint_folder()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m#print(epochs)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     loss \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain_step(unet_number \u001b[39m=\u001b[39;49m unet_to_train,max_batch_size \u001b[39m=\u001b[39;49m batch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gamal/vsc/DiffusionSpeech2Face/train_imagen_all_u1.ipynb#X50sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39m#print(\"At sample seen \" + str(my_dataset.no_of_samples_seen()))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/imagen_pytorch/trainer.py:622\u001b[0m, in \u001b[0;36mImagenTrainer.train_step\u001b[0;34m(self, unet_number, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_train_iter()\n\u001b[1;32m    621\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39munet_number\u001b[39m\u001b[39m'\u001b[39m: unet_number, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m--> 622\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_with_dl_iter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dl_iter, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(unet_number \u001b[39m=\u001b[39m unet_number)\n\u001b[1;32m    624\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/imagen_pytorch/trainer.py:638\u001b[0m, in \u001b[0;36mImagenTrainer.step_with_dl_iter\u001b[0;34m(self, dl_iter, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_with_dl_iter\u001b[39m(\u001b[39mself\u001b[39m, dl_iter, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 638\u001b[0m     dl_tuple_output \u001b[39m=\u001b[39m cast_tuple(\u001b[39mnext\u001b[39;49m(dl_iter))\n\u001b[1;32m    639\u001b[0m     model_input \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl_tuple_output_keywords_names, dl_tuple_output)))\n\u001b[1;32m    640\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_input})\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/imagen_pytorch/data.py:27\u001b[0m, in \u001b[0;36mcycle\u001b[0;34m(dl)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcycle\u001b[39m(dl):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dl:\n\u001b[1;32m     28\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/accelerate/data_loader.py:461\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     current_batch \u001b[39m=\u001b[39m send_to_device(current_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 461\u001b[0m next_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m batch_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_batches:\n\u001b[1;32m    463\u001b[0m     \u001b[39myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/ds2f_m_i/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350043\r"
     ]
    }
   ],
   "source": [
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer,NullUnet\n",
    "from imagen_pytorch.data import Dataset\n",
    "\n",
    "unet0 = NullUnet()  # add a placeholder \"null\" unet for the base unet\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = unet1_dim,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = unet2_dim,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "if(ignore_image_guide):\n",
    "    unets = (unet1, unet2)\n",
    "    image_sizes= (unet1_image_size, image_size)\n",
    "    unet_to_train = UNET #1\n",
    "    #start_image_or_video = None\n",
    "else:\n",
    "    unets = (unet0,unet1, unet2)\n",
    "    image_sizes= (begin_with_image_size,unet1_image_size, image_size)\n",
    "    unet_to_train = UNET + 1 #2\n",
    "    #start_image_or_video = input2[:1,:]\n",
    "\n",
    "#print(input2[:1,:])\n",
    "#print(input2)\n",
    "\n",
    "imagen = Imagen(\n",
    "    unets = unets,\n",
    "    image_sizes = image_sizes,\n",
    "    timesteps = timesteps,\n",
    "    cond_drop_prob = 0.1\n",
    ").cuda()\n",
    "\n",
    "\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    "    split_valid_from_train = False, # whether to split the validation dataset from the training\n",
    "    checkpoint_every = save_model_every,\n",
    "    checkpoint_path = model_filename,\n",
    "    max_checkpoints_keep = 1,\n",
    "    only_train_unet_number = unet_to_train\n",
    ").cuda()\n",
    "\n",
    "\n",
    "trainer.add_train_dataloader(my_dataloader)\n",
    "\n",
    "#if not os.path.exists(imagen_samples_folder):\n",
    "#    os.makedirs(imagen_samples_folder)\n",
    "\n",
    "#my_file = Path(model_filename)\n",
    "#if my_file.is_file():\n",
    "#    print('Using model file ' + model_filename)\n",
    "#    trainer.load(model_filename)\n",
    "\n",
    "#trainer.load_from_checkpoint_folder()\n",
    "#print(epochs)\n",
    "for i in range(epochs):\n",
    "    \n",
    "    loss = trainer.train_step(unet_number = unet_to_train,max_batch_size = batch_size)\n",
    "    print(f'loss: {loss}')\n",
    "    #print(\"At sample seen \" + str(my_dataset.no_of_samples_seen()))\n",
    "    plot_loss(my_dataset.no_of_samples_seen(),loss)\n",
    "    #print(loss_list)\n",
    "    #trainer.save_to_checkpoint_folder()\n",
    "    print('epoch:' + str(i+1) + ' from ' + str(epochs))\n",
    "    last_sample_no = my_dataset.no_of_samples_seen()\n",
    "    if(UNET == 1):\n",
    "        with open(model_filename + '/last_sample_no1.picke', 'wb') as handle:\n",
    "            pickle.dump(last_sample_no, handle)\n",
    "    else:\n",
    "        with open(model_filename + '/last_sample_no2.picke', 'wb') as handle:\n",
    "            pickle.dump(last_sample_no, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint saved to /home/gamal/vsc/DiffusionSpeech2Face/checkpoint/noablation/checkpoint.10260.pt\n"
     ]
    }
   ],
   "source": [
    "trainer.save_to_checkpoint_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import Resize\n",
    "cond_scale = random.uniform(5.1, 9.9)\n",
    "now =time.time()\n",
    "seconds = now\n",
    "output, input0 = my_dataset.__getitem__(1)\n",
    "save_image(output,'ground_truth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img_tensor = Resize((begin_with_image_size, begin_with_image_size))\n",
    "\n",
    "if(ignore_image_guide):\n",
    "    start_image_or_video = None\n",
    "else:\n",
    "    start_image_or_video = resize_img_tensor(output)\n",
    "\n",
    "start_image_or_video = torch.unsqueeze(start_image_or_video,0)\n",
    "input0 = torch.unsqueeze(input0,0)\n",
    "output = torch.unsqueeze(output,0)\n",
    "\n",
    "print(start_image_or_video.shape)\n",
    "print(input0.shape)\n",
    "print(output.shape)\n",
    "\n",
    "images = trainer.sample(text_embeds=input0,start_image_or_video = start_image_or_video,start_at_unet_number = unet_to_train -1 \n",
    "            ,stop_at_unet_number=unet_to_train,batch_size = 1, return_pil_images = True,cond_scale=cond_scale) # returns List[Image]\n",
    "images[0].save('generated.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2f_m_i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78dccc615e96ab04385280185a87a524fe0822daf5dbad2f4bf2e7d7b28366a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
